{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA 620 - Assignment 6\n",
    "\n",
    "Jeremy OBrien, Mael Illien, Vanita Thompson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Classification\n",
    "\n",
    "* It can be useful to be able to classify new \"test\" documents using already classified \"training\" documents. A common example is using a corpus of labeled spam and ham (non-spam) e-mails to predict whether or not a new document is spam. Here is one example of such data:  UCI Machine Learning Repository: Spambase Data Set (http://archive.ics.uci.edu/ml/datasets/Spambase)\n",
    "* For this project, you can either use the above dataset to predict the class of new documents (either withheld from the training dataset or from another source such as your own spam folder).\n",
    "* For more adventurous students, you are welcome (encouraged!) to come up a different set of documents (including scraped web pages!?) that have already been classified (e.g. tagged), then analyze these documents to predict how new documents should be classified.\n",
    "\n",
    "\n",
    "Resources:\n",
    "\n",
    "- http://www.cs.ucf.edu/courses/cap5636/fall2011/nltk.pdf\n",
    "- https://bbengfort.github.io/tutorials/2016/05/19/text-classification-nltk-sckit-learn.html\n",
    "- https://www.cs.bgu.ac.il/~elhadad/nlp16/spam_classifier.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "from nltk import PorterStemmer\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import & Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read individual files from current directory and return the content in a list\n",
    "def get_emails(path):\n",
    "    emails = []\n",
    "    files = [path + f for f in listdir(path) if f != 'cmds']\n",
    "\n",
    "    for file in files:\n",
    "        with open(file, encoding=\"latin-1\") as f:\n",
    "            email = f.read()\n",
    "            if len(email) != 0:\n",
    "                emails.append(email) \n",
    "    return emails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the ham and spam corpora are not balanced. We will sample the ham corpus to even out the sizes in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of emails in easy_ham corpus: 2500\n",
      "Number of emails in spam corpus: 500\n"
     ]
    }
   ],
   "source": [
    "easy_ham = get_emails('./easy_ham/')\n",
    "spam = get_emails('./spam/')\n",
    "\n",
    "print('Number of emails in {} corpus: {}'.format('easy_ham', len(easy_ham)))\n",
    "print('Number of emails in {} corpus: {}'.format('spam', len(spam)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See below for an example of the email format. There are a number of headers followed by the body of the email. Our analysis will be focused on the body content. The function get_email_body will be used to extract this content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract only the body of the emails, ignoring all the headers\n",
    "def get_email_body(email):\n",
    "    # Looking for the last occurence of Date: Sat, 02 Feb 2002 11:20:17 +1300\\n\n",
    "    iter = re.finditer(r\"Date: .*\\n\", email)\n",
    "    # Otherwise look for repeated \\n\\n patterm\n",
    "\n",
    "    indices = [m.span() for m in iter]\n",
    "    body_start = indices[-1][1]\n",
    "    body = email[body_start:].replace(\"\\n\", \"\")\n",
    "\n",
    "    return body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From rssfeeds@jmason.org  Thu Sep 26 16:43:26 2002\n",
      "Return-Path: <rssfeeds@spamassassin.taint.org>\n",
      "Delivered-To: yyyy@localhost.spamassassin.taint.org\n",
      "Received: from localhost (jalapeno [127.0.0.1])\n",
      "\tby jmason.org (Postfix) with ESMTP id E080E16F76\n",
      "\tfor <jm@localhost>; Thu, 26 Sep 2002 16:42:30 +0100 (IST)\n",
      "Received: from jalapeno [127.0.0.1]\n",
      "\tby localhost with IMAP (fetchmail-5.9.0)\n",
      "\tfor jm@localhost (single-drop); Thu, 26 Sep 2002 16:42:30 +0100 (IST)\n",
      "Received: from dogma.slashnull.org (localhost [127.0.0.1]) by\n",
      "    dogma.slashnull.org (8.11.6/8.11.6) with ESMTP id g8QFSsg24511 for\n",
      "    <jm@jmason.org>; Thu, 26 Sep 2002 16:28:54 +0100\n",
      "Message-Id: <200209261528.g8QFSsg24511@dogma.slashnull.org>\n",
      "To: yyyy@spamassassin.taint.org\n",
      "From: fark <rssfeeds@spamassassin.taint.org>\n",
      "Subject: Friends don't let friends swim drunk. Paging Dr. Darwin..\n",
      "Date: Thu, 26 Sep 2002 15:28:54 -0000\n",
      "Content-Type: text/plain; encoding=utf-8\n",
      "\n",
      "URL: http://www.newsisfree.com/click/-4,8272607,1717/\n",
      "Date: 2002-09-26T11:26:11+01:00\n",
      "\n",
      "(NY Daily News)\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(easy_ham[2001])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(NY Daily News)\n"
     ]
    }
   ],
   "source": [
    "print(get_email_body(easy_ham[2001]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1000 emails in this corpus.\n"
     ]
    }
   ],
   "source": [
    "# Assemble the corpus by combining the spam emails with 500 emails sampled from the \n",
    "# ham emails to balance the dataset and assign the known labels ham: 0, spam:1\n",
    "random.seed(620)\n",
    "labeled_emails = ([(get_email_body(em), '0') for em in random.choices(easy_ham, k=500)] + \n",
    "                    [(get_email_body(em), '1') for em in spam])\n",
    "\n",
    "print('There are {} emails in this corpus.'.format(len(labeled_emails)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing\n",
    "\n",
    "The simple approach taken is case normalization, stopword removal, and stemming, then TF-IDF vectorization (apparently tokenizing doesnâ€™t work well with email due to colloquial speech)\n",
    "\n",
    "Resource: \n",
    "- https://towardsdatascience.com/tf-idf-for-document-ranking-from-scratch-in-python-on-real-world-dataset-796d339a4089\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual pre-processing\n",
    "\n",
    "This is shown for exploration. The functionality is encapsulated in the process_email_body function and the below can be removed later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'    From:        Chris Garrigues <cwg-dated-1030377287.06fa6d@DeepEddy.Com>    Message-ID:  <1029945287.4797.TMDA@deepeddy.vircio.com>  | I can\\'t reproduce this error.For me it is very repeatable... (like every time, without fail).This is the debug log of the pick happening ...18:19:03 Pick_It {exec pick +inbox -list -lbrace -lbrace -subject ftp -rbrace -rbrace} {4852-4852 -sequence mercury}18:19:03 exec pick +inbox -list -lbrace -lbrace -subject ftp -rbrace -rbrace 4852-4852 -sequence mercury18:19:04 Ftoc_PickMsgs {{1 hit}}18:19:04 Marking 1 hits18:19:04 tkerror: syntax error in expression \"int ...Note, if I run the pick command by hand ...delta$ pick +inbox -list -lbrace -lbrace -subject ftp -rbrace -rbrace  4852-4852 -sequence mercury1 hitThat\\'s where the \"1 hit\" comes from (obviously).  The version of nmh I\\'musing is ...delta$ pick -versionpick -- nmh-1.0.4 [compiled on fuchsia.cs.mu.OZ.AU at Sun Mar 17 14:55:56 ICT 2002]And the relevant part of my .mh_profile ...delta$ mhparam pick-seq sel -listSince the pick command works, the sequence (actually, both of them, theone that\\'s explicit on the command line, from the search popup, and theone that comes from .mh_profile) do get created.kreps: this is still using the version of the code form a day ago, I haven\\'tbeen able to reach the cvs repository today (local routing issue I think)._______________________________________________Exmh-workers mailing listExmh-workers@redhat.comhttps://listman.redhat.com/mailman/listinfo/exmh-workers'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_email_body(easy_ham[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['From', ':', 'Chris', 'Garrigues', '<', 'cwg-dated-1030377287.06fa6d', '@', 'DeepEddy.Com', '>', 'Message-ID']\n"
     ]
    }
   ],
   "source": [
    "# The sklearn tfidf function does most of the work below. See usage below.\n",
    "\n",
    "# Tokenize\n",
    "tokens = word_tokenize(get_email_body(easy_ham[0]))\n",
    "print(tokens[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136\n",
      "['from', 'chris', 'garrigues', 'i', 'ca', 'reproduce', 'this', 'me', 'it', 'is']\n"
     ]
    }
   ],
   "source": [
    "# Normalize\n",
    "# ME: Note: We might not want to get rid of non-alpha characters. Potential value punctions, html tags?\n",
    "word_tokens = [w.lower() for w in tokens if w.isalpha()] \n",
    "print(len(word_tokens))\n",
    "print(word_tokens[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\n",
      "['chris', 'garrigues', 'ca', 'reproduce', 'repeatable', 'like', 'every', 'time', 'without', 'fail']\n"
     ]
    }
   ],
   "source": [
    "# Remove stop words\n",
    "stop_words = stopwords.words('english')\n",
    "filtered_words = [w for w in word_tokens if not w in stop_words]\n",
    "print(len(filtered_words))\n",
    "print(filtered_words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chri', 'garrigu', 'ca', 'reproduc', 'repeat', 'like', 'everi', 'time', 'without', 'fail', 'debug', 'log', 'pick', 'happen', 'exec', 'pick', 'ftp', 'mercuri', 'exec', 'pick']\n"
     ]
    }
   ],
   "source": [
    "# Stemming (Consider Lemmatization instead)\n",
    "porter = PorterStemmer()\n",
    "stemmed_words = [porter.stem(t) for t in filtered_words]\n",
    "print(stemmed_words[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider Lemmatization instead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing (encapsulated):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process email: tokenize, remove non-alpha characters, remove stop words, stem, lemmatize\n",
    "# and return a list of tokens\n",
    "def process_email_body(email, alpha=True, rm_stopwords=True, stem=True, lemma=False):\n",
    "    tokens = word_tokenize(email)\n",
    "    if alpha: tokens = [w.lower() for w in tokens if w.isalpha()] \n",
    "    if rm_stopwords: \n",
    "        stop_words = stopwords.words('english')\n",
    "        tokens = [w for w in tokens if not w in stop_words]\n",
    "    if stem:\n",
    "        porter = PorterStemmer()\n",
    "        tokens = [porter.stem(t) for t in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chri', 'garrigu', 'ca', 'reproduc', 'repeat', 'like', 'everi', 'time', 'without', 'fail', 'debug', 'log', 'pick', 'happen', 'exec', 'pick', 'ftp', 'mercuri', 'exec', 'pick', 'ftp', 'hit', 'mark', 'tkerror', 'syntax', 'error', 'express', 'int', 'note', 'run', 'pick', 'command', 'hand', 'delta', 'pick', 'ftp', 'hitthat', 'hit', 'come', 'obvious', 'version', 'nmh', 'delta', 'pick', 'compil', 'sun', 'mar', 'ict', 'relev', 'part', 'delta', 'mhparam', 'sel', 'pick', 'command', 'work', 'sequenc', 'actual', 'theon', 'explicit', 'command', 'line', 'search', 'popup', 'theon', 'come', 'get', 'still', 'use', 'version', 'code', 'form', 'day', 'ago', 'abl', 'reach', 'cv', 'repositori', 'today', 'local', 'rout', 'issu', 'think', 'mail']\n"
     ]
    }
   ],
   "source": [
    "# Example\n",
    "print(process_email_body(get_email_body(easy_ham[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_set = [(gender_features_function(n), gender) for (n, gender) in train_names]\n",
    "#     devtest_set = [(gender_features_function(n), gender) for (n, gender) in devtest_names]\n",
    "#     test_set = [(gender_features_function(n), gender) for (n, gender) in test_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Consider additional feature engineering?\n",
    "- number of tokens, etc.\n",
    "- presence of word 'unsubscribe'\n",
    "\n",
    "For feature engineering, what would you say to the following combinations:\n",
    "\n",
    "- yes case normalization, yes symbol removal, yes stopword removal, then stem\n",
    "- yes case normalization, yes symbol removal, no stopword removal, then stem\n",
    "- yes case normalization, no symbol removal, no stopword removal, then stem\n",
    "- no case normalization, no symbol removal, no stopword removal, then stem\n",
    "  \n",
    "  \n",
    "- yes case normalization, yes symbol removal, yes stopword removal, then lemmatize\n",
    "- yes case normalization, yes symbol removal, no stopword removal, then lemmatize\n",
    "- yes case normalization, no symbol removal, no stopword removal, then lemmatize\n",
    "- no case normalization, no symbol removal, no stopword removal, then lemmatize\n",
    "  \n",
    "  \n",
    "- yes case normalization, yes symbol removal, yes stopword removal, no stem / lemmatize\n",
    "- yes case normalization, yes symbol removal, no stopword removal, no stem / lemmatize\n",
    "- yes case normalization, no symbol removal, no stopword removal, no stem / lemmatize\n",
    "- no case normalization, no symbol removal, no stopword removal, no stem / lemmatize\n",
    "  \n",
    "Then once we've determine the best performer, we can implement some sort of error correction to see if that improves it.\n",
    "\n",
    "Then we can try versions of the best performer that are noun-only or verb-only (with the settings above, so long as not contradictory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split labeled corpus into emails and labels:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply processing functions to email bodies. \n",
    "- Option 1: manual. \n",
    "- Option 2: sklearn pre-processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: takes a long time\n",
    "\n",
    "# emails = [process_email_body(email) for email in labeled_emails] # X\n",
    "# y = [label for (email, label) in labeled_emails] # y = labels\n",
    "\n",
    "# vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2\n",
    "# Refer to https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
    "# vectorizer = TfidfVectorizer(lowercase=True, stop_words='english')\n",
    "# play with max_features, etc.\n",
    "\n",
    "emails = [email for (email, label) in labeled_emails] # X\n",
    "y = [label for (email, label) in labeled_emails] # y = labels\n",
    "\n",
    "vectorizer = TfidfVectorizer(lowercase=True, stop_words='english', token_pattern = r'[a-zA-Z]+', max_features=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aa', 'ab', 'able', 'absolutely', 'ac', 'accept', 'access', 'account', 'act', 'action', 'actually', 'ad', 'adclick', 'add', 'address', 'addresses', 'admanmail', 'admin', 'administration', 'ads', 'adult', 'advantage', 'advertising', 'ae', 'africa', 'ag', 'age', 'agent', 'agents', 'ago', 'ah', 'ahref', 'aid', 'al', 'alb', 'align', 'allow', 'alsa', 'alt', 'alternative', 'america', 'american', 'amp', 'annuity', 'answer', 'application', 'applications', 'apply', 'apt', 'archive', 'area', 'arial', 'article', 'ascii', 'asciicontent', 'ask', 'asp', 'assist', 'assistance', 'atoll', 'au', 'aug', 'available', 'average', 'aw', 'away', 'awr', 'b', 'background', 'bad', 'bank', 'base', 'based', 'bb', 'bc', 'beenthere', 'begin', 'believe', 'benefit', 'best', 'better', 'bgcolor', 'bidi', 'big', 'billion', 'bin', 'bindex', 'bit', 'bitx', 'black', 'blank', 'blockquote', 'blue', 'body', 'bold', 'bonus', 'book', 'border', 'bordercolor', 'boundary', 'box', 'br', 'bug', 'build', 'bulk', 'bulklist', 'bush', 'business', 'buy', 'c', 'ca', 'called', 'came', 'capital', 'car', 'card', 'care', 'case', 'cash', 'cb', 'cc', 'cccccc', 'cd', 'cdo', 'ce', 'cellpadding', 'cellspacing', 'center', 'cf', 'cfm', 'cgi', 'ch', 'change', 'charset', 'check', 'china', 'choice', 'city', 'cj', 'ck', 'claim', 'class', 'classes', 'clean', 'clear', 'click', 'client', 'clients', 'cm', 'cn', 'cna', 'code', 'collapse', 'color', 'colspan', 'com', 'comcast', 'comcontent', 'come', 'comes', 'comments', 'commission', 'communication', 'communications', 'companies', 'company', 'complete', 'computer', 'comsubject', 'contact', 'contains', 'content', 'continue', 'control', 'copy', 'copyright', 'cost', 'countries', 'country', 'courier', 'course', 'create', 'credit', 'current', 'currently', 'custom', 'customer', 'customers', 'd', 'da', 'daily', 'darial', 'data', 'database', 'datapower', 'date', 'dave', 'day', 'days', 'dc']\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.get_feature_names()[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1000)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=21)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=21, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes - Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "# Required because of complaint about the matrix being too sparse\n",
    "print(type(X))\n",
    "X_train = X_train.toarray()\n",
    "X_test = X_test.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and train Gaussian Naive Bayes model\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "# Predict on test set\n",
    "y_pred = gnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9914285714285714"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9366666666666666"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[131  15]\n",
      " [  4 150]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.90      0.93       146\n",
      "           1       0.91      0.97      0.94       154\n",
      "\n",
      "    accuracy                           0.94       300\n",
      "   macro avg       0.94      0.94      0.94       300\n",
      "weighted avg       0.94      0.94      0.94       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes - Bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and train Gaussian Naive Bayes model\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train, y_train)\n",
    "# Predict on test set\n",
    "y_pred = bnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8985714285714286"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9166666666666666"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[142   4]\n",
      " [ 21 133]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.97      0.92       146\n",
      "           1       0.97      0.86      0.91       154\n",
      "\n",
      "    accuracy                           0.92       300\n",
      "   macro avg       0.92      0.92      0.92       300\n",
      "weighted avg       0.92      0.92      0.92       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "spambase = pd.read_csv(\"https://raw.githubusercontent.com/Vthomps000/DATA620/master/spambase.data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column names from spambase.names data\n",
    "spambase.columns=['word_freq_make','word_freq_address','word_freq_all','word_freq_3d','word_freq_our','word_freq_over',\n",
    "              'word_freq_remove','word_freq_internet','word_freq_order','word_freq_mail','word_freq_receive',\n",
    "              'word_freq_will','word_freq_people','word_freq_report','word_freq_addresses','word_freq_free',\n",
    "              'word_freq_business','word_freq_email','word_freq_you','word_freq_credit','word_freq_your',\n",
    "              'word_freq_font','word_freq_000','word_freq_money','word_freq_hp','word_freq_hpl','word_freq_george',\n",
    "              'word_freq_650','word_freq_lab','word_freq_labs','word_freq_telnet','word_freq_857','word_freq_data',\n",
    "              'word_freq_415','word_freq_85','word_freq_technology','word_freq_1999','word_freq_parts','word_freq_pm',\n",
    "              'word_freq_direct','word_freq_cs','word_freq_meeting','word_freq_original','word_freq_project',\n",
    "              'word_freq_re','word_freq_edu','word_freq_table','word_freq_conference','char_freq_;','char_freq_(',\n",
    "              'char_freq_[','char_freq_!','char_freq_$','char_freq_#','capital_run_length_average','capital_run_length_longest',\n",
    "              'capital_run_length_total','spamclass']                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spam: 1812\n",
      "Ham: 2788\n"
     ]
    }
   ],
   "source": [
    "# Count the number of spam vs. not spam\n",
    "spam_count = len(spambase[spambase.spamclass==1])\n",
    "ham_count = len(spambase[spambase.spamclass==0])\n",
    "\n",
    "print(\"Spam: %d\" %spam_count)\n",
    "print(\"Ham: %d\" %ham_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train 70%, test 30%\n",
    "X = spambase.values[:, 0:57]\n",
    "y = spambase.values[:, 57]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.7, test_size=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jlobr\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:319: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9152173913043479"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
    "    max_features=None, max_leaf_nodes=None,\n",
    "    min_impurity_decrease=1e-07, min_samples_leaf=1,\n",
    "    min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "    presort=False, random_state=88, splitter='best')\n",
    "dt.fit(X_train, y_train)\n",
    "dt.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Ham</th>\n",
       "      <th>Predicted Spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Ham</th>\n",
       "      <td>797</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Spam</th>\n",
       "      <td>61</td>\n",
       "      <td>466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Predicted Ham  Predicted Spam\n",
       "Actual Ham             797              56\n",
       "Actual Spam             61             466"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confusion matrix for Decission Tree\n",
    "dt_cm = confusion_matrix(y_test, dt.predict(X_test))\n",
    "pd.DataFrame(data = dt_cm, columns = ['Predicted Ham', 'Predicted Spam'],\n",
    "            index = ['Actual Ham', 'Actual Spam'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled emails out of a total 1380 emails in test dataset : 117\n",
      "In detail, 56 ham emails are mislabeled as spam, 61 spam emails are mislabeled as ham.\n"
     ]
    }
   ],
   "source": [
    "dt_pred = dt.predict(X_test)\n",
    "print(\"Number of mislabeled emails out of a total %d emails in test dataset : %d\"\n",
    "       % (X_test.shape[0],(y_test != dt_pred).sum()))\n",
    "print(\"In detail, %d ham emails are mislabeled as spam, %d spam emails are mislabeled as ham.\"\n",
    "      % (dt_cm [0,1], dt_cm[1,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure grid search for hyperparameter tuning at exponential increments\n",
    "def svm_tune_grid(X, y, kernel, nfolds):\n",
    "    \n",
    "    C = [.0001,.001,.01,.1,1,10]\n",
    "    gamma = [.0001,.001,.01,.1,1,10]\n",
    "    \n",
    "    if kernel == 'linear':\n",
    "        param_grid = {'C': C}\n",
    "        grid_search = GridSearchCV(svm.SVC(kernel=kernel), \n",
    "                                   param_grid, \n",
    "                                   cv=nfolds)\n",
    "    \n",
    "    elif kernel == 'rbf':\n",
    "        param_grid = {'C': C, 'gamma': gamma}\n",
    "        grid_search = GridSearchCV(svm.SVC(kernel=kernel), \n",
    "                                   param_grid, \n",
    "                                   cv=nfolds)\n",
    "    else:\n",
    "        print('Kernel not recognized or supported')\n",
    "        return\n",
    "    \n",
    "    grid_search.fit(X,y)\n",
    "    grid_search.best_params_\n",
    "    \n",
    "    return grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machines is a classifier which makes use of a 'kernel trick' to efficiently transform data to a new space in which the margin between different classes can be maximized using a hyperplane.\n",
    "\n",
    "We employ two common kernels - linear and radial basis function (RBF) - to evaluate their respective performance.\n",
    "\n",
    "SVM kernels take several parameters.  The C parameter is a regularization term that penalizes misclassification (i.e. a lower value imposes a softer class boundary, or higher value a harder), and is used for both linear and RBF kernels.  The RBF kernel also takes a gamma parameter, which controls the distance over which a given training example influences the boundary.\n",
    "\n",
    "We perform a grid search to identify good candidates for C (for linearn and RBF) and gamma (only for RBF) parameters.  Due to computational load, we limit the cross validation to five folds - optimally this would be 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grid search for optimal C and gamma in linear kernel\n",
    "svm_tune_grid(X_train, y_train, 'linear', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'gamma': 1}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grid search for optimal C and gamma in radial basis function kernel\n",
    "svm_tune_grid(X_train, y_train, 'rbf', 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit an SVM classifier with the linear kernel and C parameter value of 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit SVM classifier with linear kernel on training set\n",
    "svm_lin = svm.SVC(C=10, \n",
    "               kernel='linear')\n",
    "svm_lin.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[141   5]\n",
      " [  5 149]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       146\n",
      "           1       0.97      0.97      0.97       154\n",
      "\n",
      "    accuracy                           0.97       300\n",
      "   macro avg       0.97      0.97      0.97       300\n",
      "weighted avg       0.97      0.97      0.97       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_lin.score(X_train, y_train)\n",
    "svm_lin.score(X_test, y_test)\n",
    "svm_lin_y_pred = svm_lin.predict(X_test)\n",
    "print(confusion_matrix(y_test, svm_lin_y_pred))\n",
    "print(classification_report(y_test, svm_lin_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit an SVM classifier with the radial basis function kernel, C parameter value of 10, and gamma of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf', max_iter=-1,\n",
       "    probability=False, random_state=None, shrinking=True, tol=0.001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit SVM classifier with RBF kernel on training set\n",
    "svm_rbf = svm.SVC(C=10, \n",
    "               kernel='rbf',\n",
    "                 gamma=1)\n",
    "svm_rbf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[143   3]\n",
      " [  4 150]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98       146\n",
      "           1       0.98      0.97      0.98       154\n",
      "\n",
      "    accuracy                           0.98       300\n",
      "   macro avg       0.98      0.98      0.98       300\n",
      "weighted avg       0.98      0.98      0.98       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_rbf.score(X_train, y_train)\n",
    "svm_rbf.score(X_test, y_test)\n",
    "svm_rbf_y_pred = svm_rbf.predict(X_test)\n",
    "print(confusion_matrix(y_test, svm_rbf_y_pred))\n",
    "print(classification_report(y_test, svm_rbf_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(SVM findings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptive Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9398550724637681"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada = AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
    "          learning_rate=1.0, n_estimators=50, random_state=88)\n",
    "ada.fit(X_train, y_train)\n",
    "ada.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Ham</th>\n",
       "      <th>Predicted Spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Ham</th>\n",
       "      <td>831</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Spam</th>\n",
       "      <td>47</td>\n",
       "      <td>466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Predicted Ham  Predicted Spam\n",
       "Actual Ham             831              36\n",
       "Actual Spam             47             466"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_cm = confusion_matrix(y_test, ada.predict(X_test))\n",
    "\n",
    "pd.DataFrame(data = ada_cm, columns = ['Predicted Ham', 'Predicted Spam'],\n",
    "            index = ['Actual Ham', 'Actual Spam'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled emails out of a total 1380 emails in test dataset : 83\n",
      "In detail, 36 ham emails are mislabeled as spam, 47 spam emails are mislabeled as ham.\n"
     ]
    }
   ],
   "source": [
    "ada_pred = ada.predict(X_test)\n",
    "print(\"Number of mislabeled emails out of a total %d emails in test dataset : %d\"\n",
    "       % (X_test.shape[0],(y_test != ada_pred).sum()))\n",
    "print(\"In detail, %d ham emails are mislabeled as spam, %d spam emails are mislabeled as ham.\"\n",
    "      % (ada_cm [0,1], ada_cm[1,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reference:https://datawhatnow.com/feature-importance/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.936231884057971"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=1e-07, min_samples_leaf=1,\n",
    "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "            n_estimators=10, n_jobs=1, oob_score=False, random_state=88,\n",
    "            verbose=0, warm_start=False)\n",
    "rf.fit(X_train, y_train)\n",
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Ham</th>\n",
       "      <th>Predicted Spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Ham</th>\n",
       "      <td>839</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Spam</th>\n",
       "      <td>60</td>\n",
       "      <td>453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Predicted Ham  Predicted Spam\n",
       "Actual Ham             839              28\n",
       "Actual Spam             60             453"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_cm = confusion_matrix(y_test, rf.predict(X_test))\n",
    "pd.DataFrame(data = rf_cm, columns = ['Predicted Ham', 'Predicted Spam'],\n",
    "            index = ['Actual Ham', 'Actual Spam'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled emails out of a total 1380 emails in test dataset : 88\n",
      "In detail, 28 ham emails are mislabeled as spam, 60 spam emails are mislabeled as ham.\n"
     ]
    }
   ],
   "source": [
    "rf_pred = rf.predict(X_test)\n",
    "print(\"Number of mislabeled emails out of a total %d emails in test dataset : %d\"\n",
    "       % (X_test.shape[0],(y_test != rf_pred).sum()))\n",
    "print(\"In detail, %d ham emails are mislabeled as spam, %d spam emails are mislabeled as ham.\"\n",
    "      % (rf_cm [0,1], rf_cm[1,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can we add the other models to this? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>AdaBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.936232</td>\n",
       "      <td>0.939855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mislabelled</th>\n",
       "      <td>120.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>83.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Decision Tree  Random Forest   AdaBoost\n",
       "Accuracy          0.913043       0.936232   0.939855\n",
       "Mislabelled     120.000000      88.000000  83.000000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reference:https://datawhatnow.com/feature-importance/\n",
    "Conclusion = {'Decision Tree' : [dt.score(X_test, y_test), (y_test != dt_pred).sum()],\n",
    "             'Random Forest' : [rf.score(X_test, y_test), (y_test != rf_pred).sum()],\n",
    "             'AdaBoost' : [ada.score(X_test, y_test), (y_test != ada_pred).sum()],\n",
    "             }\n",
    "pd.DataFrame (Conclusion)\n",
    "pd.DataFrame(Conclusion, index=['Accuracy', 'Mislabelled'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
