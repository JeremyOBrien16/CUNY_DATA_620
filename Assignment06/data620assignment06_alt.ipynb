{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA 620 - Assignment 6\n",
    "\n",
    "Jeremy OBrien, Mael Illien, Vanita Thompson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Classification\n",
    "\n",
    "* It can be useful to be able to classify new \"test\" documents using already classified \"training\" documents. A common example is using a corpus of labeled spam and ham (non-spam) e-mails to predict whether or not a new document is spam. Here is one example of such data:  UCI Machine Learning Repository: Spambase Data Set (http://archive.ics.uci.edu/ml/datasets/Spambase)\n",
    "* For this project, you can either use the above dataset to predict the class of new documents (either withheld from the training dataset or from another source such as your own spam folder).\n",
    "* For more adventurous students, you are welcome (encouraged!) to come up a different set of documents (including scraped web pages!?) that have already been classified (e.g. tagged), then analyze these documents to predict how new documents should be classified.\n",
    "\n",
    "\n",
    "Resources:\n",
    "\n",
    "- http://www.cs.ucf.edu/courses/cap5636/fall2011/nltk.pdf\n",
    "- https://bbengfort.github.io/tutorials/2016/05/19/text-classification-nltk-sckit-learn.html\n",
    "- https://www.cs.bgu.ac.il/~elhadad/nlp16/spam_classifier.html\n",
    "\n",
    "Resource: (can be removed)\n",
    "- https://towardsdatascience.com/tf-idf-for-document-ranking-from-scratch-in-python-on-real-world-dataset-796d339a4089\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "In this assignment, we will look at document classification in the realm of emails with the binary labels 'spam' and 'non-spam', also referred to as 'ham'. The spamassassin corpus [insert source] contains individual raw email files which will extracted and processed to form a unified corpus. From this corpus, the data will be split into training and test sets and a variety of models will be developed to identify the best approach to spam email classification. \n",
    "\n",
    "The procedure is as follows:\n",
    "   - Extract emails from raw files\n",
    "   - Process email content to containly only the body of the emails and ignoring all the headers\n",
    "   - Apply NLP methods from NLTK and Sklearn to tokenize the email content into features\n",
    "   - Develop models\n",
    "   - Compare performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from nltk import PorterStemmer\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import & Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ham and spam emails are stored in individual files. The `get_emails` function below extracts the content from file and returns a list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read individual files from current directory and return the content in a list\n",
    "def get_emails(path):\n",
    "    emails = []\n",
    "    files = [path + f for f in listdir(path) if f != 'cmds']\n",
    "\n",
    "    for file in files:\n",
    "        with open(file, encoding=\"latin-1\") as f:\n",
    "            email = f.read()\n",
    "            if len(email) != 0:\n",
    "                emails.append(email) \n",
    "    return emails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the ham and spam corpora are not balanced. We will sample the ham corpus to even out the sizes in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of emails in easy_ham corpus: 2500\n",
      "Number of emails in spam corpus: 500\n"
     ]
    }
   ],
   "source": [
    "easy_ham = get_emails('./easy_ham/')\n",
    "spam = get_emails('./spam/')\n",
    "\n",
    "print('Number of emails in {} corpus: {}'.format('easy_ham', len(easy_ham)))\n",
    "print('Number of emails in {} corpus: {}'.format('spam', len(spam)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of the email format. There are a number of headers followed by the body of the email. Our analysis will be focused on the body content. The function `get_email_body` will be used to extract this content. While it is possible that the ignored headers contain useful data for classification, this will be left for further investigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From rssfeeds@jmason.org  Mon Oct  7 12:05:27 2002\n",
      "Return-Path: <rssfeeds@spamassassin.taint.org>\n",
      "Delivered-To: yyyy@localhost.spamassassin.taint.org\n",
      "Received: from localhost (jalapeno [127.0.0.1])\n",
      "\tby jmason.org (Postfix) with ESMTP id 4123D16F7C\n",
      "\tfor <jm@localhost>; Mon,  7 Oct 2002 12:04:04 +0100 (IST)\n",
      "Received: from jalapeno [127.0.0.1]\n",
      "\tby localhost with IMAP (fetchmail-5.9.0)\n",
      "\tfor jm@localhost (single-drop); Mon, 07 Oct 2002 12:04:04 +0100 (IST)\n",
      "Received: from dogma.slashnull.org (localhost [127.0.0.1]) by\n",
      "    dogma.slashnull.org (8.11.6/8.11.6) with ESMTP id g9780fK23260 for\n",
      "    <jm@jmason.org>; Mon, 7 Oct 2002 09:00:41 +0100\n",
      "Message-Id: <200210070800.g9780fK23260@dogma.slashnull.org>\n",
      "To: yyyy@spamassassin.taint.org\n",
      "From: gamasutra <rssfeeds@spamassassin.taint.org>\n",
      "Subject: Postmortem: Ubi Soft China's Music Up -- Summer Rainbow\n",
      "Date: Mon, 07 Oct 2002 08:00:41 -0000\n",
      "Content-Type: text/plain; encoding=utf-8\n",
      "\n",
      "URL: http://www.newsisfree.com/click/-0,8613667,159/\n",
      "Date: 2002-10-06T18:12:53+01:00\n",
      "\n",
      "Ubi China had always wanted to make a PC game for the local market, but a \n",
      "number to factors kept the idea on hold. In January 2001, the right incentive \n",
      "to motivate Ubi China to try a local project finally arrived: the license for \n",
      "\"Music Up\", a popular animated property.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(easy_ham[2001])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract only the body of the emails, ignoring all the headers\n",
    "def get_email_body(email):\n",
    "    # Looking for the last occurence of Date: Sat, 02 Feb 2002 11:20:17 +1300\\n\n",
    "    iter = re.finditer(r\"Date: .*\\n\", email)\n",
    "    # Otherwise look for repeated \\n\\n patterm\n",
    "\n",
    "    indices = [m.span() for m in iter]\n",
    "    body_start = indices[-1][1]\n",
    "    body = email[body_start:].replace(\"\\n\", \"\")\n",
    "\n",
    "    return body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ubi China had always wanted to make a PC game for the local market, but a number to factors kept the idea on hold. In January 2001, the right incentive to motivate Ubi China to try a local project finally arrived: the license for \"Music Up\", a popular animated property.\n"
     ]
    }
   ],
   "source": [
    "print(get_email_body(easy_ham[2001]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `get_email_body` function is applied to the emails and the corpus is assembled by combining the spam emails with 500 emails sampled from the ham emails to balance the dataset. Known labels ham: 0, spam:1 are also assigned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1000 emails in this corpus.\n"
     ]
    }
   ],
   "source": [
    "# Assemble the corpus by combining the spam emails with 500 emails sampled from the \n",
    "# ham emails to balance the dataset and assign the known labels ham: 0, spam:1\n",
    "random.seed(620)\n",
    "labeled_emails = ([(get_email_body(em), '0') for em in random.choices(easy_ham, k=500)] + \n",
    "                    [(get_email_body(em), '1') for em in spam])\n",
    "\n",
    "print('There are {} emails in this corpus.'.format(len(labeled_emails)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing\n",
    "\n",
    "There are a number of NLP methods to process text including tokenizing, case normalization, stopword removal, stemming and lemmatization.\n",
    "\n",
    "The manual pre-processing section below highlights some of the functionality described above on a sample email. These steps will be encapsulated in the function `process_email_body` with parameters allowing for more control over the processing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"In a message dated 9/24/2002 11:24:58 AM, jamesr@best.com writes:>This situation wouldn't have happened in the first place if California>didn't have economically insane regulations.  They created a regulatory>climate that facilitated this.  So yes, it is the product of>over-regulation.>Which is to say, if you reduce the argument to absurdity, that law causes crime. (Yes, I agree that badly written law can make life so frustrating that people have little choice but to subvery it if they want to get anything done. This is also true of corporate policies, and all other attempts to regulate conduct by rules. Rules just don't work well when situations are fluid or ambiguous. But I don't think that the misbehavior of energy companies in California can properly be called well-intentioned lawbreaking by parties who were trying to do the right thing but could do so only by falling afoul of some technicality.)If you want to get to root causes, we should probably go to the slaying of Abel by Cain. Perhaps we can figure out what went wrong then, and roll our learning forward through history and create a FoRKtopia.Nonpartisanly, which is to say casting stones on all houses, whether bicameral or unicameral, built on sand or on rock, to the left of them or to the right of them, of glass or brick or twig or straw, Tom\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_email_body(easy_ham[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['In', 'a', 'message', 'dated', '9/24/2002', '11:24:58', 'AM', ',', 'jamesr', '@']\n"
     ]
    }
   ],
   "source": [
    "# Tokenize\n",
    "tokens = word_tokenize(get_email_body(easy_ham[0]))\n",
    "print(tokens[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223\n",
      "['in', 'a', 'message', 'dated', 'am', 'jamesr', 'writes', 'this', 'situation', 'would']\n"
     ]
    }
   ],
   "source": [
    "# Normalize\n",
    "word_tokens = [w.lower() for w in tokens if w.isalpha()] \n",
    "print(len(word_tokens))\n",
    "print(word_tokens[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107\n",
      "['message', 'dated', 'jamesr', 'writes', 'situation', 'would', 'happened', 'first', 'place', 'california']\n"
     ]
    }
   ],
   "source": [
    "# Stopword removal \n",
    "stop_words = stopwords.words('english')\n",
    "filtered_words = [w for w in word_tokens if not w in stop_words]\n",
    "print(len(filtered_words))\n",
    "print(filtered_words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['messag', 'date', 'jamesr', 'write', 'situat', 'would', 'happen', 'first', 'place', 'california', 'econom', 'insan', 'regul', 'creat', 'regulatori', 'climat', 'facilit', 'ye', 'product', 'say']\n"
     ]
    }
   ],
   "source": [
    "# Stemming\n",
    "porter = PorterStemmer()\n",
    "stemmed_words = [porter.stem(t) for t in filtered_words]\n",
    "print(stemmed_words[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual pre-processing (encapsulated):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As described above, the function `process_email_body` can be applied to each email in order to turn the content of the emails into useable features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process email: tokenize, remove non-alpha characters, remove stop words, stem, lemmatize\n",
    "# and return a list of tokens\n",
    "def process_email_body(email, alpha=True, rm_stopwords=True, stem=True, lemma=False):\n",
    "    tokens = word_tokenize(email)\n",
    "    if alpha: tokens = [w.lower() for w in tokens if w.isalpha()] \n",
    "    if rm_stopwords: \n",
    "        stop_words = stopwords.words('english')\n",
    "        tokens = [w for w in tokens if not w in stop_words]\n",
    "    if stem:\n",
    "        porter = PorterStemmer()\n",
    "        tokens = [porter.stem(t) for t in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['messag', 'date', 'jamesr', 'write', 'situat', 'would', 'happen', 'first', 'place', 'california', 'econom', 'insan', 'regul', 'creat', 'regulatori', 'climat', 'facilit', 'ye', 'product', 'say', 'reduc', 'argument', 'absurd', 'law', 'caus', 'crime', 'ye', 'agre', 'badli', 'written', 'law', 'make', 'life', 'frustrat', 'peopl', 'littl', 'choic', 'subveri', 'want', 'get', 'anyth', 'done', 'also', 'true', 'corpor', 'polici', 'attempt', 'regul', 'conduct', 'rule', 'rule', 'work', 'well', 'situat', 'fluid', 'ambigu', 'think', 'misbehavior', 'energi', 'compani', 'california', 'properli', 'call', 'lawbreak', 'parti', 'tri', 'right', 'thing', 'could', 'fall', 'afoul', 'technic', 'want', 'get', 'root', 'caus', 'probabl', 'go', 'slay', 'abel', 'cain', 'perhap', 'figur', 'went', 'wrong', 'roll', 'learn', 'forward', 'histori', 'creat', 'say', 'cast', 'stone', 'hous', 'whether', 'bicamer', 'unicamer', 'built', 'sand', 'rock', 'left', 'right', 'glass', 'brick', 'twig', 'straw', 'tom']\n"
     ]
    }
   ],
   "source": [
    "# Example above revisited using the function\n",
    "print(process_email_body(get_email_body(easy_ham[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Consider additional feature engineering?\n",
    "\n",
    "MI: incorporate this into text if needed\n",
    "\n",
    "- number of tokens, etc.\n",
    "- presence of word 'unsubscribe'\n",
    "\n",
    "For feature engineering, what would you say to the following combinations:\n",
    "\n",
    "- yes case normalization, yes symbol removal, yes stopword removal, then stem\n",
    "- yes case normalization, yes symbol removal, no stopword removal, then stem\n",
    "- yes case normalization, no symbol removal, no stopword removal, then stem\n",
    "- no case normalization, no symbol removal, no stopword removal, then stem\n",
    "  \n",
    "  \n",
    "- yes case normalization, yes symbol removal, yes stopword removal, then lemmatize\n",
    "- yes case normalization, yes symbol removal, no stopword removal, then lemmatize\n",
    "- yes case normalization, no symbol removal, no stopword removal, then lemmatize\n",
    "- no case normalization, no symbol removal, no stopword removal, then lemmatize\n",
    "  \n",
    "  \n",
    "- yes case normalization, yes symbol removal, yes stopword removal, no stem / lemmatize\n",
    "- yes case normalization, yes symbol removal, no stopword removal, no stem / lemmatize\n",
    "- yes case normalization, no symbol removal, no stopword removal, no stem / lemmatize\n",
    "- no case normalization, no symbol removal, no stopword removal, no stem / lemmatize\n",
    "  \n",
    "Then once we've determine the best performer, we can implement some sort of error correction to see if that improves it.\n",
    "\n",
    "Then we can try versions of the best performer that are noun-only or verb-only (with the settings above, so long as not contradictory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, run time becomes excessive when emails processed with the manual approach are vectorized and the transformation applied to the emails using the code block below. For this reason, we will rely on the efficiency of the built-in pre-processor of the sklearn library for the remainder of the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: manual pre-processing (takes a long time to run)\n",
    "\n",
    "# emails = [process_email_body(email) for email in labeled_emails] # X\n",
    "# y = [label for (email, label) in labeled_emails] # y = labels\n",
    "\n",
    "# vectorizer = TfidfVectorizer()\n",
    "# X = vectorizer.fit_transform(emails) # run time takes too long."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing using sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sklearn `TfidfVectorizer` object allows us to apply the same processing steps that we manually outlined below via the function paramters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2\n",
    "# Refer to https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
    "\n",
    "emails = [email for (email, label) in labeled_emails] # X = emails features (see below)\n",
    "y = [label for (email, label) in labeled_emails] # y = labels\n",
    "\n",
    "vectorizer = TfidfVectorizer(lowercase=True, stop_words='english', token_pattern = r'[a-zA-Z]+', max_features=1000)\n",
    "\n",
    "X = vectorizer.fit_transform(emails)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a look as some of the features returned by the vectorizer, we find english words such as 'address' or 'advertising' but also a number of html tags such as 'cellpadding' or 'bgcolor' which are often typical of spam emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aa', 'ab', 'able', 'absolutely', 'ac', 'accept', 'access', 'account', 'act', 'action', 'actually', 'ad', 'adclick', 'add', 'additional', 'address', 'addresses', 'admanmail', 'admin', 'ads', 'adult', 'advertising', 'ae', 'af', 'ag', 'age', 'agent', 'agents', 'ago', 'ahref', 'aid', 'al', 'align', 'allow', 'alsa', 'alt', 'alternative', 'america', 'american', 'amp', 'annuity', 'answer', 'application', 'apply', 'archive', 'area', 'arial', 'article', 'ascii', 'asciicontent', 'ask', 'asp', 'assist', 'assistance', 'atoll', 'au', 'aug', 'available', 'average', 'aw', 'away', 'awr', 'b', 'ba', 'background', 'bad', 'bank', 'banners', 'base', 'based', 'bb', 'bc', 'beenthere', 'begin', 'believe', 'benefit', 'best', 'better', 'bgcolor', 'bidi', 'big', 'bin', 'bindex', 'bit', 'bitx', 'black', 'blank', 'blockquote', 'blue', 'body', 'bonus', 'book', 'border', 'bordercolor', 'boundary', 'box', 'br', 'build', 'bulk', 'bulklist', 'bush', 'business', 'businesses', 'buy', 'c', 'ca', 'called', 'came', 'campaign', 'canada', 'capital', 'car', 'card', 'care', 'case', 'cash', 'cb', 'cc', 'cccccc', 'cd', 'cdo', 'ce', 'cellpadding', 'cellspacing', 'center', 'cf', 'cfm', 'cgi', 'ch', 'change', 'charge', 'charset', 'check', 'city', 'cj', 'ck', 'claim', 'class', 'classes', 'clean', 'clear', 'click', 'client', 'clients', 'cm', 'cn', 'cna', 'code', 'collapse', 'color', 'colspan', 'com', 'comcast', 'comcontent', 'come', 'comes', 'coming', 'comments', 'commission', 'communication', 'communications', 'companies', 'company', 'complete', 'computer', 'comsubject', 'contact', 'contains', 'content', 'continue', 'control', 'copy', 'cost', 'country', 'courier', 'course', 'cr', 'create', 'credit', 'current', 'currently', 'customer', 'customers', 'd', 'da', 'daily', 'darial', 'data', 'database', 'date', 'day', 'days', 'dc', 'dcenter', 'dd', 'deal', 'dear', 'death', 'decided', 'decoration']\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.get_feature_names()[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1000)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split\n",
    "\n",
    "The dataset is split into test and training sets and evualted using a number of models in the section that follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=21)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=21, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "In sections, a number of models are examined including two Naive Bayes approaches (Gaussian & Bernoulli), Decision Trees, SVM, Adaptive Boosting and Random Forests.\n",
    "\n",
    "The function below will be used to display summaries of each model. It also returns the model and accuracies for further use in a summary dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [] # holds model and accuracy information\n",
    "\n",
    "def build_and_score_model(model, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    # Predict on test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Training set accuracy\n",
    "    train_acc = model.score(X_train,y_train)\n",
    "    print('Model training set accuracy: {} \\n'.format(train_acc))\n",
    "    \n",
    "    # Testing set accuracy\n",
    "    test_acc = model.score(X_test, y_test)\n",
    "    print('Model test set accuracy: {} \\n'.format(test_acc))\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    cm = pd.DataFrame(data = cm, columns = ['Predicted Ham', 'Predicted Spam'],\n",
    "            index = ['Actual Ham', 'Actual Spam'])\n",
    "    print(cm)\n",
    "    print('\\n')\n",
    "          \n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    models.append([model, train_acc, test_acc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes - Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required because of complaint about the matrix being too sparse\n",
    "X_train = X_train.toarray()\n",
    "X_test = X_test.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate and train Gaussian Naive Bayes model\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training set accuracy: 0.98 \n",
      "\n",
      "Model test set accuracy: 0.9266666666666666 \n",
      "\n",
      "             Predicted Ham  Predicted Spam\n",
      "Actual Ham             134              12\n",
      "Actual Spam             10             144\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.92       146\n",
      "           1       0.92      0.94      0.93       154\n",
      "\n",
      "    accuracy                           0.93       300\n",
      "   macro avg       0.93      0.93      0.93       300\n",
      "weighted avg       0.93      0.93      0.93       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "build_and_score_model(gnb, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes - Bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate and train Gaussian Naive Bayes model\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training set accuracy: 0.9057142857142857 \n",
      "\n",
      "Model test set accuracy: 0.9033333333333333 \n",
      "\n",
      "             Predicted Ham  Predicted Spam\n",
      "Actual Ham             142               4\n",
      "Actual Spam             25             129\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.97      0.91       146\n",
      "           1       0.97      0.84      0.90       154\n",
      "\n",
      "    accuracy                           0.90       300\n",
      "   macro avg       0.91      0.91      0.90       300\n",
      "weighted avg       0.91      0.90      0.90       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "build_and_score_model(bnb, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=1e-07, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=88, splitter='best')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
    "    max_features=None, max_leaf_nodes=None,\n",
    "    min_impurity_decrease=1e-07, min_samples_leaf=1,\n",
    "    min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "    random_state=88, splitter='best')\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training set accuracy: 1.0 \n",
      "\n",
      "Model test set accuracy: 0.96 \n",
      "\n",
      "             Predicted Ham  Predicted Spam\n",
      "Actual Ham             142               4\n",
      "Actual Spam              8             146\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96       146\n",
      "           1       0.97      0.95      0.96       154\n",
      "\n",
      "    accuracy                           0.96       300\n",
      "   macro avg       0.96      0.96      0.96       300\n",
      "weighted avg       0.96      0.96      0.96       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "build_and_score_model(dt, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure grid search for hyperparameter tuning at exponential increments\n",
    "def svm_tune_grid(X, y, kernel, nfolds):\n",
    "    \n",
    "    C = [.0001,.001,.01,.1,1,10]\n",
    "    gamma = [.0001,.001,.01,.1,1,10]\n",
    "    \n",
    "    if kernel == 'linear':\n",
    "        param_grid = {'C': C}\n",
    "        grid_search = GridSearchCV(svm.SVC(kernel=kernel), \n",
    "                                   param_grid, \n",
    "                                   cv=nfolds)\n",
    "    \n",
    "    elif kernel == 'rbf':\n",
    "        param_grid = {'C': C, 'gamma': gamma}\n",
    "        grid_search = GridSearchCV(svm.SVC(kernel=kernel), \n",
    "                                   param_grid, \n",
    "                                   cv=nfolds)\n",
    "    else:\n",
    "        print('Kernel not recognized or supported')\n",
    "        return\n",
    "    \n",
    "    grid_search.fit(X,y)\n",
    "    grid_search.best_params_\n",
    "    \n",
    "    return grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machines is a classifier which makes use of a 'kernel trick' to efficiently transform data to a new space in which the margin between different classes can be maximized using a hyperplane.\n",
    "\n",
    "We employ two common kernels - linear and radial basis function (RBF) - to evaluate their respective performance.\n",
    "\n",
    "SVM kernels take several parameters.  The C parameter is a regularization term that penalizes misclassification (i.e. a lower value imposes a softer class boundary, or higher value a harder), and is used for both linear and RBF kernels.  The RBF kernel also takes a gamma parameter, which controls the distance over which a given training example influences the boundary.\n",
    "\n",
    "We perform a grid search to identify good candidates for C (for linearn and RBF) and gamma (only for RBF) parameters.  Due to computational load, we limit the cross validation to five folds - optimally this would be 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search for optimal C and gamma in linear kernel\n",
    "svm_tune_grid(X_train, y_train, 'linear', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search for optimal C and gamma in radial basis function kernel\n",
    "svm_tune_grid(X_train, y_train, 'rbf', 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit an SVM classifier with the linear kernel and C parameter value of 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit SVM classifier with linear kernel on training set\n",
    "svm_lin = svm.SVC(C=10, \n",
    "               kernel='linear')\n",
    "svm_lin.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_lin.score(X_train, y_train)\n",
    "svm_lin.score(X_test, y_test)\n",
    "svm_lin_y_pred = svm_lin.predict(X_test)\n",
    "print(confusion_matrix(y_test, svm_lin_y_pred))\n",
    "print(classification_report(y_test, svm_lin_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit an SVM classifier with the radial basis function kernel, C parameter value of 10, and gamma of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit SVM classifier with RBF kernel on training set\n",
    "svm_rbf = svm.SVC(C=10, \n",
    "               kernel='rbf',\n",
    "                 gamma=1)\n",
    "svm_rbf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_rbf.score(X_train, y_train)\n",
    "svm_rbf.score(X_test, y_test)\n",
    "svm_rbf_y_pred = svm_rbf.predict(X_test)\n",
    "print(confusion_matrix(y_test, svm_rbf_y_pred))\n",
    "print(classification_report(y_test, svm_rbf_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(SVM findings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptive Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada = AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
    "          learning_rate=1.0, n_estimators=50, random_state=88)\n",
    "ada.fit(X_train, y_train)\n",
    "ada.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_cm = confusion_matrix(y_test, ada.predict(X_test))\n",
    "\n",
    "pd.DataFrame(data = ada_cm, columns = ['Predicted Ham', 'Predicted Spam'],\n",
    "            index = ['Actual Ham', 'Actual Spam'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_pred = ada.predict(X_test)\n",
    "print(\"Number of mislabeled emails out of a total %d emails in test dataset : %d\"\n",
    "       % (X_test.shape[0],(y_test != ada_pred).sum()))\n",
    "print(\"In detail, %d ham emails are mislabeled as spam, %d spam emails are mislabeled as ham.\"\n",
    "      % (ada_cm [0,1], ada_cm[1,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reference:https://datawhatnow.com/feature-importance/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=1e-07, min_samples_leaf=1,\n",
    "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "            n_estimators=10, n_jobs=1, oob_score=False, random_state=88,\n",
    "            verbose=0, warm_start=False)\n",
    "rf.fit(X_train, y_train)\n",
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_cm = confusion_matrix(y_test, rf.predict(X_test))\n",
    "pd.DataFrame(data = rf_cm, columns = ['Predicted Ham', 'Predicted Spam'],\n",
    "            index = ['Actual Ham', 'Actual Spam'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pred = rf.predict(X_test)\n",
    "print(\"Number of mislabeled emails out of a total %d emails in test dataset : %d\"\n",
    "       % (X_test.shape[0],(y_test != rf_pred).sum()))\n",
    "print(\"In detail, %d ham emails are mislabeled as spam, %d spam emails are mislabeled as ham.\"\n",
    "      % (rf_cm [0,1], rf_cm[1,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can we add the other models to this? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reference:https://datawhatnow.com/feature-importance/\n",
    "Conclusion = {'Decision Tree' : [dt.score(X_test, y_test), (y_test != dt_pred).sum()],\n",
    "             'Random Forest' : [rf.score(X_test, y_test), (y_test != rf_pred).sum()],\n",
    "             'AdaBoost' : [ada.score(X_test, y_test), (y_test != ada_pred).sum()],\n",
    "             }\n",
    "pd.DataFrame (Conclusion)\n",
    "pd.DataFrame(Conclusion, index=['Accuracy', 'Mislabelled'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
