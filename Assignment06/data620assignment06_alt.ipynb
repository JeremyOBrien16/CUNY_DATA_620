{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA 620 - Assignment 6\n",
    "\n",
    "Jeremy OBrien, Mael Illien, Vanita Thompson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Classification\n",
    "\n",
    "* It can be useful to be able to classify new \"test\" documents using already classified \"training\" documents. A common example is using a corpus of labeled spam and ham (non-spam) e-mails to predict whether or not a new document is spam. Here is one example of such data:  UCI Machine Learning Repository: Spambase Data Set (http://archive.ics.uci.edu/ml/datasets/Spambase)\n",
    "* For this project, you can either use the above dataset to predict the class of new documents (either withheld from the training dataset or from another source such as your own spam folder).\n",
    "* For more adventurous students, you are welcome (encouraged!) to come up a different set of documents (including scraped web pages!?) that have already been classified (e.g. tagged), then analyze these documents to predict how new documents should be classified.\n",
    "\n",
    "\n",
    "Resources:\n",
    "\n",
    "- http://www.cs.ucf.edu/courses/cap5636/fall2011/nltk.pdf\n",
    "- https://bbengfort.github.io/tutorials/2016/05/19/text-classification-nltk-sckit-learn.html\n",
    "- https://www.cs.bgu.ac.il/~elhadad/nlp16/spam_classifier.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from nltk import PorterStemmer\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import & Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read individual files from current directory and return the content in a list\n",
    "def get_emails(path):\n",
    "    emails = []\n",
    "    files = [path + f for f in listdir(path) if f != 'cmds']\n",
    "\n",
    "    for file in files:\n",
    "        with open(file, encoding=\"latin-1\") as f:\n",
    "            email = f.read()\n",
    "            if len(email) != 0:\n",
    "                emails.append(email) \n",
    "    return emails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the ham and spam corpora are not balanced. We will sample the ham corpus to even out the sizes in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of emails in easy_ham corpus: 2500\n",
      "Number of emails in spam corpus: 500\n"
     ]
    }
   ],
   "source": [
    "easy_ham = get_emails('./easy_ham/')\n",
    "spam = get_emails('./spam/')\n",
    "\n",
    "print('Number of emails in {} corpus: {}'.format('easy_ham', len(easy_ham)))\n",
    "print('Number of emails in {} corpus: {}'.format('spam', len(spam)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See below for an example of the email format. There are a number of headers followed by the body of the email. Our analysis will be focused on the body content. The function get_email_body will be used to extract this content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract only the body of the emails, ignoring all the headers\n",
    "def get_email_body(email):\n",
    "    # Looking for the last occurence of Date: Sat, 02 Feb 2002 11:20:17 +1300\\n\n",
    "    iter = re.finditer(r\"Date: .*\\n\", email)\n",
    "    # Otherwise look for repeated \\n\\n patterm\n",
    "\n",
    "    indices = [m.span() for m in iter]\n",
    "    body_start = indices[-1][1]\n",
    "    body = email[body_start:].replace(\"\\n\", \"\")\n",
    "\n",
    "    return body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From rssfeeds@jmason.org  Mon Oct  7 12:05:27 2002\n",
      "Return-Path: <rssfeeds@spamassassin.taint.org>\n",
      "Delivered-To: yyyy@localhost.spamassassin.taint.org\n",
      "Received: from localhost (jalapeno [127.0.0.1])\n",
      "\tby jmason.org (Postfix) with ESMTP id 4123D16F7C\n",
      "\tfor <jm@localhost>; Mon,  7 Oct 2002 12:04:04 +0100 (IST)\n",
      "Received: from jalapeno [127.0.0.1]\n",
      "\tby localhost with IMAP (fetchmail-5.9.0)\n",
      "\tfor jm@localhost (single-drop); Mon, 07 Oct 2002 12:04:04 +0100 (IST)\n",
      "Received: from dogma.slashnull.org (localhost [127.0.0.1]) by\n",
      "    dogma.slashnull.org (8.11.6/8.11.6) with ESMTP id g9780fK23260 for\n",
      "    <jm@jmason.org>; Mon, 7 Oct 2002 09:00:41 +0100\n",
      "Message-Id: <200210070800.g9780fK23260@dogma.slashnull.org>\n",
      "To: yyyy@spamassassin.taint.org\n",
      "From: gamasutra <rssfeeds@spamassassin.taint.org>\n",
      "Subject: Postmortem: Ubi Soft China's Music Up -- Summer Rainbow\n",
      "Date: Mon, 07 Oct 2002 08:00:41 -0000\n",
      "Content-Type: text/plain; encoding=utf-8\n",
      "\n",
      "URL: http://www.newsisfree.com/click/-0,8613667,159/\n",
      "Date: 2002-10-06T18:12:53+01:00\n",
      "\n",
      "Ubi China had always wanted to make a PC game for the local market, but a \n",
      "number to factors kept the idea on hold. In January 2001, the right incentive \n",
      "to motivate Ubi China to try a local project finally arrived: the license for \n",
      "\"Music Up\", a popular animated property.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(easy_ham[2001])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ubi China had always wanted to make a PC game for the local market, but a number to factors kept the idea on hold. In January 2001, the right incentive to motivate Ubi China to try a local project finally arrived: the license for \"Music Up\", a popular animated property.\n"
     ]
    }
   ],
   "source": [
    "print(get_email_body(easy_ham[2001]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1000 emails in this corpus.\n"
     ]
    }
   ],
   "source": [
    "# Assemble the corpus by combining the spam emails with 500 emails sampled from the \n",
    "# ham emails to balance the dataset and assign the known labels ham: 0, spam:1\n",
    "random.seed(620)\n",
    "labeled_emails = ([(get_email_body(em), '0') for em in random.choices(easy_ham, k=500)] + \n",
    "                    [(get_email_body(em), '1') for em in spam])\n",
    "\n",
    "print('There are {} emails in this corpus.'.format(len(labeled_emails)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing\n",
    "\n",
    "The simple approach taken is case normalization, stopword removal, and stemming, then TF-IDF vectorization (apparently tokenizing doesnâ€™t work well with email due to colloquial speech)\n",
    "\n",
    "Resource: \n",
    "- https://towardsdatascience.com/tf-idf-for-document-ranking-from-scratch-in-python-on-real-world-dataset-796d339a4089\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual pre-processing\n",
    "\n",
    "This is shown for exploration. The functionality is encapsulated in the process_email_body function and the below can be removed later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"In a message dated 9/24/2002 11:24:58 AM, jamesr@best.com writes:>This situation wouldn't have happened in the first place if California>didn't have economically insane regulations.  They created a regulatory>climate that facilitated this.  So yes, it is the product of>over-regulation.>Which is to say, if you reduce the argument to absurdity, that law causes crime. (Yes, I agree that badly written law can make life so frustrating that people have little choice but to subvery it if they want to get anything done. This is also true of corporate policies, and all other attempts to regulate conduct by rules. Rules just don't work well when situations are fluid or ambiguous. But I don't think that the misbehavior of energy companies in California can properly be called well-intentioned lawbreaking by parties who were trying to do the right thing but could do so only by falling afoul of some technicality.)If you want to get to root causes, we should probably go to the slaying of Abel by Cain. Perhaps we can figure out what went wrong then, and roll our learning forward through history and create a FoRKtopia.Nonpartisanly, which is to say casting stones on all houses, whether bicameral or unicameral, built on sand or on rock, to the left of them or to the right of them, of glass or brick or twig or straw, Tom\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_email_body(easy_ham[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['In', 'a', 'message', 'dated', '9/24/2002', '11:24:58', 'AM', ',', 'jamesr', '@']\n"
     ]
    }
   ],
   "source": [
    "# The sklearn tfidf function does most of the work below. See usage below.\n",
    "\n",
    "# Tokenize\n",
    "tokens = word_tokenize(get_email_body(easy_ham[0]))\n",
    "print(tokens[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223\n",
      "['in', 'a', 'message', 'dated', 'am', 'jamesr', 'writes', 'this', 'situation', 'would']\n"
     ]
    }
   ],
   "source": [
    "# Normalize\n",
    "# ME: Note: We might not want to get rid of non-alpha characters. Potential value punctions, html tags?\n",
    "word_tokens = [w.lower() for w in tokens if w.isalpha()] \n",
    "print(len(word_tokens))\n",
    "print(word_tokens[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107\n",
      "['message', 'dated', 'jamesr', 'writes', 'situation', 'would', 'happened', 'first', 'place', 'california']\n"
     ]
    }
   ],
   "source": [
    "# Remove stop words\n",
    "stop_words = stopwords.words('english')\n",
    "filtered_words = [w for w in word_tokens if not w in stop_words]\n",
    "print(len(filtered_words))\n",
    "print(filtered_words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['messag', 'date', 'jamesr', 'write', 'situat', 'would', 'happen', 'first', 'place', 'california', 'econom', 'insan', 'regul', 'creat', 'regulatori', 'climat', 'facilit', 'ye', 'product', 'say']\n"
     ]
    }
   ],
   "source": [
    "# Stemming (Consider Lemmatization instead)\n",
    "porter = PorterStemmer()\n",
    "stemmed_words = [porter.stem(t) for t in filtered_words]\n",
    "print(stemmed_words[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider Lemmatization instead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing (encapsulated):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process email: tokenize, remove non-alpha characters, remove stop words, stem, lemmatize\n",
    "# and return a list of tokens\n",
    "def process_email_body(email, alpha=True, rm_stopwords=True, stem=True, lemma=False):\n",
    "    tokens = word_tokenize(email)\n",
    "    if alpha: tokens = [w.lower() for w in tokens if w.isalpha()] \n",
    "    if rm_stopwords: \n",
    "        stop_words = stopwords.words('english')\n",
    "        tokens = [w for w in tokens if not w in stop_words]\n",
    "    if stem:\n",
    "        porter = PorterStemmer()\n",
    "        tokens = [porter.stem(t) for t in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['messag', 'date', 'jamesr', 'write', 'situat', 'would', 'happen', 'first', 'place', 'california', 'econom', 'insan', 'regul', 'creat', 'regulatori', 'climat', 'facilit', 'ye', 'product', 'say', 'reduc', 'argument', 'absurd', 'law', 'caus', 'crime', 'ye', 'agre', 'badli', 'written', 'law', 'make', 'life', 'frustrat', 'peopl', 'littl', 'choic', 'subveri', 'want', 'get', 'anyth', 'done', 'also', 'true', 'corpor', 'polici', 'attempt', 'regul', 'conduct', 'rule', 'rule', 'work', 'well', 'situat', 'fluid', 'ambigu', 'think', 'misbehavior', 'energi', 'compani', 'california', 'properli', 'call', 'lawbreak', 'parti', 'tri', 'right', 'thing', 'could', 'fall', 'afoul', 'technic', 'want', 'get', 'root', 'caus', 'probabl', 'go', 'slay', 'abel', 'cain', 'perhap', 'figur', 'went', 'wrong', 'roll', 'learn', 'forward', 'histori', 'creat', 'say', 'cast', 'stone', 'hous', 'whether', 'bicamer', 'unicamer', 'built', 'sand', 'rock', 'left', 'right', 'glass', 'brick', 'twig', 'straw', 'tom']\n"
     ]
    }
   ],
   "source": [
    "# Example\n",
    "print(process_email_body(get_email_body(easy_ham[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_set = [(gender_features_function(n), gender) for (n, gender) in train_names]\n",
    "#     devtest_set = [(gender_features_function(n), gender) for (n, gender) in devtest_names]\n",
    "#     test_set = [(gender_features_function(n), gender) for (n, gender) in test_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Consider additional feature engineering?\n",
    "- number of tokens, etc.\n",
    "- presence of word 'unsubscribe'\n",
    "\n",
    "For feature engineering, what would you say to the following combinations:\n",
    "\n",
    "- yes case normalization, yes symbol removal, yes stopword removal, then stem\n",
    "- yes case normalization, yes symbol removal, no stopword removal, then stem\n",
    "- yes case normalization, no symbol removal, no stopword removal, then stem\n",
    "- no case normalization, no symbol removal, no stopword removal, then stem\n",
    "  \n",
    "  \n",
    "- yes case normalization, yes symbol removal, yes stopword removal, then lemmatize\n",
    "- yes case normalization, yes symbol removal, no stopword removal, then lemmatize\n",
    "- yes case normalization, no symbol removal, no stopword removal, then lemmatize\n",
    "- no case normalization, no symbol removal, no stopword removal, then lemmatize\n",
    "  \n",
    "  \n",
    "- yes case normalization, yes symbol removal, yes stopword removal, no stem / lemmatize\n",
    "- yes case normalization, yes symbol removal, no stopword removal, no stem / lemmatize\n",
    "- yes case normalization, no symbol removal, no stopword removal, no stem / lemmatize\n",
    "- no case normalization, no symbol removal, no stopword removal, no stem / lemmatize\n",
    "  \n",
    "Then once we've determine the best performer, we can implement some sort of error correction to see if that improves it.\n",
    "\n",
    "Then we can try versions of the best performer that are noun-only or verb-only (with the settings above, so long as not contradictory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split labeled corpus into emails and labels:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply processing functions to email bodies. \n",
    "- Option 1: manual. \n",
    "- Option 2: sklearn pre-processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: takes a long time\n",
    "\n",
    "# emails = [process_email_body(email) for email in labeled_emails] # X\n",
    "# y = [label for (email, label) in labeled_emails] # y = labels\n",
    "\n",
    "# vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2\n",
    "# Refer to https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
    "# vectorizer = TfidfVectorizer(lowercase=True, stop_words='english')\n",
    "# play with max_features, etc.\n",
    "\n",
    "emails = [email for (email, label) in labeled_emails] # X\n",
    "y = [label for (email, label) in labeled_emails] # y = labels\n",
    "\n",
    "vectorizer = TfidfVectorizer(lowercase=True, stop_words='english', token_pattern = r'[a-zA-Z]+', max_features=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aa', 'ab', 'able', 'absolutely', 'ac', 'accept', 'access', 'account', 'act', 'action', 'actually', 'ad', 'adclick', 'add', 'additional', 'address', 'addresses', 'admanmail', 'admin', 'ads', 'adult', 'advertising', 'ae', 'af', 'ag', 'age', 'agent', 'agents', 'ago', 'ahref', 'aid', 'al', 'align', 'allow', 'alsa', 'alt', 'alternative', 'america', 'american', 'amp', 'annuity', 'answer', 'application', 'apply', 'archive', 'area', 'arial', 'article', 'ascii', 'asciicontent', 'ask', 'asp', 'assist', 'assistance', 'atoll', 'au', 'aug', 'available', 'average', 'aw', 'away', 'awr', 'b', 'ba', 'background', 'bad', 'bank', 'banners', 'base', 'based', 'bb', 'bc', 'beenthere', 'begin', 'believe', 'benefit', 'best', 'better', 'bgcolor', 'bidi', 'big', 'bin', 'bindex', 'bit', 'bitx', 'black', 'blank', 'blockquote', 'blue', 'body', 'bonus', 'book', 'border', 'bordercolor', 'boundary', 'box', 'br', 'build', 'bulk', 'bulklist', 'bush', 'business', 'businesses', 'buy', 'c', 'ca', 'called', 'came', 'campaign', 'canada', 'capital', 'car', 'card', 'care', 'case', 'cash', 'cb', 'cc', 'cccccc', 'cd', 'cdo', 'ce', 'cellpadding', 'cellspacing', 'center', 'cf', 'cfm', 'cgi', 'ch', 'change', 'charge', 'charset', 'check', 'city', 'cj', 'ck', 'claim', 'class', 'classes', 'clean', 'clear', 'click', 'client', 'clients', 'cm', 'cn', 'cna', 'code', 'collapse', 'color', 'colspan', 'com', 'comcast', 'comcontent', 'come', 'comes', 'coming', 'comments', 'commission', 'communication', 'communications', 'companies', 'company', 'complete', 'computer', 'comsubject', 'contact', 'contains', 'content', 'continue', 'control', 'copy', 'cost', 'country', 'courier', 'course', 'cr', 'create', 'credit', 'current', 'currently', 'customer', 'customers', 'd', 'da', 'daily', 'darial', 'data', 'database', 'date', 'day', 'days', 'dc', 'dcenter', 'dd', 'deal', 'dear', 'death', 'decided', 'decoration']\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.get_feature_names()[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1000)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=21)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=21, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes - Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "# Required because of complaint about the matrix being too sparse\n",
    "print(type(X))\n",
    "X_train = X_train.toarray()\n",
    "X_test = X_test.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and train Gaussian Naive Bayes model\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "# Predict on test set\n",
    "y_pred = gnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9266666666666666"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[134  12]\n",
      " [ 10 144]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.92       146\n",
      "           1       0.92      0.94      0.93       154\n",
      "\n",
      "    accuracy                           0.93       300\n",
      "   macro avg       0.93      0.93      0.93       300\n",
      "weighted avg       0.93      0.93      0.93       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes - Bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and train Gaussian Naive Bayes model\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train, y_train)\n",
    "# Predict on test set\n",
    "y_pred = bnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9057142857142857"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9033333333333333"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[142   4]\n",
      " [ 25 129]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.97      0.91       146\n",
      "           1       0.97      0.84      0.90       154\n",
      "\n",
      "    accuracy                           0.90       300\n",
      "   macro avg       0.91      0.91      0.90       300\n",
      "weighted avg       0.91      0.90      0.90       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "spambase = pd.read_csv(\"https://raw.githubusercontent.com/Vthomps000/DATA620/master/spambase.data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column names from spambase.names data\n",
    "spambase.columns=['word_freq_make','word_freq_address','word_freq_all','word_freq_3d','word_freq_our','word_freq_over',\n",
    "              'word_freq_remove','word_freq_internet','word_freq_order','word_freq_mail','word_freq_receive',\n",
    "              'word_freq_will','word_freq_people','word_freq_report','word_freq_addresses','word_freq_free',\n",
    "              'word_freq_business','word_freq_email','word_freq_you','word_freq_credit','word_freq_your',\n",
    "              'word_freq_font','word_freq_000','word_freq_money','word_freq_hp','word_freq_hpl','word_freq_george',\n",
    "              'word_freq_650','word_freq_lab','word_freq_labs','word_freq_telnet','word_freq_857','word_freq_data',\n",
    "              'word_freq_415','word_freq_85','word_freq_technology','word_freq_1999','word_freq_parts','word_freq_pm',\n",
    "              'word_freq_direct','word_freq_cs','word_freq_meeting','word_freq_original','word_freq_project',\n",
    "              'word_freq_re','word_freq_edu','word_freq_table','word_freq_conference','char_freq_;','char_freq_(',\n",
    "              'char_freq_[','char_freq_!','char_freq_$','char_freq_#','capital_run_length_average','capital_run_length_longest',\n",
    "              'capital_run_length_total','spamclass']                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spam: 1812\n",
      "Ham: 2788\n"
     ]
    }
   ],
   "source": [
    "# Count the number of spam vs. not spam\n",
    "spam_count = len(spambase[spambase.spamclass==1])\n",
    "ham_count = len(spambase[spambase.spamclass==0])\n",
    "\n",
    "print(\"Spam: %d\" %spam_count)\n",
    "print(\"Ham: %d\" %ham_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train 70%, test 30%\n",
    "X = spambase.values[:, 0:57]\n",
    "y = spambase.values[:, 57]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.7, test_size=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thomp\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:319: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9130434782608695"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
    "    max_features=None, max_leaf_nodes=None,\n",
    "    min_impurity_decrease=1e-07, min_samples_leaf=1,\n",
    "    min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "    presort=False, random_state=88, splitter='best')\n",
    "dt.fit(X_train, y_train)\n",
    "dt.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Ham</th>\n",
       "      <th>Predicted Spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Ham</th>\n",
       "      <td>799</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Spam</th>\n",
       "      <td>52</td>\n",
       "      <td>461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Predicted Ham  Predicted Spam\n",
       "Actual Ham             799              68\n",
       "Actual Spam             52             461"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confusion matrix for Decission Tree\n",
    "dt_cm = confusion_matrix(y_test, dt.predict(X_test))\n",
    "pd.DataFrame(data = dt_cm, columns = ['Predicted Ham', 'Predicted Spam'],\n",
    "            index = ['Actual Ham', 'Actual Spam'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled emails out of a total 1380 emails in test dataset : 120\n",
      "In detail, 68 ham emails are mislabeled as spam, 52 spam emails are mislabeled as ham.\n"
     ]
    }
   ],
   "source": [
    "dt_pred = dt.predict(X_test)\n",
    "print(\"Number of mislabeled emails out of a total %d emails in test dataset : %d\"\n",
    "       % (X_test.shape[0],(y_test != dt_pred).sum()))\n",
    "print(\"In detail, %d ham emails are mislabeled as spam, %d spam emails are mislabeled as ham.\"\n",
    "      % (dt_cm [0,1], dt_cm[1,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptive Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9398550724637681"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada = AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
    "          learning_rate=1.0, n_estimators=50, random_state=88)\n",
    "ada.fit(X_train, y_train)\n",
    "ada.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Ham</th>\n",
       "      <th>Predicted Spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Ham</th>\n",
       "      <td>831</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Spam</th>\n",
       "      <td>47</td>\n",
       "      <td>466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Predicted Ham  Predicted Spam\n",
       "Actual Ham             831              36\n",
       "Actual Spam             47             466"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_cm = confusion_matrix(y_test, ada.predict(X_test))\n",
    "\n",
    "pd.DataFrame(data = ada_cm, columns = ['Predicted Ham', 'Predicted Spam'],\n",
    "            index = ['Actual Ham', 'Actual Spam'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled emails out of a total 1380 emails in test dataset : 83\n",
      "In detail, 36 ham emails are mislabeled as spam, 47 spam emails are mislabeled as ham.\n"
     ]
    }
   ],
   "source": [
    "ada_pred = ada.predict(X_test)\n",
    "print(\"Number of mislabeled emails out of a total %d emails in test dataset : %d\"\n",
    "       % (X_test.shape[0],(y_test != ada_pred).sum()))\n",
    "print(\"In detail, %d ham emails are mislabeled as spam, %d spam emails are mislabeled as ham.\"\n",
    "      % (ada_cm [0,1], ada_cm[1,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reference:https://datawhatnow.com/feature-importance/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.936231884057971"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=1e-07, min_samples_leaf=1,\n",
    "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "            n_estimators=10, n_jobs=1, oob_score=False, random_state=88,\n",
    "            verbose=0, warm_start=False)\n",
    "rf.fit(X_train, y_train)\n",
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Ham</th>\n",
       "      <th>Predicted Spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Ham</th>\n",
       "      <td>839</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Spam</th>\n",
       "      <td>60</td>\n",
       "      <td>453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Predicted Ham  Predicted Spam\n",
       "Actual Ham             839              28\n",
       "Actual Spam             60             453"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_cm = confusion_matrix(y_test, rf.predict(X_test))\n",
    "pd.DataFrame(data = rf_cm, columns = ['Predicted Ham', 'Predicted Spam'],\n",
    "            index = ['Actual Ham', 'Actual Spam'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled emails out of a total 1380 emails in test dataset : 88\n",
      "In detail, 28 ham emails are mislabeled as spam, 60 spam emails are mislabeled as ham.\n"
     ]
    }
   ],
   "source": [
    "rf_pred = rf.predict(X_test)\n",
    "print(\"Number of mislabeled emails out of a total %d emails in test dataset : %d\"\n",
    "       % (X_test.shape[0],(y_test != rf_pred).sum()))\n",
    "print(\"In detail, %d ham emails are mislabeled as spam, %d spam emails are mislabeled as ham.\"\n",
    "      % (rf_cm [0,1], rf_cm[1,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can we add the other models to this? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>AdaBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.936232</td>\n",
       "      <td>0.939855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mislabelled</th>\n",
       "      <td>120.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>83.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Decision Tree  Random Forest   AdaBoost\n",
       "Accuracy          0.913043       0.936232   0.939855\n",
       "Mislabelled     120.000000      88.000000  83.000000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reference:https://datawhatnow.com/feature-importance/\n",
    "Conclusion = {'Decision Tree' : [dt.score(X_test, y_test), (y_test != dt_pred).sum()],\n",
    "             'Random Forest' : [rf.score(X_test, y_test), (y_test != rf_pred).sum()],\n",
    "             'AdaBoost' : [ada.score(X_test, y_test), (y_test != ada_pred).sum()],\n",
    "             }\n",
    "pd.DataFrame (Conclusion)\n",
    "pd.DataFrame(Conclusion, index=['Accuracy', 'Mislabelled'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
