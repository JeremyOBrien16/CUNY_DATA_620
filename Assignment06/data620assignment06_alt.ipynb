{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA 620 - Assignment 6\n",
    "\n",
    "Jeremy OBrien, Mael Illien, Vanita Thompson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Classification\n",
    "\n",
    "* It can be useful to be able to classify new \"test\" documents using already classified \"training\" documents. A common example is using a corpus of labeled spam and ham (non-spam) e-mails to predict whether or not a new document is spam. Here is one example of such data:  UCI Machine Learning Repository: Spambase Data Set (http://archive.ics.uci.edu/ml/datasets/Spambase)\n",
    "* For this project, you can either use the above dataset to predict the class of new documents (either withheld from the training dataset or from another source such as your own spam folder).\n",
    "* For more adventurous students, you are welcome (encouraged!) to come up a different set of documents (including scraped web pages!?) that have already been classified (e.g. tagged), then analyze these documents to predict how new documents should be classified.\n",
    "\n",
    "\n",
    "Resources:\n",
    "\n",
    "- http://www.cs.ucf.edu/courses/cap5636/fall2011/nltk.pdf\n",
    "- https://bbengfort.github.io/tutorials/2016/05/19/text-classification-nltk-sckit-learn.html\n",
    "- https://www.cs.bgu.ac.il/~elhadad/nlp16/spam_classifier.html\n",
    "\n",
    "Resource: (can be removed)\n",
    "- https://towardsdatascience.com/tf-idf-for-document-ranking-from-scratch-in-python-on-real-world-dataset-796d339a4089\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "In this assignment, we will look at document classification in the realm of emails with the binary labels 'spam' and 'non-spam', also referred to as 'ham'. The [spamassassin corpus](https://spamassassin.apache.org/old/publiccorpus/) contains individual raw email files which will extracted and processed to form a unified corpus. From this corpus, the data will be split into training and test sets and a variety of models will be developed to identify the best approach to spam email classification. \n",
    "\n",
    "The procedure is as follows:\n",
    "   - Extract emails from raw files\n",
    "   - Process email content to containly only the body of the emails and ignoring all the headers\n",
    "   - Apply NLP methods from NLTK and Sklearn to tokenize the email content into features\n",
    "   - Develop models\n",
    "   - Compare performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from nltk import PorterStemmer\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import & Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ham and spam emails are stored in individual files. The `get_emails` function below extracts the content from file and returns a list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read individual files from current directory and return the content in a list\n",
    "def get_emails(path):\n",
    "    emails = []\n",
    "    files = [path + f for f in listdir(path) if f != 'cmds']\n",
    "\n",
    "    for file in files:\n",
    "        with open(file, encoding=\"latin-1\") as f:\n",
    "            email = f.read()\n",
    "            if len(email) != 0:\n",
    "                emails.append(email) \n",
    "    return emails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the ham and spam corpora are not balanced. We will sample the ham corpus to even out the sizes in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of emails in easy_ham corpus: 2500\n",
      "Number of emails in spam corpus: 500\n"
     ]
    }
   ],
   "source": [
    "easy_ham = get_emails('./easy_ham/')\n",
    "spam = get_emails('./spam/')\n",
    "\n",
    "print('Number of emails in {} corpus: {}'.format('easy_ham', len(easy_ham)))\n",
    "print('Number of emails in {} corpus: {}'.format('spam', len(spam)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of the email format. There are a number of headers followed by the body of the email. Our analysis will be focused on the body content. The function `get_email_body` will be used to extract this content. While it is possible that the ignored headers contain useful data for classification, this will be left for further investigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From rssfeeds@jmason.org  Mon Oct  7 12:05:27 2002\n",
      "Return-Path: <rssfeeds@spamassassin.taint.org>\n",
      "Delivered-To: yyyy@localhost.spamassassin.taint.org\n",
      "Received: from localhost (jalapeno [127.0.0.1])\n",
      "\tby jmason.org (Postfix) with ESMTP id 4123D16F7C\n",
      "\tfor <jm@localhost>; Mon,  7 Oct 2002 12:04:04 +0100 (IST)\n",
      "Received: from jalapeno [127.0.0.1]\n",
      "\tby localhost with IMAP (fetchmail-5.9.0)\n",
      "\tfor jm@localhost (single-drop); Mon, 07 Oct 2002 12:04:04 +0100 (IST)\n",
      "Received: from dogma.slashnull.org (localhost [127.0.0.1]) by\n",
      "    dogma.slashnull.org (8.11.6/8.11.6) with ESMTP id g9780fK23260 for\n",
      "    <jm@jmason.org>; Mon, 7 Oct 2002 09:00:41 +0100\n",
      "Message-Id: <200210070800.g9780fK23260@dogma.slashnull.org>\n",
      "To: yyyy@spamassassin.taint.org\n",
      "From: gamasutra <rssfeeds@spamassassin.taint.org>\n",
      "Subject: Postmortem: Ubi Soft China's Music Up -- Summer Rainbow\n",
      "Date: Mon, 07 Oct 2002 08:00:41 -0000\n",
      "Content-Type: text/plain; encoding=utf-8\n",
      "\n",
      "URL: http://www.newsisfree.com/click/-0,8613667,159/\n",
      "Date: 2002-10-06T18:12:53+01:00\n",
      "\n",
      "Ubi China had always wanted to make a PC game for the local market, but a \n",
      "number to factors kept the idea on hold. In January 2001, the right incentive \n",
      "to motivate Ubi China to try a local project finally arrived: the license for \n",
      "\"Music Up\", a popular animated property.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(easy_ham[2001])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract only the body of the emails, ignoring all the headers\n",
    "def get_email_body(email):\n",
    "    # Looking for the last occurence of Date: Sat, 02 Feb 2002 11:20:17 +1300\\n\n",
    "    iter = re.finditer(r\"Date: .*\\n\", email)\n",
    "    # Otherwise look for repeated \\n\\n patterm\n",
    "\n",
    "    indices = [m.span() for m in iter]\n",
    "    body_start = indices[-1][1]\n",
    "    body = email[body_start:].replace(\"\\n\", \"\")\n",
    "\n",
    "    return body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ubi China had always wanted to make a PC game for the local market, but a number to factors kept the idea on hold. In January 2001, the right incentive to motivate Ubi China to try a local project finally arrived: the license for \"Music Up\", a popular animated property.\n"
     ]
    }
   ],
   "source": [
    "print(get_email_body(easy_ham[2001]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `get_email_body` function is applied to the emails and the corpus is assembled by combining the spam emails with 500 emails sampled from the ham emails to balance the dataset. Known labels ham: 0, spam:1 are also assigned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1000 emails in this corpus.\n"
     ]
    }
   ],
   "source": [
    "# Assemble the corpus by combining the spam emails with 500 emails sampled from the \n",
    "# ham emails to balance the dataset and assign the known labels ham: 0, spam:1\n",
    "random.seed(620)\n",
    "labeled_emails = ([(get_email_body(em), '0') for em in random.choices(easy_ham, k=500)] + \n",
    "                    [(get_email_body(em), '1') for em in spam])\n",
    "\n",
    "print('There are {} emails in this corpus.'.format(len(labeled_emails)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing\n",
    "\n",
    "There are a number of NLP methods to process text including tokenizing, case normalization, stopword removal, stemming and lemmatization.\n",
    "\n",
    "The manual pre-processing section below highlights some of the functionality described above on a sample email. These steps will be encapsulated in the function `process_email_body` with parameters allowing for more control over the processing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"In a message dated 9/24/2002 11:24:58 AM, jamesr@best.com writes:>This situation wouldn't have happened in the first place if California>didn't have economically insane regulations.  They created a regulatory>climate that facilitated this.  So yes, it is the product of>over-regulation.>Which is to say, if you reduce the argument to absurdity, that law causes crime. (Yes, I agree that badly written law can make life so frustrating that people have little choice but to subvery it if they want to get anything done. This is also true of corporate policies, and all other attempts to regulate conduct by rules. Rules just don't work well when situations are fluid or ambiguous. But I don't think that the misbehavior of energy companies in California can properly be called well-intentioned lawbreaking by parties who were trying to do the right thing but could do so only by falling afoul of some technicality.)If you want to get to root causes, we should probably go to the slaying of Abel by Cain. Perhaps we can figure out what went wrong then, and roll our learning forward through history and create a FoRKtopia.Nonpartisanly, which is to say casting stones on all houses, whether bicameral or unicameral, built on sand or on rock, to the left of them or to the right of them, of glass or brick or twig or straw, Tom\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_email_body(easy_ham[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['In', 'a', 'message', 'dated', '9/24/2002', '11:24:58', 'AM', ',', 'jamesr', '@']\n"
     ]
    }
   ],
   "source": [
    "# Tokenize\n",
    "tokens = word_tokenize(get_email_body(easy_ham[0]))\n",
    "print(tokens[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223\n",
      "['in', 'a', 'message', 'dated', 'am', 'jamesr', 'writes', 'this', 'situation', 'would']\n"
     ]
    }
   ],
   "source": [
    "# Normalize\n",
    "word_tokens = [w.lower() for w in tokens if w.isalpha()] \n",
    "print(len(word_tokens))\n",
    "print(word_tokens[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107\n",
      "['message', 'dated', 'jamesr', 'writes', 'situation', 'would', 'happened', 'first', 'place', 'california']\n"
     ]
    }
   ],
   "source": [
    "# Stopword removal \n",
    "stop_words = stopwords.words('english')\n",
    "filtered_words = [w for w in word_tokens if not w in stop_words]\n",
    "print(len(filtered_words))\n",
    "print(filtered_words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['messag', 'date', 'jamesr', 'write', 'situat', 'would', 'happen', 'first', 'place', 'california', 'econom', 'insan', 'regul', 'creat', 'regulatori', 'climat', 'facilit', 'ye', 'product', 'say']\n"
     ]
    }
   ],
   "source": [
    "# Stemming\n",
    "porter = PorterStemmer()\n",
    "stemmed_words = [porter.stem(t) for t in filtered_words]\n",
    "print(stemmed_words[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual pre-processing (encapsulated):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As described above, the function `process_email_body` can be applied to each email in order to turn the content of the emails into useable features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process email: tokenize, remove non-alpha characters, remove stop words, stem, lemmatize\n",
    "# and return a list of tokens\n",
    "def process_email_body(email, alpha=True, rm_stopwords=True, stem=True, lemma=False):\n",
    "    tokens = word_tokenize(email)\n",
    "    if alpha: tokens = [w.lower() for w in tokens if w.isalpha()] \n",
    "    if rm_stopwords: \n",
    "        stop_words = stopwords.words('english')\n",
    "        tokens = [w for w in tokens if not w in stop_words]\n",
    "    if stem:\n",
    "        porter = PorterStemmer()\n",
    "        tokens = [porter.stem(t) for t in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['messag', 'date', 'jamesr', 'write', 'situat', 'would', 'happen', 'first', 'place', 'california', 'econom', 'insan', 'regul', 'creat', 'regulatori', 'climat', 'facilit', 'ye', 'product', 'say', 'reduc', 'argument', 'absurd', 'law', 'caus', 'crime', 'ye', 'agre', 'badli', 'written', 'law', 'make', 'life', 'frustrat', 'peopl', 'littl', 'choic', 'subveri', 'want', 'get', 'anyth', 'done', 'also', 'true', 'corpor', 'polici', 'attempt', 'regul', 'conduct', 'rule', 'rule', 'work', 'well', 'situat', 'fluid', 'ambigu', 'think', 'misbehavior', 'energi', 'compani', 'california', 'properli', 'call', 'lawbreak', 'parti', 'tri', 'right', 'thing', 'could', 'fall', 'afoul', 'technic', 'want', 'get', 'root', 'caus', 'probabl', 'go', 'slay', 'abel', 'cain', 'perhap', 'figur', 'went', 'wrong', 'roll', 'learn', 'forward', 'histori', 'creat', 'say', 'cast', 'stone', 'hous', 'whether', 'bicamer', 'unicamer', 'built', 'sand', 'rock', 'left', 'right', 'glass', 'brick', 'twig', 'straw', 'tom']\n"
     ]
    }
   ],
   "source": [
    "# Example above revisited using the function\n",
    "print(process_email_body(get_email_body(easy_ham[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Consider additional feature engineering?\n",
    "\n",
    "MI: incorporate this into text if needed\n",
    "\n",
    "- number of tokens, etc.\n",
    "- presence of word 'unsubscribe'\n",
    "\n",
    "For feature engineering, what would you say to the following combinations:\n",
    "\n",
    "- yes case normalization, yes symbol removal, yes stopword removal, then stem\n",
    "- yes case normalization, yes symbol removal, no stopword removal, then stem\n",
    "- yes case normalization, no symbol removal, no stopword removal, then stem\n",
    "- no case normalization, no symbol removal, no stopword removal, then stem\n",
    "  \n",
    "  \n",
    "- yes case normalization, yes symbol removal, yes stopword removal, then lemmatize\n",
    "- yes case normalization, yes symbol removal, no stopword removal, then lemmatize\n",
    "- yes case normalization, no symbol removal, no stopword removal, then lemmatize\n",
    "- no case normalization, no symbol removal, no stopword removal, then lemmatize\n",
    "  \n",
    "  \n",
    "- yes case normalization, yes symbol removal, yes stopword removal, no stem / lemmatize\n",
    "- yes case normalization, yes symbol removal, no stopword removal, no stem / lemmatize\n",
    "- yes case normalization, no symbol removal, no stopword removal, no stem / lemmatize\n",
    "- no case normalization, no symbol removal, no stopword removal, no stem / lemmatize\n",
    "  \n",
    "Then once we've determine the best performer, we can implement some sort of error correction to see if that improves it.\n",
    "\n",
    "Then we can try versions of the best performer that are noun-only or verb-only (with the settings above, so long as not contradictory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, run time becomes excessive when emails processed with the manual approach are vectorized and the transformation applied to the emails using the code block below. For this reason, we will rely on the efficiency of the built-in pre-processor of the sklearn library for the remainder of the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: manual pre-processing (takes a long time to run)\n",
    "\n",
    "# emails = [process_email_body(email) for email in labeled_emails] # X\n",
    "# y = [label for (email, label) in labeled_emails] # y = labels\n",
    "\n",
    "# vectorizer = TfidfVectorizer()\n",
    "# X = vectorizer.fit_transform(emails) # run time takes too long."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing using sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sklearn `TfidfVectorizer` object allows us to apply the same processing steps that we manually outlined below via the function paramters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2\n",
    "# Refer to https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
    "\n",
    "emails = [email for (email, label) in labeled_emails] # X = emails features (see below)\n",
    "y = [label for (email, label) in labeled_emails] # y = labels\n",
    "\n",
    "vectorizer = TfidfVectorizer(lowercase=True, stop_words='english', token_pattern = r'[a-zA-Z]+', max_features=1000)\n",
    "\n",
    "X = vectorizer.fit_transform(emails)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a look as some of the features returned by the vectorizer, we find english words such as 'address' or 'advertising' but also a number of html tags such as 'cellpadding' or 'bgcolor' which are often typical of spam emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aa', 'ab', 'able', 'absolutely', 'ac', 'accept', 'access', 'account', 'act', 'action', 'actually', 'ad', 'adclick', 'add', 'additional', 'address', 'addresses', 'admanmail', 'admin', 'ads', 'adult', 'advertising', 'ae', 'af', 'ag', 'age', 'agent', 'agents', 'ago', 'ahref', 'aid', 'al', 'align', 'allow', 'alsa', 'alt', 'alternative', 'america', 'american', 'amp', 'annuity', 'answer', 'application', 'apply', 'archive', 'area', 'arial', 'article', 'ascii', 'asciicontent', 'ask', 'asp', 'assist', 'assistance', 'atoll', 'au', 'aug', 'available', 'average', 'aw', 'away', 'awr', 'b', 'ba', 'background', 'bad', 'bank', 'banners', 'base', 'based', 'bb', 'bc', 'beenthere', 'begin', 'believe', 'benefit', 'best', 'better', 'bgcolor', 'bidi', 'big', 'bin', 'bindex', 'bit', 'bitx', 'black', 'blank', 'blockquote', 'blue', 'body', 'bonus', 'book', 'border', 'bordercolor', 'boundary', 'box', 'br', 'build', 'bulk', 'bulklist', 'bush', 'business', 'businesses', 'buy', 'c', 'ca', 'called', 'came', 'campaign', 'canada', 'capital', 'car', 'card', 'care', 'case', 'cash', 'cb', 'cc', 'cccccc', 'cd', 'cdo', 'ce', 'cellpadding', 'cellspacing', 'center', 'cf', 'cfm', 'cgi', 'ch', 'change', 'charge', 'charset', 'check', 'city', 'cj', 'ck', 'claim', 'class', 'classes', 'clean', 'clear', 'click', 'client', 'clients', 'cm', 'cn', 'cna', 'code', 'collapse', 'color', 'colspan', 'com', 'comcast', 'comcontent', 'come', 'comes', 'coming', 'comments', 'commission', 'communication', 'communications', 'companies', 'company', 'complete', 'computer', 'comsubject', 'contact', 'contains', 'content', 'continue', 'control', 'copy', 'cost', 'country', 'courier', 'course', 'cr', 'create', 'credit', 'current', 'currently', 'customer', 'customers', 'd', 'da', 'daily', 'darial', 'data', 'database', 'date', 'day', 'days', 'dc', 'dcenter', 'dd', 'deal', 'dear', 'death', 'decided', 'decoration']\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.get_feature_names()[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1000)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "In this section, a number of models are examined including two Naive Bayes approaches (Gaussian & Bernoulli), Decision Trees, SVM, Adaptive Boosting and Random Forests.\n",
    "\n",
    "The dataset is split into test and training sets and evualted using a number of models in the section that follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=21)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=21, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below will be used to display summaries of each model. It also returns the model and accuracy measures for further use in a summary dataframe. \n",
    "\n",
    "Given for a spam detection use case:\n",
    "- the cost of false positives are high (i.e. misclassifying a legitimate email as spam would mean a use loses a valid communication which could be very important);\n",
    "- the cost of false negatives are low (i.e. the inconvenience of junk emails or risk of unwittingly clicking on malicious links;\n",
    "- and, therefore, there's little need to balance between two;\n",
    "\n",
    "Precision is a better metric to focus on for the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [] # holds model and accuracy information\n",
    "\n",
    "def build_and_score_model(model, model_name, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    # Predict on test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Training set accuracy\n",
    "    train_acc = model.score(X_train,y_train)\n",
    "    print('Model training set accuracy: {} \\n'.format(train_acc))\n",
    "    \n",
    "    # Testing set accuracy\n",
    "    test_acc = model.score(X_test, y_test)\n",
    "    print('Model test set accuracy: {} \\n'.format(test_acc))\n",
    "    \n",
    "    # Precision\n",
    "    precision = classification_report(y_test, y_pred, output_dict=True)['1']['precision']\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    cm = pd.DataFrame(data = cm, columns = ['Predicted Ham', 'Predicted Spam'],\n",
    "            index = ['Actual Ham', 'Actual Spam'])\n",
    "    print(cm)\n",
    "    print('\\n')\n",
    "          \n",
    "    print(classification_report(y_test, y_pred, target_names=['ham','spam']))\n",
    "    \n",
    "    models.append([model_name, model, test_acc, precision])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes - Gaussian\n",
    "\n",
    "In this model, the likelihood of the features is assumed to be Gaussian and is typically better suited for continuous data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required because of complaint about the matrix being too sparse\n",
    "X_train = X_train.toarray()\n",
    "X_test = X_test.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate and train Gaussian Naive Bayes model\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The precision of the Gaussian Naive Bayes classifier is 0.92, and it misidentifies 10 spam emails as ham and 12 ham emails as spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training set accuracy: 0.98 \n",
      "\n",
      "Model test set accuracy: 0.9266666666666666 \n",
      "\n",
      "             Predicted Ham  Predicted Spam\n",
      "Actual Ham             134              12\n",
      "Actual Spam             10             144\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.93      0.92      0.92       146\n",
      "        spam       0.92      0.94      0.93       154\n",
      "\n",
      "    accuracy                           0.93       300\n",
      "   macro avg       0.93      0.93      0.93       300\n",
      "weighted avg       0.93      0.93      0.93       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "build_and_score_model(gnb, 'NaiveBayesGaussian', X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes - Bernoulli\n",
    "\n",
    "This Bernoulli Naive Bayes model assumes that all our features are binary meaning that either the feature does, or does not appear in the document. This kind of model typically performs better on shorted documents, like emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate and train Gaussian Naive Bayes model\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The precision of the Bernoulli Naive Bayes classifier is 0.97, and it misidentifies 25 spam emails as ham and 4 ham emails as spam. While this model allowed for more spam emails to be classified as ham than the above, there were less actual ham emails classified as spam. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training set accuracy: 0.9057142857142857 \n",
      "\n",
      "Model test set accuracy: 0.9033333333333333 \n",
      "\n",
      "             Predicted Ham  Predicted Spam\n",
      "Actual Ham             142               4\n",
      "Actual Spam             25             129\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.85      0.97      0.91       146\n",
      "        spam       0.97      0.84      0.90       154\n",
      "\n",
      "    accuracy                           0.90       300\n",
      "   macro avg       0.91      0.91      0.90       300\n",
      "weighted avg       0.91      0.90      0.90       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "build_and_score_model(bnb, 'NaiveBayesBernoulli', X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of the two Naive Bayes model, the Bernoulli had a slightly lower accuracy but higher precision. For a real email classifier, this is a better result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=1e-07, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=88, splitter='best')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
    "    max_features=None, max_leaf_nodes=None,\n",
    "    min_impurity_decrease=1e-07, min_samples_leaf=1,\n",
    "    min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "    random_state=88, splitter='best')\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Decision Tree model is an improvement on the Naive Bayes classifiers both in terms of accuracy with a score of 0.96 and in terms of precision which reaches 0.97. Classification errors both for ham and spam emails were also reduced with only 4 ham emails classified as spam and 8 spam classified as ham."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training set accuracy: 1.0 \n",
      "\n",
      "Model test set accuracy: 0.96 \n",
      "\n",
      "             Predicted Ham  Predicted Spam\n",
      "Actual Ham             142               4\n",
      "Actual Spam              8             146\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.95      0.97      0.96       146\n",
      "        spam       0.97      0.95      0.96       154\n",
      "\n",
      "    accuracy                           0.96       300\n",
      "   macro avg       0.96      0.96      0.96       300\n",
      "weighted avg       0.96      0.96      0.96       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "build_and_score_model(dt, 'DecisionTree', X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machines is a classifier which makes use of a 'kernel trick' to efficiently transform data to a new space in which the margin between different classes can be maximized using a hyperplane.\n",
    "\n",
    "We employ two common kernels - **linear** and **radial basis function (RBF)** - to evaluate their respective performance.\n",
    "\n",
    "SVM kernels take different parameters depending on the kernel type.  The *C* parameter is a regularization term that penalizes misclassification (i.e. a lower value imposes a softer class boundary, or higher value a harder), and it is used for both linear and RBF kernels.  The RBF kernel also takes a *gamma* parameter, which controls the distance over which a given training example influences the boundary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a function to perform a grid search to identify good candidates for *C* (for linear and RBF) and gamma (for RBF only) parameters.  Due to computational load, we limit the cross validation to five folds (optimally this would be 10.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure grid search for hyperparameter tuning at exponential increments\n",
    "def svm_tune_grid(X, y, kernel, nfolds):\n",
    "    \n",
    "    C = [.0001,.001,.01,.1,1,10]\n",
    "    gamma = [.0001,.001,.01,.1,1,10]\n",
    "    \n",
    "    # For linear kernels\n",
    "    if kernel == 'linear':\n",
    "        param_grid = {'C': C}\n",
    "        grid_search = GridSearchCV(svm.SVC(kernel=kernel), \n",
    "                                   param_grid, \n",
    "                                   cv=nfolds)\n",
    "    \n",
    "    # For RBF kernels\n",
    "    elif kernel == 'rbf':\n",
    "        param_grid = {'C': C, 'gamma': gamma}\n",
    "        grid_search = GridSearchCV(svm.SVC(kernel=kernel), \n",
    "                                   param_grid, \n",
    "                                   cv=nfolds)\n",
    "    \n",
    "    # Other kernels are not supported by this function\n",
    "    else:\n",
    "        print('Kernel not recognized or supported')\n",
    "        return\n",
    "    \n",
    "    grid_search.fit(X,y)\n",
    "    grid_search.best_params_\n",
    "    \n",
    "    return grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grid search for optimal C and gamma in linear kernel\n",
    "svm_tune_grid(X_train, y_train, 'linear', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'gamma': 0.1}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grid search for optimal C and gamma in radial basis function kernel\n",
    "svm_tune_grid(X_train, y_train, 'rbf', 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the grid search returned an optimal *C* value of 10 for both kernels, and a *gamma* value of 1 for the RBF kernel, we fit the two versions of the SVM classifier accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we fit an SVM classifier with linear kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit SVM classifier with linear kernel on training set\n",
    "svm_lin = svm.SVC(C=10,  # identified by grid search\n",
    "               kernel='linear')\n",
    "svm_lin.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The precision of the linear kernel SVM classifier is 0.97, and it only misidentifies five spam emails as ham and five ham emails as spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training set accuracy: 1.0 \n",
      "\n",
      "Model test set accuracy: 0.9766666666666667 \n",
      "\n",
      "             Predicted Ham  Predicted Spam\n",
      "Actual Ham             144               2\n",
      "Actual Spam              5             149\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      0.99      0.98       146\n",
      "        spam       0.99      0.97      0.98       154\n",
      "\n",
      "    accuracy                           0.98       300\n",
      "   macro avg       0.98      0.98      0.98       300\n",
      "weighted avg       0.98      0.98      0.98       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "build_and_score_model(svm_lin, 'SVMLinearKernel', X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we fit an SVM classifier with an RBF kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf', max_iter=-1,\n",
       "    probability=False, random_state=None, shrinking=True, tol=0.001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit SVM classifier with RBF kernel on training set\n",
    "svm_rbf = svm.SVC(C=10,  # identified by grid search\n",
    "               kernel='rbf',\n",
    "                 gamma=1)  # identified by grid search\n",
    "svm_rbf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The precision of the RBF kernel SVM classifier is 0.98, and it only misidentifies four spam emails as ham and three ham emails as spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training set accuracy: 1.0 \n",
      "\n",
      "Model test set accuracy: 0.97 \n",
      "\n",
      "             Predicted Ham  Predicted Spam\n",
      "Actual Ham             144               2\n",
      "Actual Spam              7             147\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.95      0.99      0.97       146\n",
      "        spam       0.99      0.95      0.97       154\n",
      "\n",
      "    accuracy                           0.97       300\n",
      "   macro avg       0.97      0.97      0.97       300\n",
      "weighted avg       0.97      0.97      0.97       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "build_and_score_model(svm_rbf, 'SVMRBFKernel', X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of the two SVM classifiers, the RBF kernel performs incrementally better than the linear kernel.  This means that a non-linear boundary in the hyperplane better distinguishes between the two classes.  As we encountered at runtime, the RBF kernel requires greater computational resources, and its incrementally better performance should be weighed against it's cost.  This is particularly true if a model like this is being deploued into production and scaled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptive Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
       "                   n_estimators=50, random_state=88)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada = AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
    "          learning_rate=1.0, n_estimators=50, random_state=88)\n",
    "ada.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Adaptive Boosting model rivals the SVM models on precision and accuracy with only 9 errors: 2 ham emails classified as spam and 7 spam emails classified as ham."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training set accuracy: 1.0 \n",
      "\n",
      "Model test set accuracy: 0.97 \n",
      "\n",
      "             Predicted Ham  Predicted Spam\n",
      "Actual Ham             144               2\n",
      "Actual Spam              7             147\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.95      0.99      0.97       146\n",
      "        spam       0.99      0.95      0.97       154\n",
      "\n",
      "    accuracy                           0.97       300\n",
      "   macro avg       0.97      0.97      0.97       300\n",
      "weighted avg       0.97      0.97      0.97       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "build_and_score_model(ada, 'AdaptiveBoosting', X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=1e-07, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "                       oob_score=False, random_state=88, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=1e-07, min_samples_leaf=1,\n",
    "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "            n_estimators=10, n_jobs=1, oob_score=False, random_state=88,\n",
    "            verbose=0, warm_start=False)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Random Forest model achieves 0.99 precision which is the highest score so far. Only a single ham email is classified as spam. The accuracy of 0.963 is slightly lower than the SVM models due the the 10 spam emails incorrectly classified as ham. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training set accuracy: 0.9985714285714286 \n",
      "\n",
      "Model test set accuracy: 0.9633333333333334 \n",
      "\n",
      "             Predicted Ham  Predicted Spam\n",
      "Actual Ham             145               1\n",
      "Actual Spam             10             144\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.94      0.99      0.96       146\n",
      "        spam       0.99      0.94      0.96       154\n",
      "\n",
      "    accuracy                           0.96       300\n",
      "   macro avg       0.96      0.96      0.96       300\n",
      "weighted avg       0.97      0.96      0.96       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "build_and_score_model(rf, 'RandomForest', X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The `models` list that stored the models and performance metrics is unfolded to summarize the findings of this investigation in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_models(models):\n",
    "    table = pd.DataFrame(columns = ['model', 'acc_test', 'precision'])\n",
    "    \n",
    "    for m in models:\n",
    "        df = pd.DataFrame({'model': [m[0]], 'acc_test': [m[2]], 'precision': [m[3]]})\n",
    "        table = table.append(df, ignore_index=True)\n",
    "\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_5666a0ba_c711_11ea_8bb4_784f434fb9dcrow0_col1 {\n",
       "            background-color:  #b0d2e7;\n",
       "            color:  #000000;\n",
       "        }    #T_5666a0ba_c711_11ea_8bb4_784f434fb9dcrow0_col2 {\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }    #T_5666a0ba_c711_11ea_8bb4_784f434fb9dcrow1_col1 {\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }    #T_5666a0ba_c711_11ea_8bb4_784f434fb9dcrow1_col2 {\n",
       "            background-color:  #3686c0;\n",
       "            color:  #000000;\n",
       "        }    #T_5666a0ba_c711_11ea_8bb4_784f434fb9dcrow2_col1 {\n",
       "            background-color:  #1c6bb0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_5666a0ba_c711_11ea_8bb4_784f434fb9dcrow2_col2 {\n",
       "            background-color:  #2a7ab9;\n",
       "            color:  #000000;\n",
       "        }    #T_5666a0ba_c711_11ea_8bb4_784f434fb9dcrow3_col1 {\n",
       "            background-color:  #08306b;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_5666a0ba_c711_11ea_8bb4_784f434fb9dcrow3_col2 {\n",
       "            background-color:  #08488e;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_5666a0ba_c711_11ea_8bb4_784f434fb9dcrow4_col1 {\n",
       "            background-color:  #08488e;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_5666a0ba_c711_11ea_8bb4_784f434fb9dcrow4_col2 {\n",
       "            background-color:  #08488e;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_5666a0ba_c711_11ea_8bb4_784f434fb9dcrow5_col1 {\n",
       "            background-color:  #08488e;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_5666a0ba_c711_11ea_8bb4_784f434fb9dcrow5_col2 {\n",
       "            background-color:  #08488e;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_5666a0ba_c711_11ea_8bb4_784f434fb9dcrow6_col1 {\n",
       "            background-color:  #135fa7;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_5666a0ba_c711_11ea_8bb4_784f434fb9dcrow6_col2 {\n",
       "            background-color:  #08306b;\n",
       "            color:  #f1f1f1;\n",
       "        }</style><table id=\"T_5666a0ba_c711_11ea_8bb4_784f434fb9dc\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >model</th>        <th class=\"col_heading level0 col1\" >acc_test</th>        <th class=\"col_heading level0 col2\" >precision</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_5666a0ba_c711_11ea_8bb4_784f434fb9dclevel0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_5666a0ba_c711_11ea_8bb4_784f434fb9dcrow0_col0\" class=\"data row0 col0\" >NaiveBayesGaussian</td>\n",
       "                        <td id=\"T_5666a0ba_c711_11ea_8bb4_784f434fb9dcrow0_col1\" class=\"data row0 col1\" >0.926667</td>\n",
       "                        <td id=\"T_5666a0ba_c711_11ea_8bb4_784f434fb9dcrow0_col2\" class=\"data row0 col2\" >0.923077</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5666a0ba_c711_11ea_8bb4_784f434fb9dclevel0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_5666a0ba_c711_11ea_8bb4_784f434fb9dcrow1_col0\" class=\"data row1 col0\" >NaiveBayesBernoulli</td>\n",
       "                        <td id=\"T_5666a0ba_c711_11ea_8bb4_784f434fb9dcrow1_col1\" class=\"data row1 col1\" >0.903333</td>\n",
       "                        <td id=\"T_5666a0ba_c711_11ea_8bb4_784f434fb9dcrow1_col2\" class=\"data row1 col2\" >0.969925</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5666a0ba_c711_11ea_8bb4_784f434fb9dclevel0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_5666a0ba_c711_11ea_8bb4_784f434fb9dcrow2_col0\" class=\"data row2 col0\" >DecisionTree</td>\n",
       "                        <td id=\"T_5666a0ba_c711_11ea_8bb4_784f434fb9dcrow2_col1\" class=\"data row2 col1\" >0.960000</td>\n",
       "                        <td id=\"T_5666a0ba_c711_11ea_8bb4_784f434fb9dcrow2_col2\" class=\"data row2 col2\" >0.973333</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5666a0ba_c711_11ea_8bb4_784f434fb9dclevel0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_5666a0ba_c711_11ea_8bb4_784f434fb9dcrow3_col0\" class=\"data row3 col0\" >SVMLinearKernel</td>\n",
       "                        <td id=\"T_5666a0ba_c711_11ea_8bb4_784f434fb9dcrow3_col1\" class=\"data row3 col1\" >0.976667</td>\n",
       "                        <td id=\"T_5666a0ba_c711_11ea_8bb4_784f434fb9dcrow3_col2\" class=\"data row3 col2\" >0.986755</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5666a0ba_c711_11ea_8bb4_784f434fb9dclevel0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_5666a0ba_c711_11ea_8bb4_784f434fb9dcrow4_col0\" class=\"data row4 col0\" >SVMRBFKernel</td>\n",
       "                        <td id=\"T_5666a0ba_c711_11ea_8bb4_784f434fb9dcrow4_col1\" class=\"data row4 col1\" >0.970000</td>\n",
       "                        <td id=\"T_5666a0ba_c711_11ea_8bb4_784f434fb9dcrow4_col2\" class=\"data row4 col2\" >0.986577</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5666a0ba_c711_11ea_8bb4_784f434fb9dclevel0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_5666a0ba_c711_11ea_8bb4_784f434fb9dcrow5_col0\" class=\"data row5 col0\" >AdaptiveBoosting</td>\n",
       "                        <td id=\"T_5666a0ba_c711_11ea_8bb4_784f434fb9dcrow5_col1\" class=\"data row5 col1\" >0.970000</td>\n",
       "                        <td id=\"T_5666a0ba_c711_11ea_8bb4_784f434fb9dcrow5_col2\" class=\"data row5 col2\" >0.986577</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5666a0ba_c711_11ea_8bb4_784f434fb9dclevel0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_5666a0ba_c711_11ea_8bb4_784f434fb9dcrow6_col0\" class=\"data row6 col0\" >RandomForest</td>\n",
       "                        <td id=\"T_5666a0ba_c711_11ea_8bb4_784f434fb9dcrow6_col1\" class=\"data row6 col1\" >0.963333</td>\n",
       "                        <td id=\"T_5666a0ba_c711_11ea_8bb4_784f434fb9dcrow6_col2\" class=\"data row6 col2\" >0.993103</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x10bdd6e50>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = summarize_models(models)\n",
    "table.style.background_gradient(cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here two principal metrics are used to determine how 'good' a model is. SVM based models turned out to be the most accurate. However, as stated earlier, a spam email classifier is more concerned with penalizing misclassifications of ham emails as spam while being more tolerant of the occasional spam email going through to the ham box. The precision metric revealed that the Random Forest model was the most precise with only a single ham email classified as spam.\n",
    "\n",
    "Both of these models are the best in their own way and they are select below by index. \n",
    "\n",
    "Based on the consistenly high scores in both test set accuracy and precision, the SVMLinearKernel delivers the best overall performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_accurate_model = models[3][1] # Select the best model by index from the table above\n",
    "most_accurate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=1e-07, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "                       oob_score=False, random_state=88, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_precise_model = models[6][1] # Select the best model by index from the table above\n",
    "most_precise_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To quickly examine why the Random Forest model was so precise in identifying spam emails correctly, we take a look at the most importance features. We can regognize the majority of these features as HTML tags. This tell us that spam emails are easily identifiable by the amount of HTML present in the body of an email which differentiates them from emails whose bodies are simply plain text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_importance = [i for i in zip(vectorizer.get_feature_names(), most_precise_model.feature_importances_)]\n",
    "feature_importance_20 = sorted(feature_importance, key = lambda x: x[1], reverse=True)[:20]\n",
    "features = [f for (f, i) in feature_importance_20]\n",
    "importance = [i for (f, i) in feature_importance_20]\n",
    "plt.figure(figsize=(18, 8))\n",
    "plt.yscale('log', nonposy='clip')\n",
    "plt.bar(range(len(importance)), importance, align='center')\n",
    "plt.xticks(range(len(importance)), features, rotation='vertical', color = 'blue')\n",
    "plt.title('Top 20 Importance Features for Most Precise Model')\n",
    "plt.ylabel('Importance')\n",
    "plt.xlabel('Feature Variables')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
