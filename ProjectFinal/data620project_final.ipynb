{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA 620 - Final Project\n",
    "\n",
    "Jeremy OBrien, Mael Illien, Vanita Thompson\n",
    "\n",
    "## Topic Modeling and Network Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "A powerful analytical application of NLP is topic modeling, which identifies the themes present in a corpus comprised of multiple documents based on the words in those documents. Because it can be used to uncover the thematic structure in documents, topic modeling has an array of applications in information retrieval and document mining.\n",
    "\n",
    "Topics are 'probability distributions over a fixed vocabulary'. An overview of topic modeling and its current applications in bioinformatics, and it's common to use probabilistic generative models derived from LDA (Latent Dirichlet Allocation) to model in an unsupervised fashion the latent semantic structure of documents. Topic models can be tuned and optimized in a variety of ways, including improving how topics are segregated from each other and calibrating for a useful number of topics.\n",
    "\n",
    "### Research Question\n",
    "\n",
    "We will combine techniques from topic modeling and network analysis to address this question.\n",
    "\n",
    "*Given a text corpus comprised of multiple documents, what are the topics of those documents and how are the documents thematically related to one another?*\n",
    "\n",
    "### Approach\n",
    "\n",
    "- Leverage the Reuters news corpus of nearly 11,000 articles (labeled with at least one category each; unfortunately, authorship is not labeled)\n",
    "- Using the NLTK, Spacy, and Gensim packages, implement and tune an unsupervised LDA-based topic model (i.e. without reference to the provided article topic labels)\n",
    "- Analyze model perplexity and coherence, overall topic prevalence, and topic distribution across articles\n",
    "- Generate a bipartite, weighted (on likelyhood of belonging to the most domiant topic) graph of articles and topics, and analyze its topology to identify relationships between topics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "np.random.seed(12321)\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import reuters\n",
    "\n",
    "import spacy  # need to install\n",
    "\n",
    "import gensim  # need to install\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "# warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# NLTK Reuters corpus\n",
    "from nltk.corpus import reuters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import & Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data import and preliminary EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per the NLTK Reuters README (accessible via `reuters.readme()`), this corpus include 10,788 article from the Reuters financial newswire service.  While it is partitioned into training and test sets, we will not be making use of these splits for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_4eda1e46_ca2f_11ea_b6b7_784f434fb9dc\" ><thead>    <tr>        <th class=\"col_heading level0 col0\" >Article</th>        <th class=\"col_heading level0 col2\" >Category</th>        <th class=\"col_heading level0 col3\" >Text</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_4eda1e46_ca2f_11ea_b6b7_784f434fb9dcrow0_col0\" class=\"data row0 col0\" >14826</td>\n",
       "                                <td id=\"T_4eda1e46_ca2f_11ea_b6b7_784f434fb9dcrow0_col2\" class=\"data row0 col2\" >['trade']</td>\n",
       "                        <td id=\"T_4eda1e46_ca2f_11ea_b6b7_784f434fb9dcrow0_col3\" class=\"data row0 col3\" >ASIAN EXPORTERS FEAR DAMAGE FROM U.S.-JAPAN RIFT\n",
       "  Mounting trade friction between the\n",
       "  U.S. And Japan has raised fears amon</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_4eda1e46_ca2f_11ea_b6b7_784f434fb9dcrow1_col0\" class=\"data row1 col0\" >14828</td>\n",
       "                                <td id=\"T_4eda1e46_ca2f_11ea_b6b7_784f434fb9dcrow1_col2\" class=\"data row1 col2\" >['grain']</td>\n",
       "                        <td id=\"T_4eda1e46_ca2f_11ea_b6b7_784f434fb9dcrow1_col3\" class=\"data row1 col3\" >CHINA DAILY SAYS VERMIN EAT 7-12 PCT GRAIN STOCKS\n",
       "  A survey of 19 provinces and seven cities\n",
       "  showed vermin consume between</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_4eda1e46_ca2f_11ea_b6b7_784f434fb9dcrow2_col0\" class=\"data row2 col0\" >14829</td>\n",
       "                                <td id=\"T_4eda1e46_ca2f_11ea_b6b7_784f434fb9dcrow2_col2\" class=\"data row2 col2\" >['crude', 'nat-gas']</td>\n",
       "                        <td id=\"T_4eda1e46_ca2f_11ea_b6b7_784f434fb9dcrow2_col3\" class=\"data row2 col3\" >JAPAN TO REVISE LONG-TERM ENERGY DEMAND DOWNWARDS\n",
       "  The Ministry of International Trade and\n",
       "  Industry (MITI) will revise its</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_4eda1e46_ca2f_11ea_b6b7_784f434fb9dcrow3_col0\" class=\"data row3 col0\" >14832</td>\n",
       "                                <td id=\"T_4eda1e46_ca2f_11ea_b6b7_784f434fb9dcrow3_col2\" class=\"data row3 col2\" >['corn', 'grain', 'rice', 'rubber', 'sugar', 'tin', 'trade']</td>\n",
       "                        <td id=\"T_4eda1e46_ca2f_11ea_b6b7_784f434fb9dcrow3_col3\" class=\"data row3 col3\" >THAI TRADE DEFICIT WIDENS IN FIRST QUARTER\n",
       "  Thailand's trade deficit widened to 4.5\n",
       "  billion baht in the first quarter of 1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_4eda1e46_ca2f_11ea_b6b7_784f434fb9dcrow4_col0\" class=\"data row4 col0\" >14833</td>\n",
       "                                <td id=\"T_4eda1e46_ca2f_11ea_b6b7_784f434fb9dcrow4_col2\" class=\"data row4 col2\" >['palm-oil', 'veg-oil']</td>\n",
       "                        <td id=\"T_4eda1e46_ca2f_11ea_b6b7_784f434fb9dcrow4_col3\" class=\"data row4 col3\" >INDONESIA SEES CPO PRICE RISING SHARPLY\n",
       "  Indonesia expects crude palm oil (CPO)\n",
       "  prices to rise sharply to between 450 and </td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x120b3dc10>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate dataframe of Reuters\n",
    "news = []\n",
    "for fileid in reuters.fileids():\n",
    "    tag, filename = fileid.split('/')\n",
    "    news.append((filename, tag, reuters.categories(fileid), reuters.raw(fileid)))\n",
    "df = pd.DataFrame(news, columns=['Article', 'Tag', 'Category', 'Text'])\n",
    "\n",
    "# Peek at Reuters data frame\n",
    "df.head(5).apply(lambda x: x.str.slice(0, 125)).style.hide_index().hide_columns(['Tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Article Count</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>earn</td>\n",
       "      <td>3964</td>\n",
       "      <td>0.297419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>acq</td>\n",
       "      <td>2369</td>\n",
       "      <td>0.177746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>money-fx</td>\n",
       "      <td>717</td>\n",
       "      <td>0.053797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>grain</td>\n",
       "      <td>582</td>\n",
       "      <td>0.043667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>crude</td>\n",
       "      <td>578</td>\n",
       "      <td>0.043367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>trade</td>\n",
       "      <td>485</td>\n",
       "      <td>0.036390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>interest</td>\n",
       "      <td>478</td>\n",
       "      <td>0.035864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ship</td>\n",
       "      <td>286</td>\n",
       "      <td>0.021459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>wheat</td>\n",
       "      <td>283</td>\n",
       "      <td>0.021233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>corn</td>\n",
       "      <td>237</td>\n",
       "      <td>0.017782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Category  Article Count  Percentage\n",
       "0      earn           3964    0.297419\n",
       "1       acq           2369    0.177746\n",
       "2  money-fx            717    0.053797\n",
       "3     grain            582    0.043667\n",
       "4     crude            578    0.043367\n",
       "5     trade            485    0.036390\n",
       "6  interest            478    0.035864\n",
       "7      ship            286    0.021459\n",
       "8     wheat            283    0.021233\n",
       "9      corn            237    0.017782"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Article Count</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>palladium</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>palmkernel</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>copra-cake</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>dfl</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>cotton-oil</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>sun-meal</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>groundnut-oil</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>rye</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>lin-oil</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>castor-oil</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Category  Article Count  Percentage\n",
       "80      palladium              3    0.000225\n",
       "81     palmkernel              3    0.000225\n",
       "82     copra-cake              3    0.000225\n",
       "83            dfl              3    0.000225\n",
       "84     cotton-oil              3    0.000225\n",
       "85       sun-meal              2    0.000150\n",
       "86  groundnut-oil              2    0.000150\n",
       "87            rye              2    0.000150\n",
       "88        lin-oil              2    0.000150\n",
       "89     castor-oil              2    0.000150"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories with less than 1% of all articles:  74\n",
      "Categories with less than .1% of all articles:  28\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate category makeup of corpus\n",
    "def category_count(df):\n",
    "    \n",
    "    cats = list(reuters.categories())\n",
    "    cat_count = []\n",
    "    \n",
    "    # Count an article with multiple categories in tuple\n",
    "    for cat in cats:\n",
    "        cat_count.append(len(df[[cat in x for x in df['Category']]]))\n",
    "    \n",
    "    count_df = pd.DataFrame(cat_count, cats).reset_index()\n",
    "    count_df.set_axis(['Category', 'Article Count'], axis=1, inplace=True)\n",
    "    count_df.sort_values(by=['Article Count'], ascending=False, inplace=True)\n",
    "    count_df.reset_index(drop=True, inplace=True)\n",
    "    count_df['Percentage'] = count_df['Article Count'] / count_df['Article Count'].sum()\n",
    "    \n",
    "    return count_df\n",
    "\n",
    "article_props = category_count(df)\n",
    "display(article_props.head(n=10))\n",
    "display(article_props.tail(n=10))\n",
    "print('Categories with less than 1% of all articles: ', len(article_props[article_props['Percentage'] < .01]))\n",
    "print('Categories with less than .1% of all articles: ', len(article_props[article_props['Percentage'] < .001]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The corpus is labeled with 90 different categories. Each article can be labelled with multiple categories (e.g. 'trade' and 'ship').\n",
    "\n",
    "There is considerable category skew and a pronounced long tail: 'earn' (29.7%) and 'acq' (17.7%) represent nearly half the articles in the corpus, while 74 categories have less than 1% of all articles, and 28 have less than .1%. \n",
    "\n",
    "However, given LDA is unsupervised and these labels aren't used, category skew does not impact the performance of topic modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text preparation and tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA aims to describe document collections by assigning topics based on the those documents' word frequency.  To do this the words must be demarcated and standardized for lexical analysis.\n",
    "\n",
    "We remove characters, diacritics, and punctuation, and convert all text to lower case tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original text: \n",
      " G-7 ISSUES STATEMENT AFTER MEETING\n",
      "  Following is the text of a statement\n",
      "  by the Group of Seven -- the U.S., Japan, West Germany, France,\n",
      "  Britain, Italy and Canada -- issued after a Washington meeting\n",
      "  yesterday.\n",
      "      1. The finance ministers and central bank governors of\n",
      "  seven major industr\n",
      "\n",
      "After cleaning: \n",
      " G-7 ISSUES STATEMENT AFTER MEETING Following is the text of a statement by the Group of Seven -- the U.S., Japan, West Germany, France, Britain, Italy and Canada -- issued after a Washington meeting yesterday. 1. The finance ministers and central bank governors of seven major industrial countries me\n",
      "\n",
      "After tokenization: \n",
      " ['issues', 'statement', 'after', 'meeting', 'following', 'is', 'the', 'text', 'of', 'statement', 'by', 'the', 'group', 'of', 'seven', 'the', 'japan', 'west', 'germany', 'france', 'britain', 'italy', 'and', 'canada', 'issued', 'after', 'washington', 'meeting', 'yesterday', 'the']\n"
     ]
    }
   ],
   "source": [
    "# Convert text to list\n",
    "data = df['Text'].values.tolist()\n",
    "\n",
    "# Remove new line characters and single quotes\n",
    "data = [re.sub(r'\\s+', ' ', sent) for sent in data]\n",
    "data = [re.sub(r\"\\'\", \"\", sent) for sent in data]\n",
    "\n",
    "# Function to tokenize words and remove punctuation\n",
    "def sentence_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuation\n",
    "\n",
    "data_words = list(sentence_to_words(data))\n",
    "\n",
    "# Impact of text preparation\n",
    "print('\\nOriginal text: \\n', (df.iloc[330,3][:300]))\n",
    "print('\\nAfter cleaning: \\n', data[330][:300])\n",
    "print('\\nAfter tokenization: \\n', data_words[330][:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing and feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stopwords are abundant in English. Their high frequency provides very little information to inform topic modeling, so we remove them from the tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove stopwords\n",
    "def remove_stopwords(texts):\n",
    "    \n",
    "    # Identify stopwords using NLTK and amend\n",
    "    stop_words = stopwords.words('english')\n",
    "    stop_words.extend(['from', 'subject', 're', 'edu', 'use'])\n",
    "    \n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "# Remove stop words\n",
    "data_words_nostops = remove_stopwords(data_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some adjacent words are known to convey different meaning.  We associate  these words in pairs called bigrams, and add them to the tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to make bigrams\n",
    "def make_bigrams(texts):\n",
    "    \n",
    "    # Generate bigram model\n",
    "    bigram = gensim.models.Phrases(data_words, \n",
    "                                   min_count=5, # must occur at least five times in corpus to be counted\n",
    "                                   threshold=100)  # higher threshold fewer phrases\n",
    "    bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "    \n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "# Form bigrams\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Words are inflected when their use in speech changes due to 'tense, case, voice, aspect, person, number, gender, and mood'  ([Wikipedia](https://en.wikipedia.org/wiki/Inflection)).  These inflections in nouns (declension) and verbs (conjugation) can take the form of prefixes, suffixes, or infixes.  **Stemming** uses an algorithmic approach that is more approximate than **lemmatization**, which uses dictionaries to identify root forms.\n",
    "\n",
    "We lemmatize the tokens to normalize them for topic modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['asian', 'exporter', 'fear', 'damage', 'mount', 'trade', 'friction', 'raise', 'fear', 'many', 'asia', 'export', 'nation', 'row', 'could', 'inflict', 'far', 'reach', 'economic', 'damage', 'businessman', 'official', 'say', 'tell', 'asian', 'capital', 'move', 'may', 'boost', 'protectionist_sentiment']\n"
     ]
    }
   ],
   "source": [
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \n",
    "    # https://spacy.io/api/annotation\n",
    "    \n",
    "    texts_out = []\n",
    "    \n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    \n",
    "    return texts_out\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "# python3 -m spacy download en\n",
    "\n",
    "# MI: do we use the nlp variable below anywhere?\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n",
    "# Perform lemmatization keeping only noun, adj, vb, adv\n",
    "data_lemmatized = lemmatization(data_words_bigrams)\n",
    "\n",
    "print(data_lemmatized[0][:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a dictionary representation of the tokens in the corpus, calculating the term document frequency for each token.  With this, we can proceed with topic modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary representation of corpus\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "# Create corpus with term document frequency\n",
    "texts = data_lemmatized\n",
    "corpus = [id2word.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generate a topic model for the article.  We employ two approaches:\n",
    "\n",
    "1. Gensim's built-in LDA topic modeling function, `ldamodel`.  Gensim implementations of LDA employ Variational Inference, which introduces bias and can provide less coherence in topics.\n",
    "2. MALLET (MAchine Learning for LanguagE Toolkit)'s LDA topic model with a Gensim wrapper, `ldamallet`.  This model employs Gibbs sampling (an MCMC method), which is unbiased at the cost of heavy computation (performed in Java).\n",
    "\n",
    "LDA models can be evaluated based on several different metrics:\n",
    "\n",
    "- **Perplexity** is a [measure](https://en.wikipedia.org/wiki/Perplexity) of 'surprise', or how well the model predicts.  The lower the score, the better the prediction.\n",
    "- **Coherence** is the degree of 'semantic similarity between high scoring keywords in the topic' [Learn to Find Topics in a Text Corpus](https://towardsdatascience.com/evaluate-topic-model-in-python-latent-dirichlet-allocation-lda-7d57484bb5d0).  It is computed as a the sum of pairwise scores of the top n words by frequency.  The higher the coherence, the more coherent and interpretable the topic. \n",
    "\n",
    "Selecting the number of topics in an LDA model can be an arbitrary decision. We inform this decision through hyperparameter tuning based on an evaluation of the topic coherence yielded by different numbers of topics. We optimize the Gensim and MALLET LDA models accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate Gensim LDA model\n",
    "def gensim_ldamodel(corpus, num_topics):\n",
    "    \n",
    "    model = gensim.models.ldamodel.LdaModel(corpus=corpus,  # TDF corpus\n",
    "                                               id2word=id2word,  # dictionary\n",
    "                                               num_topics=num_topics,  # to be optimized\n",
    "                                               random_state=100,  # [JO: CONFIRM]\n",
    "                                               # update_every=1,  # how often paramater should be updated\n",
    "                                               # chunksize=100,\n",
    "                                               # passes=10,  # total number of training passes\n",
    "                                               # alpha='auto',  # learn assymetric alpha from training data (JO: consider whether to evaluate symmetric approach for alpha with asymmetric for beta)\n",
    "                                               per_word_topics=True)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Function to generate MALLET LDA model\n",
    "def mallet_ldamodel(corpus, num_topics):\n",
    "    \n",
    "    mallet_path = './mallet-2.0.8/bin/mallet' \n",
    "    \n",
    "    model = gensim.models.wrappers.LdaMallet(mallet_path, \n",
    "                                        corpus=corpus, \n",
    "                                        num_topics=num_topics,\n",
    "                                        random_seed=100,\n",
    "                                        id2word=id2word)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Function to iterate over numbers of topics and calculates LDA model coherence\n",
    "def compute_coherence_values(model_type, dictionary, corpus, texts, limit, start=2, step=3):\n",
    "   \n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    coherence='c_v'\n",
    "    \n",
    "    for num_topics in range(start, limit, step):\n",
    "        \n",
    "        if model_type == 'LdaModel':\n",
    "            model = gensim_ldamodel(corpus=corpus,\n",
    "                           num_topics=num_topics)\n",
    "            \n",
    "        elif model_type == 'LdaMallet':\n",
    "            model = mallet_ldamodel(corpus=corpus,\n",
    "                                    num_topics=num_topics)\n",
    "            \n",
    "        else:\n",
    "            print('model_type not supported')\n",
    "            break\n",
    "        \n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, \n",
    "                                        texts=texts,\n",
    "                                        dictionary=id2word, \n",
    "                                        coherence=coherence)\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "        \n",
    "    return model_list, coherence_values  # List of LDA topic models and coherence values for respective number of topics\n",
    "\n",
    "# Function to support decision on optimal number of topics\n",
    "def chart_model_coherence(coherence_values, limit, start=2, step=3):\n",
    "    \n",
    "    x = range(start, limit, step)\n",
    "    \n",
    "    coherence_table = pd.DataFrame(list(zip(x,coherence_values)), columns=['Num Topics','Coherence Score'])\n",
    "    \n",
    "    plt.plot(x, coherence_values)\n",
    "    plt.xlabel('Num Topics')\n",
    "    plt.ylabel('Coherence Score')\n",
    "    plt.legend(('coherence_values'), loc='best')\n",
    "    plt.show()\n",
    "    \n",
    "    return coherence_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gensim LDA model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning Number of Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/gensim/topic_coherence/text_analysis.py:449: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  logger.warn(\"stats accumulation interrupted; <= %d documents processed\", self._num_docs)\n",
      "/usr/local/lib/python3.7/site-packages/gensim/topic_coherence/direct_confirmation_measure.py:204: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  m_lr_i = np.log(numerator / denominator)\n",
      "/usr/local/lib/python3.7/site-packages/gensim/topic_coherence/indirect_confirmation_measure.py:323: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cv1.T.dot(cv2)[0, 0] / (_magnitude(cv1) * _magnitude(cv2))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Num Topics</th>\n",
       "      <th>Coherence Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.315559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>0.396004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>0.424539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>0.396019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>0.407569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>26</td>\n",
       "      <td>0.420701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>30</td>\n",
       "      <td>0.410306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>34</td>\n",
       "      <td>0.403574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>38</td>\n",
       "      <td>0.396488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Num Topics  Coherence Score\n",
       "0           2         0.315559\n",
       "1           6         0.396004\n",
       "2          10         0.424539\n",
       "3          14         0.396019\n",
       "4          18         0.407569\n",
       "5          22              NaN\n",
       "6          26         0.420701\n",
       "7          30         0.410306\n",
       "8          34         0.403574\n",
       "9          38         0.396488"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cast broad net to find neighborhood of optimal number of topics in range of 2 to 40 in steps of 4\n",
    "gs_broad_model_list, gs_broad_coherence_values = compute_coherence_values(model_type='LdaModel',\n",
    "                                                                          dictionary=id2word, \n",
    "                                                                          corpus=corpus, \n",
    "                                                                          texts=data_lemmatized, \n",
    "                                                                          start=2, \n",
    "                                                                          limit=40, \n",
    "                                                                          step=4)\n",
    "\n",
    "# Chart broad net of optimal number of topics\n",
    "chart_model_coherence(gs_broad_coherence_values, \n",
    "                      start=2, \n",
    "                      limit=40, \n",
    "                      step=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When analyzed at 4 topic steps, Gensim LDA model coherence peaks between 6 and 25 topics.  It's not very smooth, so given that 4 topic increments spikes could be obscuring the optimum we narrow our search in that range with 1 topic steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/gensim/topic_coherence/text_analysis.py:449: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  logger.warn(\"stats accumulation interrupted; <= %d documents processed\", self._num_docs)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-a3a15aa8534f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                                                             \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                                                                             \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                                                                             step=1)\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Chart narrower net of optimal number of topics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-3b8e555e283b>\u001b[0m in \u001b[0;36mcompute_coherence_values\u001b[0;34m(model_type, dictionary, corpus, texts, limit, start, step)\u001b[0m\n\u001b[1;32m     52\u001b[0m                                         \u001b[0mdictionary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mid2word\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                                         coherence=coherence)\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mcoherence_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoherencemodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_coherence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoherence_values\u001b[0m  \u001b[0;31m# List of LDA topic models and coherence values for respective number of topics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/gensim/models/coherencemodel.py\u001b[0m in \u001b[0;36mget_coherence\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m         \"\"\"\n\u001b[0;32m--> 609\u001b[0;31m         \u001b[0mconfirmed_measures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_coherence_per_topic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    610\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maggregate_measures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfirmed_measures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/gensim/models/coherencemodel.py\u001b[0m in \u001b[0;36mget_coherence_per_topic\u001b[0;34m(self, segmented_topics, with_std, with_support)\u001b[0m\n\u001b[1;32m    567\u001b[0m             \u001b[0msegmented_topics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeasure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accumulator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimate_probabilities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegmented_topics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_std\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwith_std\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_support\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwith_support\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/gensim/models/coherencemodel.py\u001b[0m in \u001b[0;36mestimate_probabilities\u001b[0;34m(self, segmented_topics)\u001b[0m\n\u001b[1;32m    539\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeyed_vectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accumulator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeasure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accumulator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/gensim/topic_coherence/probability_estimation.py\u001b[0m in \u001b[0;36mp_boolean_sliding_window\u001b[0;34m(texts, segmented_topics, dictionary, window_size, processes)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0maccumulator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallelWordOccurrenceAccumulator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocesses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"using %s to estimate probabilities from sliding windows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccumulator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0maccumulator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccumulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/gensim/topic_coherence/text_analysis.py\u001b[0m in \u001b[0;36maccumulate\u001b[0;34m(self, texts, window_size)\u001b[0m\n\u001b[1;32m    450\u001b[0m             \u001b[0minterrupted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m         \u001b[0maccumulators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminate_workers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_q\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_q\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterrupted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_accumulators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccumulators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/gensim/topic_coherence/text_analysis.py\u001b[0m in \u001b[0;36mterminate_workers\u001b[0;34m(self, input_q, output_q, workers, interrupted)\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0maccumulators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccumulators\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m             \u001b[0maccumulators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_q\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%d accumulators retrieved from output queue\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccumulators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.7/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.7/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"negative maxlength\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bad_message_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.7/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxsize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.7/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Cast narrower net in range of 6 to 25 in single steps to smooth and find optimum in number of topics\n",
    "gs_narrow_model_list, gs_narrow_coherence_values = compute_coherence_values(model_type='LdaModel',\n",
    "                                                                            dictionary=id2word, \n",
    "                                                                            corpus=corpus, \n",
    "                                                                            texts=data_lemmatized, \n",
    "                                                                            start=6, \n",
    "                                                                            limit=25, \n",
    "                                                                            step=1)\n",
    "\n",
    "# Chart narrower net of optimal number of topics\n",
    "gs_narrow_coherence = chart_model_coherence(gs_narrow_coherence_values, \n",
    "                      start=6, \n",
    "                      limit=25, \n",
    "                      step=1)     \n",
    "gs_narrow_coherence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimized Gensim Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9 topics yield the highest coherence score so we select the model with a k of 9. Here is a snapshot of top words for each of the 9 topics in this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gensim LDA model perplexity:  -7.095693898256886\n",
      "\n",
      "Gensim LDA model coherence score:  0.43975307826479676 \n",
      "\n",
      "0: say year rate rise quarter expect growth first earning increase\n",
      "1: price say oil raise crude trader barrel today dlrs rate\n",
      "2: say crop year deficit soybean estimate last trade surplus program\n",
      "3: say company share offer would buy stock group also sell\n",
      "4: say bank market rise dollar rate dealer money yen currency\n",
      "5: loss net ct profit dlrs sale year say include note\n",
      "6: say trade would export official government import country year japanese\n",
      "7: share ct say dividend stock record split dlrs may pay\n",
      "8: say year oil price production last would rise market export\n"
     ]
    }
   ],
   "source": [
    "# Optimal Gensim model\n",
    "# gs_optimal_model = gs_narrow_model_list[int(gs_narrow_coherence.loc[gs_narrow_coherence['Coherence Score'].idxmax()]['Num Topics'])]\n",
    "gs_optimal_model = gensim_ldamodel(corpus=corpus, num_topics=9)\n",
    "\n",
    "# Compute model perplexity and coherence score\n",
    "print('\\nGensim LDA model perplexity: ', gs_optimal_model.log_perplexity(corpus))\n",
    "# print('\\nGensim LDA model coherence score: ', gs_narrow_coherence.loc[gs_narrow_coherence['Coherence Score'].idxmax()]['Coherence Score'])\n",
    "print('\\nGensim LDA model coherence score: ', CoherenceModel(model=gs_optimal_model, texts=texts).get_coherence(), '\\n')\n",
    "\n",
    "# Here is a quick look at the the top words by topic for the optimal Gensim model\n",
    "for topic_id in range(gs_optimal_model.num_topics):\n",
    "    top_k = gs_optimal_model.show_topic(topic_id, 10)\n",
    "    top_k_words = [w for w, _ in top_k]\n",
    "    \n",
    "    print('{}: {}'.format(topic_id, ' '.join(top_k_words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -> Presentation split <-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MALLET LDA model\n",
    "\n",
    "We replicate the steps from above to the MALLET topic model. As stated above, the MALLET is computationally heavy yet we expect to have more coherent topics as a compromise. We start by sweeping the number of topics as a parameter from 2 to 20 and build all the intermediate models. From there we can focus on the are of the coherence plot below which has the high coherence and narrow in further to identify the optimal number of topics for this model on this corpus. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning Number of Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Num Topics</th>\n",
       "      <th>Coherence Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.371488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>0.508364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>0.497556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>0.527151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>0.503495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Num Topics  Coherence Score\n",
       "0           2         0.371488\n",
       "1           6         0.508364\n",
       "2          10         0.497556\n",
       "3          14         0.527151\n",
       "4          18         0.503495"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cast broad net to find neighborhood of optimal number of topics in range of 2 to 40 in steps of 4\n",
    "mlt_broad_model_list, mlt_broad_coherence_values = compute_coherence_values(model_type='LdaMallet',\n",
    "                                                                          dictionary=id2word, \n",
    "                                                                          corpus=corpus, \n",
    "                                                                          texts=data_lemmatized, \n",
    "                                                                          start=2, \n",
    "                                                                          limit=20, \n",
    "                                                                          step=4)\n",
    "\n",
    "# Chart broad net of optimal number of topics\n",
    "chart_model_coherence(mlt_broad_coherence_values, \n",
    "                      start=2, \n",
    "                      limit=20, \n",
    "                      step=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Num Topics</th>\n",
       "      <th>Coherence Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>0.503529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>0.510041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>0.527151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>0.507292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Num Topics  Coherence Score\n",
       "0          12         0.503529\n",
       "1          13         0.510041\n",
       "2          14         0.527151\n",
       "3          15         0.507292"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cast narrower net in range of 6 to 25 in single steps to smooth and find optimum in number of topics\n",
    "mlt_narrow_model_list, mlt_narrow_coherence_values = compute_coherence_values(model_type='LdaMallet',\n",
    "                                                                            dictionary=id2word, \n",
    "                                                                            corpus=corpus, \n",
    "                                                                            texts=data_lemmatized, \n",
    "                                                                            start=12, \n",
    "                                                                            limit=16, \n",
    "                                                                            step=1)\n",
    "\n",
    "# Chart narrower net of optimal number of topics\n",
    "mlt_narrow_coherence = chart_model_coherence(mlt_narrow_coherence_values, \n",
    "                      start=12, \n",
    "                      limit=16, \n",
    "                      step=1)     \n",
    "mlt_narrow_coherence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimized MALLET Model\n",
    "\n",
    "From the sweep optimization above, we were above to determine that the optimal number of topics for this model is 14. We save this model as a variable for future use and take a look at the keyword distribution of the topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mallet LDA model perplexity:  -7.095664176983087\n",
      "\n",
      "Mallet LDA model coherence score:  0.5271508282605067 \n",
      "\n",
      "0: price agreement meeting producer market talk agree member coffee set\n",
      "1: sale company unit earning business quarter result operation sell complete\n",
      "2: year dlrs end expect report early total month period week\n",
      "3: ct loss net profit dlrs note include mln gain sale\n",
      "4: rise fall year growth increase deficit show figure decline month\n",
      "5: oil price production crude increase industry barrel contract raise gold\n",
      "6: tonne export wheat import grain crop program corn estimate production\n",
      "7: bank interest tax debt loan payment credit capital increase issue\n",
      "8: offer company make plan group merger bid tender propose proposal\n",
      "9: spokesman state today official source government ship strike work day\n",
      "10: share stock company common dividend acquire record shareholder cash pay\n",
      "11: trade official government japanese country import foreign industry economic policy\n",
      "12: buy analyst firm market investment sell give make base add\n",
      "13: rate market dollar bank exchange currency cut money yen dealer\n"
     ]
    }
   ],
   "source": [
    "# Optimal MALLET model\n",
    "mlt_optimal_model = mallet_ldamodel(corpus=corpus, num_topics=14)\n",
    "\n",
    "# Compute model perplexity and coherence score\n",
    "print('\\nMallet LDA model perplexity: ', gs_optimal_model.log_perplexity(corpus))\n",
    "print('\\nMallet LDA model coherence score: ', CoherenceModel(model=mlt_optimal_model, texts=texts).get_coherence(), '\\n')\n",
    "\n",
    "# Here is a quick look at the the top words by topic for the optimal MALLET model\n",
    "for topic_id in range(mlt_optimal_model.num_topics):\n",
    "    top_k = mlt_optimal_model.show_topic(topic_id, 10)\n",
    "    top_k_words = [w for w, _ in top_k]\n",
    "    \n",
    "    print('{}: {}'.format(topic_id, ' '.join(top_k_words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Model Analysis & Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most Dominant Topics\n",
    "\n",
    "The most dominant topics in each article are extracted using both optimal models. These will be used in a comparison against the known labels of the Reuters corpus. Along with the dominant topics, we also extract the keywords associated with the topics and the measure of how likely the dominant topic was.\n",
    "\n",
    "The function below is used to obtain the proportion of articles that have been assigned a particular topic by the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a dataframe of the proportion of articles having a particular topic\n",
    "def get_topic_distribution(best_topics_df):\n",
    "    \n",
    "    topic_count = best_topics_df.groupby(['Best Topic','Keywords'])['Article'].count()\n",
    "    topic_prop = pd.DataFrame(topic_count/len(best_topics_df)*100)\n",
    "    topic_prop = topic_prop.reset_index()\n",
    "    topic_prop.columns = ['Best Topic', 'Keywords', 'Proportion']\n",
    "    topic_prop['Proportion'] = topic_prop['Proportion'].apply(lambda x: round(x,2)) # Look into truncating digits\n",
    "    \n",
    "    return topic_prop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best Gensim Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract best topic for each article along with associate keywords and likelyhood\n",
    "def get_best_gensim_topics(lda_model, corpus):\n",
    "    \n",
    "    lda_model_corpus = lda_model[corpus]\n",
    "    art_topic_keywords = pd.DataFrame(columns = ['Article','Best Topic','Likelihood','Keywords'])\n",
    "    \n",
    "    # Loop through articles to get each article's main topic\n",
    "    for i, article in enumerate(lda_model[corpus]):\n",
    "        for article in enumerate(article): \n",
    "            if article[0] == 0:\n",
    "                #print(article)\n",
    "                wp = lda_model.show_topic(article[1][0][0])\n",
    "                topic_keywords = ', '.join([word for word, prop in wp])\n",
    "                \n",
    "                best_topic = int(article[1][0][0])\n",
    "                max_likelihood = round(article[1][0][1],4)\n",
    "                \n",
    "                d = {'Article': i, 'Best Topic': best_topic,'Likelihood': max_likelihood,'Keywords': topic_keywords}\n",
    "                art_topic_keywords = art_topic_keywords.append(d, ignore_index=True)\n",
    "\n",
    "    return art_topic_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_943bd73a_ca35_11ea_b6b7_784f434fb9dc\" ><thead>    <tr>        <th class=\"col_heading level0 col0\" >Article</th>        <th class=\"col_heading level0 col1\" >Best Topic</th>        <th class=\"col_heading level0 col2\" >Likelihood</th>        <th class=\"col_heading level0 col3\" >Keywords</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_943bd73a_ca35_11ea_b6b7_784f434fb9dcrow0_col0\" class=\"data row0 col0\" >0</td>\n",
       "                        <td id=\"T_943bd73a_ca35_11ea_b6b7_784f434fb9dcrow0_col1\" class=\"data row0 col1\" >0</td>\n",
       "                        <td id=\"T_943bd73a_ca35_11ea_b6b7_784f434fb9dcrow0_col2\" class=\"data row0 col2\" >0.077400</td>\n",
       "                        <td id=\"T_943bd73a_ca35_11ea_b6b7_784f434fb9dcrow0_col3\" class=\"data row0 col3\" >say, year, rate, rise, quarter, expect, growth, first, earning, increase</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_943bd73a_ca35_11ea_b6b7_784f434fb9dcrow1_col0\" class=\"data row1 col0\" >1</td>\n",
       "                        <td id=\"T_943bd73a_ca35_11ea_b6b7_784f434fb9dcrow1_col1\" class=\"data row1 col1\" >2</td>\n",
       "                        <td id=\"T_943bd73a_ca35_11ea_b6b7_784f434fb9dcrow1_col2\" class=\"data row1 col2\" >0.072900</td>\n",
       "                        <td id=\"T_943bd73a_ca35_11ea_b6b7_784f434fb9dcrow1_col3\" class=\"data row1 col3\" >say, crop, year, deficit, soybean, estimate, last, trade, surplus, program</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_943bd73a_ca35_11ea_b6b7_784f434fb9dcrow2_col0\" class=\"data row2 col0\" >2</td>\n",
       "                        <td id=\"T_943bd73a_ca35_11ea_b6b7_784f434fb9dcrow2_col1\" class=\"data row2 col1\" >8</td>\n",
       "                        <td id=\"T_943bd73a_ca35_11ea_b6b7_784f434fb9dcrow2_col2\" class=\"data row2 col2\" >0.988400</td>\n",
       "                        <td id=\"T_943bd73a_ca35_11ea_b6b7_784f434fb9dcrow2_col3\" class=\"data row2 col3\" >say, year, oil, price, production, last, would, rise, market, export</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_943bd73a_ca35_11ea_b6b7_784f434fb9dcrow3_col0\" class=\"data row3 col0\" >3</td>\n",
       "                        <td id=\"T_943bd73a_ca35_11ea_b6b7_784f434fb9dcrow3_col1\" class=\"data row3 col1\" >0</td>\n",
       "                        <td id=\"T_943bd73a_ca35_11ea_b6b7_784f434fb9dcrow3_col2\" class=\"data row3 col2\" >0.634600</td>\n",
       "                        <td id=\"T_943bd73a_ca35_11ea_b6b7_784f434fb9dcrow3_col3\" class=\"data row3 col3\" >say, year, rate, rise, quarter, expect, growth, first, earning, increase</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_943bd73a_ca35_11ea_b6b7_784f434fb9dcrow4_col0\" class=\"data row4 col0\" >4</td>\n",
       "                        <td id=\"T_943bd73a_ca35_11ea_b6b7_784f434fb9dcrow4_col1\" class=\"data row4 col1\" >6</td>\n",
       "                        <td id=\"T_943bd73a_ca35_11ea_b6b7_784f434fb9dcrow4_col2\" class=\"data row4 col2\" >0.048400</td>\n",
       "                        <td id=\"T_943bd73a_ca35_11ea_b6b7_784f434fb9dcrow4_col3\" class=\"data row4 col3\" >say, trade, would, export, official, government, import, country, year, japanese</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_943bd73a_ca35_11ea_b6b7_784f434fb9dcrow5_col0\" class=\"data row5 col0\" >5</td>\n",
       "                        <td id=\"T_943bd73a_ca35_11ea_b6b7_784f434fb9dcrow5_col1\" class=\"data row5 col1\" >6</td>\n",
       "                        <td id=\"T_943bd73a_ca35_11ea_b6b7_784f434fb9dcrow5_col2\" class=\"data row5 col2\" >0.990400</td>\n",
       "                        <td id=\"T_943bd73a_ca35_11ea_b6b7_784f434fb9dcrow5_col3\" class=\"data row5 col3\" >say, trade, would, export, official, government, import, country, year, japanese</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_943bd73a_ca35_11ea_b6b7_784f434fb9dcrow6_col0\" class=\"data row6 col0\" >6</td>\n",
       "                        <td id=\"T_943bd73a_ca35_11ea_b6b7_784f434fb9dcrow6_col1\" class=\"data row6 col1\" >2</td>\n",
       "                        <td id=\"T_943bd73a_ca35_11ea_b6b7_784f434fb9dcrow6_col2\" class=\"data row6 col2\" >0.074800</td>\n",
       "                        <td id=\"T_943bd73a_ca35_11ea_b6b7_784f434fb9dcrow6_col3\" class=\"data row6 col3\" >say, crop, year, deficit, soybean, estimate, last, trade, surplus, program</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_943bd73a_ca35_11ea_b6b7_784f434fb9dcrow7_col0\" class=\"data row7 col0\" >7</td>\n",
       "                        <td id=\"T_943bd73a_ca35_11ea_b6b7_784f434fb9dcrow7_col1\" class=\"data row7 col1\" >2</td>\n",
       "                        <td id=\"T_943bd73a_ca35_11ea_b6b7_784f434fb9dcrow7_col2\" class=\"data row7 col2\" >0.618400</td>\n",
       "                        <td id=\"T_943bd73a_ca35_11ea_b6b7_784f434fb9dcrow7_col3\" class=\"data row7 col3\" >say, crop, year, deficit, soybean, estimate, last, trade, surplus, program</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_943bd73a_ca35_11ea_b6b7_784f434fb9dcrow8_col0\" class=\"data row8 col0\" >8</td>\n",
       "                        <td id=\"T_943bd73a_ca35_11ea_b6b7_784f434fb9dcrow8_col1\" class=\"data row8 col1\" >8</td>\n",
       "                        <td id=\"T_943bd73a_ca35_11ea_b6b7_784f434fb9dcrow8_col2\" class=\"data row8 col2\" >0.977200</td>\n",
       "                        <td id=\"T_943bd73a_ca35_11ea_b6b7_784f434fb9dcrow8_col3\" class=\"data row8 col3\" >say, year, oil, price, production, last, would, rise, market, export</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_943bd73a_ca35_11ea_b6b7_784f434fb9dcrow9_col0\" class=\"data row9 col0\" >9</td>\n",
       "                        <td id=\"T_943bd73a_ca35_11ea_b6b7_784f434fb9dcrow9_col1\" class=\"data row9 col1\" >0</td>\n",
       "                        <td id=\"T_943bd73a_ca35_11ea_b6b7_784f434fb9dcrow9_col2\" class=\"data row9 col2\" >0.172600</td>\n",
       "                        <td id=\"T_943bd73a_ca35_11ea_b6b7_784f434fb9dcrow9_col3\" class=\"data row9 col3\" >say, year, rate, rise, quarter, expect, growth, first, earning, increase</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_943bd73a_ca35_11ea_b6b7_784f434fb9dcrow10_col0\" class=\"data row10 col0\" >10</td>\n",
       "                        <td id=\"T_943bd73a_ca35_11ea_b6b7_784f434fb9dcrow10_col1\" class=\"data row10 col1\" >3</td>\n",
       "                        <td id=\"T_943bd73a_ca35_11ea_b6b7_784f434fb9dcrow10_col2\" class=\"data row10 col2\" >0.254900</td>\n",
       "                        <td id=\"T_943bd73a_ca35_11ea_b6b7_784f434fb9dcrow10_col3\" class=\"data row10 col3\" >say, company, share, offer, would, buy, stock, group, also, sell</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_943bd73a_ca35_11ea_b6b7_784f434fb9dcrow11_col0\" class=\"data row11 col0\" >11</td>\n",
       "                        <td id=\"T_943bd73a_ca35_11ea_b6b7_784f434fb9dcrow11_col1\" class=\"data row11 col1\" >4</td>\n",
       "                        <td id=\"T_943bd73a_ca35_11ea_b6b7_784f434fb9dcrow11_col2\" class=\"data row11 col2\" >0.836200</td>\n",
       "                        <td id=\"T_943bd73a_ca35_11ea_b6b7_784f434fb9dcrow11_col3\" class=\"data row11 col3\" >say, bank, market, rise, dollar, rate, dealer, money, yen, currency</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_943bd73a_ca35_11ea_b6b7_784f434fb9dcrow12_col0\" class=\"data row12 col0\" >12</td>\n",
       "                        <td id=\"T_943bd73a_ca35_11ea_b6b7_784f434fb9dcrow12_col1\" class=\"data row12 col1\" >3</td>\n",
       "                        <td id=\"T_943bd73a_ca35_11ea_b6b7_784f434fb9dcrow12_col2\" class=\"data row12 col2\" >0.261100</td>\n",
       "                        <td id=\"T_943bd73a_ca35_11ea_b6b7_784f434fb9dcrow12_col3\" class=\"data row12 col3\" >say, company, share, offer, would, buy, stock, group, also, sell</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_943bd73a_ca35_11ea_b6b7_784f434fb9dcrow13_col0\" class=\"data row13 col0\" >13</td>\n",
       "                        <td id=\"T_943bd73a_ca35_11ea_b6b7_784f434fb9dcrow13_col1\" class=\"data row13 col1\" >0</td>\n",
       "                        <td id=\"T_943bd73a_ca35_11ea_b6b7_784f434fb9dcrow13_col2\" class=\"data row13 col2\" >0.673100</td>\n",
       "                        <td id=\"T_943bd73a_ca35_11ea_b6b7_784f434fb9dcrow13_col3\" class=\"data row13 col3\" >say, year, rate, rise, quarter, expect, growth, first, earning, increase</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_943bd73a_ca35_11ea_b6b7_784f434fb9dcrow14_col0\" class=\"data row14 col0\" >14</td>\n",
       "                        <td id=\"T_943bd73a_ca35_11ea_b6b7_784f434fb9dcrow14_col1\" class=\"data row14 col1\" >3</td>\n",
       "                        <td id=\"T_943bd73a_ca35_11ea_b6b7_784f434fb9dcrow14_col2\" class=\"data row14 col2\" >0.046100</td>\n",
       "                        <td id=\"T_943bd73a_ca35_11ea_b6b7_784f434fb9dcrow14_col3\" class=\"data row14 col3\" >say, company, share, offer, would, buy, stock, group, also, sell</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1303af7d0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gensim_topic_df = get_best_gensim_topics(gs_optimal_model, corpus)\n",
    "\n",
    "gensim_topic_df.head(15).style.hide_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe above displays the most likely topic along with the likelyhood of that topic. The keywords that describe the topics are also shown. When aggregated in the data frame below, topic 0 emerges as the most common topic with 45% of the articles classified as such. Topics 3 and 5 round out the top 3 of topics represent in more than 10% of the articles.\n",
    "\n",
    "Comment on similar themes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_9bffb0fe_ca35_11ea_b6b7_784f434fb9dcrow0_col2 {\n",
       "            background-color:  #08306b;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_9bffb0fe_ca35_11ea_b6b7_784f434fb9dcrow1_col2 {\n",
       "            background-color:  #dbe9f6;\n",
       "            color:  #000000;\n",
       "        }    #T_9bffb0fe_ca35_11ea_b6b7_784f434fb9dcrow2_col2 {\n",
       "            background-color:  #dce9f6;\n",
       "            color:  #000000;\n",
       "        }    #T_9bffb0fe_ca35_11ea_b6b7_784f434fb9dcrow3_col2 {\n",
       "            background-color:  #94c4df;\n",
       "            color:  #000000;\n",
       "        }    #T_9bffb0fe_ca35_11ea_b6b7_784f434fb9dcrow4_col2 {\n",
       "            background-color:  #eaf2fb;\n",
       "            color:  #000000;\n",
       "        }    #T_9bffb0fe_ca35_11ea_b6b7_784f434fb9dcrow5_col2 {\n",
       "            background-color:  #ccdff1;\n",
       "            color:  #000000;\n",
       "        }    #T_9bffb0fe_ca35_11ea_b6b7_784f434fb9dcrow6_col2 {\n",
       "            background-color:  #f2f8fd;\n",
       "            color:  #000000;\n",
       "        }    #T_9bffb0fe_ca35_11ea_b6b7_784f434fb9dcrow7_col2 {\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }    #T_9bffb0fe_ca35_11ea_b6b7_784f434fb9dcrow8_col2 {\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }</style><table id=\"T_9bffb0fe_ca35_11ea_b6b7_784f434fb9dc\" ><thead>    <tr>        <th class=\"col_heading level0 col0\" >Best Topic</th>        <th class=\"col_heading level0 col1\" >Keywords</th>        <th class=\"col_heading level0 col2\" >Proportion</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_9bffb0fe_ca35_11ea_b6b7_784f434fb9dcrow0_col0\" class=\"data row0 col0\" >0</td>\n",
       "                        <td id=\"T_9bffb0fe_ca35_11ea_b6b7_784f434fb9dcrow0_col1\" class=\"data row0 col1\" >say, year, rate, rise, quarter, expect, growth, first, earning, increase</td>\n",
       "                        <td id=\"T_9bffb0fe_ca35_11ea_b6b7_784f434fb9dcrow0_col2\" class=\"data row0 col2\" >45.570000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_9bffb0fe_ca35_11ea_b6b7_784f434fb9dcrow1_col0\" class=\"data row1 col0\" >1</td>\n",
       "                        <td id=\"T_9bffb0fe_ca35_11ea_b6b7_784f434fb9dcrow1_col1\" class=\"data row1 col1\" >price, say, oil, raise, crude, trader, barrel, today, dlrs, rate</td>\n",
       "                        <td id=\"T_9bffb0fe_ca35_11ea_b6b7_784f434fb9dcrow1_col2\" class=\"data row1 col2\" >7.650000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_9bffb0fe_ca35_11ea_b6b7_784f434fb9dcrow2_col0\" class=\"data row2 col0\" >2</td>\n",
       "                        <td id=\"T_9bffb0fe_ca35_11ea_b6b7_784f434fb9dcrow2_col1\" class=\"data row2 col1\" >say, crop, year, deficit, soybean, estimate, last, trade, surplus, program</td>\n",
       "                        <td id=\"T_9bffb0fe_ca35_11ea_b6b7_784f434fb9dcrow2_col2\" class=\"data row2 col2\" >7.430000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_9bffb0fe_ca35_11ea_b6b7_784f434fb9dcrow3_col0\" class=\"data row3 col0\" >3</td>\n",
       "                        <td id=\"T_9bffb0fe_ca35_11ea_b6b7_784f434fb9dcrow3_col1\" class=\"data row3 col1\" >say, company, share, offer, would, buy, stock, group, also, sell</td>\n",
       "                        <td id=\"T_9bffb0fe_ca35_11ea_b6b7_784f434fb9dcrow3_col2\" class=\"data row3 col2\" >19.070000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_9bffb0fe_ca35_11ea_b6b7_784f434fb9dcrow4_col0\" class=\"data row4 col0\" >4</td>\n",
       "                        <td id=\"T_9bffb0fe_ca35_11ea_b6b7_784f434fb9dcrow4_col1\" class=\"data row4 col1\" >say, bank, market, rise, dollar, rate, dealer, money, yen, currency</td>\n",
       "                        <td id=\"T_9bffb0fe_ca35_11ea_b6b7_784f434fb9dcrow4_col2\" class=\"data row4 col2\" >4.250000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_9bffb0fe_ca35_11ea_b6b7_784f434fb9dcrow5_col0\" class=\"data row5 col0\" >5</td>\n",
       "                        <td id=\"T_9bffb0fe_ca35_11ea_b6b7_784f434fb9dcrow5_col1\" class=\"data row5 col1\" >loss, net, ct, profit, dlrs, sale, year, say, include, note</td>\n",
       "                        <td id=\"T_9bffb0fe_ca35_11ea_b6b7_784f434fb9dcrow5_col2\" class=\"data row5 col2\" >11.080000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_9bffb0fe_ca35_11ea_b6b7_784f434fb9dcrow6_col0\" class=\"data row6 col0\" >6</td>\n",
       "                        <td id=\"T_9bffb0fe_ca35_11ea_b6b7_784f434fb9dcrow6_col1\" class=\"data row6 col1\" >say, trade, would, export, official, government, import, country, year, japanese</td>\n",
       "                        <td id=\"T_9bffb0fe_ca35_11ea_b6b7_784f434fb9dcrow6_col2\" class=\"data row6 col2\" >2.410000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_9bffb0fe_ca35_11ea_b6b7_784f434fb9dcrow7_col0\" class=\"data row7 col0\" >7</td>\n",
       "                        <td id=\"T_9bffb0fe_ca35_11ea_b6b7_784f434fb9dcrow7_col1\" class=\"data row7 col1\" >share, ct, say, dividend, stock, record, split, dlrs, may, pay</td>\n",
       "                        <td id=\"T_9bffb0fe_ca35_11ea_b6b7_784f434fb9dcrow7_col2\" class=\"data row7 col2\" >1.260000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_9bffb0fe_ca35_11ea_b6b7_784f434fb9dcrow8_col0\" class=\"data row8 col0\" >8</td>\n",
       "                        <td id=\"T_9bffb0fe_ca35_11ea_b6b7_784f434fb9dcrow8_col1\" class=\"data row8 col1\" >say, year, oil, price, production, last, would, rise, market, export</td>\n",
       "                        <td id=\"T_9bffb0fe_ca35_11ea_b6b7_784f434fb9dcrow8_col2\" class=\"data row8 col2\" >1.290000</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x130e26d90>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_topic_prop = get_topic_distribution(gensim_topic_df)\n",
    "gs_topic_prop.style.hide_index().background_gradient(subset='Proportion',cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best Mallet Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract best topic for each article along with associate keywords and likelyhood\n",
    "def get_best_mallet_topics(lda_model, corpus):\n",
    "    \n",
    "    lda_model_corpus = lda_model[corpus]\n",
    "    art_topic_keywords = pd.DataFrame(columns = ['Article','Best Topic','Likelihood','Keywords'])\n",
    "    \n",
    "    for i in range(len(lda_model_corpus)):\n",
    "        # Get article topic model distribution\n",
    "        article = lda_model_corpus[i]\n",
    "\n",
    "        # Find the max likelihood index and select the corresponding topic\n",
    "        likelihood = [likelyhood for topic,likelyhood in article]\n",
    "        max_likelihood = max(likelihood)\n",
    "        best_topic = likelihood.index(max_likelihood)\n",
    "        \n",
    "        # Get keywords for best topcis\n",
    "        wp = lda_model.show_topic(best_topic)\n",
    "        topic_keywords = ', '.join([word for word, prop in wp])\n",
    "        \n",
    "        # Assemble and append information to dataframe\n",
    "        d = {'Article': i, 'Best Topic': best_topic,'Likelihood': max_likelihood,'Keywords': topic_keywords}\n",
    "        art_topic_keywords = art_topic_keywords.append(d, ignore_index=True)\n",
    "        \n",
    "    return art_topic_keywords\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Best Topic</th>\n",
       "      <th>Likelihood</th>\n",
       "      <th>Keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.470864</td>\n",
       "      <td>trade, official, government, japanese, country...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.167488</td>\n",
       "      <td>tonne, export, wheat, import, grain, crop, pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.265873</td>\n",
       "      <td>oil, price, production, crude, increase, indus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.258730</td>\n",
       "      <td>rise, fall, year, growth, increase, deficit, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.249664</td>\n",
       "      <td>tonne, export, wheat, import, grain, crop, pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10783</th>\n",
       "      <td>10783</td>\n",
       "      <td>13</td>\n",
       "      <td>0.107672</td>\n",
       "      <td>rate, market, dollar, bank, exchange, currency...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10784</th>\n",
       "      <td>10784</td>\n",
       "      <td>3</td>\n",
       "      <td>0.105121</td>\n",
       "      <td>ct, loss, net, profit, dlrs, note, include, ml...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10785</th>\n",
       "      <td>10785</td>\n",
       "      <td>3</td>\n",
       "      <td>0.105121</td>\n",
       "      <td>ct, loss, net, profit, dlrs, note, include, ml...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10786</th>\n",
       "      <td>10786</td>\n",
       "      <td>3</td>\n",
       "      <td>0.289449</td>\n",
       "      <td>ct, loss, net, profit, dlrs, note, include, ml...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10787</th>\n",
       "      <td>10787</td>\n",
       "      <td>0</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>price, agreement, meeting, producer, market, t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10788 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Article Best Topic  Likelihood  \\\n",
       "0           0         11    0.470864   \n",
       "1           1          6    0.167488   \n",
       "2           2          5    0.265873   \n",
       "3           3          4    0.258730   \n",
       "4           4          6    0.249664   \n",
       "...       ...        ...         ...   \n",
       "10783   10783         13    0.107672   \n",
       "10784   10784          3    0.105121   \n",
       "10785   10785          3    0.105121   \n",
       "10786   10786          3    0.289449   \n",
       "10787   10787          0    0.071429   \n",
       "\n",
       "                                                Keywords  \n",
       "0      trade, official, government, japanese, country...  \n",
       "1      tonne, export, wheat, import, grain, crop, pro...  \n",
       "2      oil, price, production, crude, increase, indus...  \n",
       "3      rise, fall, year, growth, increase, deficit, s...  \n",
       "4      tonne, export, wheat, import, grain, crop, pro...  \n",
       "...                                                  ...  \n",
       "10783  rate, market, dollar, bank, exchange, currency...  \n",
       "10784  ct, loss, net, profit, dlrs, note, include, ml...  \n",
       "10785  ct, loss, net, profit, dlrs, note, include, ml...  \n",
       "10786  ct, loss, net, profit, dlrs, note, include, ml...  \n",
       "10787  price, agreement, meeting, producer, market, t...  \n",
       "\n",
       "[10788 rows x 4 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mallet_topic_df = get_best_mallet_topics(mlt_optimal_model, corpus)\n",
    "\n",
    "mallet_topic_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using the mallet model, the porportions are a lot more diversified which makes sense given the increased number of topics (from 9 to 11).\n",
    "\n",
    "Topic 3 makes up for 21% of the articles with keywords like: ct, loss, net, profit, dlrs, note, include, mln, gain, sale. We can recognize these as words from financial reports. \n",
    "\n",
    "Topic 10 with 12% is the second most represented with keywords: share, stock, company, common, dividend, acquire, record, shareholder, cash, pay. Interestingly, while there is no overlap in the words, the theme of company and financial report is very similar. Topic 10 seems more related to earnings report with keywords like 'divident'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_c6a7029e_ca35_11ea_b6b7_784f434fb9dcrow0_col2 {\n",
       "            background-color:  #eaf2fb;\n",
       "            color:  #000000;\n",
       "        }    #T_c6a7029e_ca35_11ea_b6b7_784f434fb9dcrow1_col2 {\n",
       "            background-color:  #a9cfe5;\n",
       "            color:  #000000;\n",
       "        }    #T_c6a7029e_ca35_11ea_b6b7_784f434fb9dcrow2_col2 {\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }    #T_c6a7029e_ca35_11ea_b6b7_784f434fb9dcrow3_col2 {\n",
       "            background-color:  #08306b;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_c6a7029e_ca35_11ea_b6b7_784f434fb9dcrow4_col2 {\n",
       "            background-color:  #d6e6f4;\n",
       "            color:  #000000;\n",
       "        }    #T_c6a7029e_ca35_11ea_b6b7_784f434fb9dcrow5_col2 {\n",
       "            background-color:  #d0e2f2;\n",
       "            color:  #000000;\n",
       "        }    #T_c6a7029e_ca35_11ea_b6b7_784f434fb9dcrow6_col2 {\n",
       "            background-color:  #caddf0;\n",
       "            color:  #000000;\n",
       "        }    #T_c6a7029e_ca35_11ea_b6b7_784f434fb9dcrow7_col2 {\n",
       "            background-color:  #f3f8fe;\n",
       "            color:  #000000;\n",
       "        }    #T_c6a7029e_ca35_11ea_b6b7_784f434fb9dcrow8_col2 {\n",
       "            background-color:  #d0e2f2;\n",
       "            color:  #000000;\n",
       "        }    #T_c6a7029e_ca35_11ea_b6b7_784f434fb9dcrow9_col2 {\n",
       "            background-color:  #f2f8fd;\n",
       "            color:  #000000;\n",
       "        }    #T_c6a7029e_ca35_11ea_b6b7_784f434fb9dcrow10_col2 {\n",
       "            background-color:  #6dafd7;\n",
       "            color:  #000000;\n",
       "        }    #T_c6a7029e_ca35_11ea_b6b7_784f434fb9dcrow11_col2 {\n",
       "            background-color:  #e5eff9;\n",
       "            color:  #000000;\n",
       "        }    #T_c6a7029e_ca35_11ea_b6b7_784f434fb9dcrow12_col2 {\n",
       "            background-color:  #f3f8fe;\n",
       "            color:  #000000;\n",
       "        }    #T_c6a7029e_ca35_11ea_b6b7_784f434fb9dcrow13_col2 {\n",
       "            background-color:  #cddff1;\n",
       "            color:  #000000;\n",
       "        }</style><table id=\"T_c6a7029e_ca35_11ea_b6b7_784f434fb9dc\" ><thead>    <tr>        <th class=\"col_heading level0 col0\" >Best Topic</th>        <th class=\"col_heading level0 col1\" >Keywords</th>        <th class=\"col_heading level0 col2\" >Proportion</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_c6a7029e_ca35_11ea_b6b7_784f434fb9dcrow0_col0\" class=\"data row0 col0\" >0</td>\n",
       "                        <td id=\"T_c6a7029e_ca35_11ea_b6b7_784f434fb9dcrow0_col1\" class=\"data row0 col1\" >price, agreement, meeting, producer, market, talk, agree, member, coffee, set</td>\n",
       "                        <td id=\"T_c6a7029e_ca35_11ea_b6b7_784f434fb9dcrow0_col2\" class=\"data row0 col2\" >4.410000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_c6a7029e_ca35_11ea_b6b7_784f434fb9dcrow1_col0\" class=\"data row1 col0\" >1</td>\n",
       "                        <td id=\"T_c6a7029e_ca35_11ea_b6b7_784f434fb9dcrow1_col1\" class=\"data row1 col1\" >sale, company, unit, earning, business, quarter, result, operation, sell, complete</td>\n",
       "                        <td id=\"T_c6a7029e_ca35_11ea_b6b7_784f434fb9dcrow1_col2\" class=\"data row1 col2\" >9.380000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_c6a7029e_ca35_11ea_b6b7_784f434fb9dcrow2_col0\" class=\"data row2 col0\" >2</td>\n",
       "                        <td id=\"T_c6a7029e_ca35_11ea_b6b7_784f434fb9dcrow2_col1\" class=\"data row2 col1\" >year, dlrs, end, expect, report, early, total, month, period, week</td>\n",
       "                        <td id=\"T_c6a7029e_ca35_11ea_b6b7_784f434fb9dcrow2_col2\" class=\"data row2 col2\" >3.190000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_c6a7029e_ca35_11ea_b6b7_784f434fb9dcrow3_col0\" class=\"data row3 col0\" >3</td>\n",
       "                        <td id=\"T_c6a7029e_ca35_11ea_b6b7_784f434fb9dcrow3_col1\" class=\"data row3 col1\" >ct, loss, net, profit, dlrs, note, include, mln, gain, sale</td>\n",
       "                        <td id=\"T_c6a7029e_ca35_11ea_b6b7_784f434fb9dcrow3_col2\" class=\"data row3 col2\" >21.210000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_c6a7029e_ca35_11ea_b6b7_784f434fb9dcrow4_col0\" class=\"data row4 col0\" >4</td>\n",
       "                        <td id=\"T_c6a7029e_ca35_11ea_b6b7_784f434fb9dcrow4_col1\" class=\"data row4 col1\" >rise, fall, year, growth, increase, deficit, show, figure, decline, month</td>\n",
       "                        <td id=\"T_c6a7029e_ca35_11ea_b6b7_784f434fb9dcrow4_col2\" class=\"data row4 col2\" >6.150000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_c6a7029e_ca35_11ea_b6b7_784f434fb9dcrow5_col0\" class=\"data row5 col0\" >5</td>\n",
       "                        <td id=\"T_c6a7029e_ca35_11ea_b6b7_784f434fb9dcrow5_col1\" class=\"data row5 col1\" >oil, price, production, crude, increase, industry, barrel, contract, raise, gold</td>\n",
       "                        <td id=\"T_c6a7029e_ca35_11ea_b6b7_784f434fb9dcrow5_col2\" class=\"data row5 col2\" >6.730000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_c6a7029e_ca35_11ea_b6b7_784f434fb9dcrow6_col0\" class=\"data row6 col0\" >6</td>\n",
       "                        <td id=\"T_c6a7029e_ca35_11ea_b6b7_784f434fb9dcrow6_col1\" class=\"data row6 col1\" >tonne, export, wheat, import, grain, crop, program, corn, estimate, production</td>\n",
       "                        <td id=\"T_c6a7029e_ca35_11ea_b6b7_784f434fb9dcrow6_col2\" class=\"data row6 col2\" >7.370000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_c6a7029e_ca35_11ea_b6b7_784f434fb9dcrow7_col0\" class=\"data row7 col0\" >7</td>\n",
       "                        <td id=\"T_c6a7029e_ca35_11ea_b6b7_784f434fb9dcrow7_col1\" class=\"data row7 col1\" >bank, interest, tax, debt, loan, payment, credit, capital, increase, issue</td>\n",
       "                        <td id=\"T_c6a7029e_ca35_11ea_b6b7_784f434fb9dcrow7_col2\" class=\"data row7 col2\" >3.550000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_c6a7029e_ca35_11ea_b6b7_784f434fb9dcrow8_col0\" class=\"data row8 col0\" >8</td>\n",
       "                        <td id=\"T_c6a7029e_ca35_11ea_b6b7_784f434fb9dcrow8_col1\" class=\"data row8 col1\" >offer, company, make, plan, group, merger, bid, tender, propose, proposal</td>\n",
       "                        <td id=\"T_c6a7029e_ca35_11ea_b6b7_784f434fb9dcrow8_col2\" class=\"data row8 col2\" >6.720000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_c6a7029e_ca35_11ea_b6b7_784f434fb9dcrow9_col0\" class=\"data row9 col0\" >9</td>\n",
       "                        <td id=\"T_c6a7029e_ca35_11ea_b6b7_784f434fb9dcrow9_col1\" class=\"data row9 col1\" >spokesman, state, today, official, source, government, ship, strike, work, day</td>\n",
       "                        <td id=\"T_c6a7029e_ca35_11ea_b6b7_784f434fb9dcrow9_col2\" class=\"data row9 col2\" >3.650000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_c6a7029e_ca35_11ea_b6b7_784f434fb9dcrow10_col0\" class=\"data row10 col0\" >10</td>\n",
       "                        <td id=\"T_c6a7029e_ca35_11ea_b6b7_784f434fb9dcrow10_col1\" class=\"data row10 col1\" >share, stock, company, common, dividend, acquire, record, shareholder, cash, pay</td>\n",
       "                        <td id=\"T_c6a7029e_ca35_11ea_b6b7_784f434fb9dcrow10_col2\" class=\"data row10 col2\" >12.090000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_c6a7029e_ca35_11ea_b6b7_784f434fb9dcrow11_col0\" class=\"data row11 col0\" >11</td>\n",
       "                        <td id=\"T_c6a7029e_ca35_11ea_b6b7_784f434fb9dcrow11_col1\" class=\"data row11 col1\" >trade, official, government, japanese, country, import, foreign, industry, economic, policy</td>\n",
       "                        <td id=\"T_c6a7029e_ca35_11ea_b6b7_784f434fb9dcrow11_col2\" class=\"data row11 col2\" >4.830000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_c6a7029e_ca35_11ea_b6b7_784f434fb9dcrow12_col0\" class=\"data row12 col0\" >12</td>\n",
       "                        <td id=\"T_c6a7029e_ca35_11ea_b6b7_784f434fb9dcrow12_col1\" class=\"data row12 col1\" >buy, analyst, firm, market, investment, sell, give, make, base, add</td>\n",
       "                        <td id=\"T_c6a7029e_ca35_11ea_b6b7_784f434fb9dcrow12_col2\" class=\"data row12 col2\" >3.610000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_c6a7029e_ca35_11ea_b6b7_784f434fb9dcrow13_col0\" class=\"data row13 col0\" >13</td>\n",
       "                        <td id=\"T_c6a7029e_ca35_11ea_b6b7_784f434fb9dcrow13_col1\" class=\"data row13 col1\" >rate, market, dollar, bank, exchange, currency, cut, money, yen, dealer</td>\n",
       "                        <td id=\"T_c6a7029e_ca35_11ea_b6b7_784f434fb9dcrow13_col2\" class=\"data row13 col2\" >7.120000</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x130e93710>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mallet_topic_prop = get_topic_distribution(mallet_topic_df)\n",
    "mallet_topic_prop.style.hide_index().background_gradient(subset='Proportion',cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Comparison\n",
    "\n",
    "#### Verification\n",
    "\n",
    "We can verify the relevance of the keywords generated from our topic models and the known labels against the actual text. For example, with the first text which is labeled as `trade` the related topic keywords for the topic models are:\n",
    "\n",
    "- Gensim: say, year, rate, rise, quarter, expect, growth, first, earning, increase (topic 0: 45% of articles are related)\n",
    "- MALLET: trade official government japanese country import foreign industry economic policy (topic 11: 4.8% of articles are related)\n",
    "\n",
    "This tells us that the MALLET model is able to discern topics are that particularly related to japanese trade. In the case of the article below, this is spot on as is evident from the first couple of sentences. Meanwhile, the Gensim model is classifying this article in a larger mass of articles not limited to Japan.\n",
    "\n",
    "We also find an odd repetition of the word say in the gensim keywords. This can be attributed to articles referencing other others but should have been filtered out as too common for each topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary dataframe with keywords from each model vs known categories\n",
    "summary_df = pd.concat([df['Category'], gensim_topic_df['Keywords'], mallet_topic_df['Keywords']], axis=1, sort=False)\n",
    "summary_df.columns = ['Reuters categories','Gensim keywords','MALLET keywords']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reuters categories</th>\n",
       "      <th>Gensim keywords</th>\n",
       "      <th>MALLET keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[trade]</td>\n",
       "      <td>say, year, rate, rise, quarter, expect, growth...</td>\n",
       "      <td>trade, official, government, japanese, country...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[grain]</td>\n",
       "      <td>say, crop, year, deficit, soybean, estimate, l...</td>\n",
       "      <td>tonne, export, wheat, import, grain, crop, pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[crude, nat-gas]</td>\n",
       "      <td>say, year, oil, price, production, last, would...</td>\n",
       "      <td>oil, price, production, crude, increase, indus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[corn, grain, rice, rubber, sugar, tin, trade]</td>\n",
       "      <td>say, year, rate, rise, quarter, expect, growth...</td>\n",
       "      <td>rise, fall, year, growth, increase, deficit, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[palm-oil, veg-oil]</td>\n",
       "      <td>say, trade, would, export, official, governmen...</td>\n",
       "      <td>tonne, export, wheat, import, grain, crop, pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10783</th>\n",
       "      <td>[interest, money-fx]</td>\n",
       "      <td>say, bank, market, rise, dollar, rate, dealer,...</td>\n",
       "      <td>rate, market, dollar, bank, exchange, currency...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10784</th>\n",
       "      <td>[earn]</td>\n",
       "      <td>say, year, rate, rise, quarter, expect, growth...</td>\n",
       "      <td>ct, loss, net, profit, dlrs, note, include, ml...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10785</th>\n",
       "      <td>[earn]</td>\n",
       "      <td>say, year, rate, rise, quarter, expect, growth...</td>\n",
       "      <td>ct, loss, net, profit, dlrs, note, include, ml...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10786</th>\n",
       "      <td>[earn]</td>\n",
       "      <td>say, company, share, offer, would, buy, stock,...</td>\n",
       "      <td>ct, loss, net, profit, dlrs, note, include, ml...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10787</th>\n",
       "      <td>[earn]</td>\n",
       "      <td>say, year, rate, rise, quarter, expect, growth...</td>\n",
       "      <td>price, agreement, meeting, producer, market, t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10788 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Reuters categories  \\\n",
       "0                                             [trade]   \n",
       "1                                             [grain]   \n",
       "2                                    [crude, nat-gas]   \n",
       "3      [corn, grain, rice, rubber, sugar, tin, trade]   \n",
       "4                                 [palm-oil, veg-oil]   \n",
       "...                                               ...   \n",
       "10783                            [interest, money-fx]   \n",
       "10784                                          [earn]   \n",
       "10785                                          [earn]   \n",
       "10786                                          [earn]   \n",
       "10787                                          [earn]   \n",
       "\n",
       "                                         Gensim keywords  \\\n",
       "0      say, year, rate, rise, quarter, expect, growth...   \n",
       "1      say, crop, year, deficit, soybean, estimate, l...   \n",
       "2      say, year, oil, price, production, last, would...   \n",
       "3      say, year, rate, rise, quarter, expect, growth...   \n",
       "4      say, trade, would, export, official, governmen...   \n",
       "...                                                  ...   \n",
       "10783  say, bank, market, rise, dollar, rate, dealer,...   \n",
       "10784  say, year, rate, rise, quarter, expect, growth...   \n",
       "10785  say, year, rate, rise, quarter, expect, growth...   \n",
       "10786  say, company, share, offer, would, buy, stock,...   \n",
       "10787  say, year, rate, rise, quarter, expect, growth...   \n",
       "\n",
       "                                         MALLET keywords  \n",
       "0      trade, official, government, japanese, country...  \n",
       "1      tonne, export, wheat, import, grain, crop, pro...  \n",
       "2      oil, price, production, crude, increase, indus...  \n",
       "3      rise, fall, year, growth, increase, deficit, s...  \n",
       "4      tonne, export, wheat, import, grain, crop, pro...  \n",
       "...                                                  ...  \n",
       "10783  rate, market, dollar, bank, exchange, currency...  \n",
       "10784  ct, loss, net, profit, dlrs, note, include, ml...  \n",
       "10785  ct, loss, net, profit, dlrs, note, include, ml...  \n",
       "10786  ct, loss, net, profit, dlrs, note, include, ml...  \n",
       "10787  price, agreement, meeting, producer, market, t...  \n",
       "\n",
       "[10788 rows x 3 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASIAN EXPORTERS FEAR DAMAGE FROM U.S.-JAPAN RIFT\n",
      "  Mounting trade friction between the\n",
      "  U.S. And Japan has raised fears among many of Asia's exporting\n",
      "  nations that the row could inflict far-reaching economic\n",
      "  damage, businessmen and officials said.\n",
      "      They told Reuter correspondents in Asian capitals a U.S.\n",
      "  Move against Japan might boost protectionist sentiment in the\n",
      "  U.S. And lead to curbs on American imports of their products.\n",
      "      But some exporters said that while the conflict would hurt\n",
      "  them in the long-run, in the short-term Tokyo's loss might be\n",
      "  their gain.\n",
      "      The U.S. Has said it will impose 300 mln dlrs of tariffs on\n",
      "  imports of Japanese electronics goods on April 17, in\n",
      "  retaliation for Japan's alleged failure to stick to a pact not\n",
      "  to sell semiconductors on world markets at below cost.\n",
      "      Unofficial Japanese estimates put the impact of the tariffs\n",
      "  at 10 billion dlrs and spokesmen for major electronics firms\n",
      "  said they would virtually halt exports\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[0,3][:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Model\n",
    "\n",
    "Based on the maximum coherence achieved of 0.527, we select the optimal MALLET model for further use in network analysis in the following secction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print chosen dataframe to csv file\n",
    "mallet_topic_df.to_csv('mallet_df.csv', index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Analysis\n",
    "\n",
    "- Expecting a disconnected graph with num_topics central nodes with edges to articles. \n",
    "- Get the top 5 largest subgraphs which represent the most common topics (degree centrality)\n",
    "- From the most popular topics, suggest next 5 articles to read by looking at edge weight (likelyhood)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dataframe from csv file and build a graph from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import networkx.algorithms.bipartite as bipartite\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_full = nx.from_pandas_edgelist(art_topic_keywords,'article','best_topic')\n",
    "G_full.graph['name'] = 'Full bipartite graph'\n",
    "print(nx.info(G_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'Graph is bipartite: {} \\nGraph is connected: {} \\nNumber of connected components {}'\n",
    "print(s.format(nx.is_bipartite(G_full), nx.is_connected(G_full), nx.number_connected_components(G_full)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify connected components with greater than five nodes\n",
    "sorted([len(c) for c in nx.connected_components(G_full) if len(c) > 5], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract subgraphs\n",
    "def get_subgraphs(graph):\n",
    "    \n",
    "    subgraphs = [(graph.subgraph(c),len(c)) for c in nx.connected_components(graph) if len(c) > 5] # networkx 2.4\n",
    "    return sorted(subgraphs, key = lambda x: x[1], reverse=True)\n",
    "\n",
    "# Create connected subgraphs and confirm\n",
    "subgraphs = get_subgraphs(G_full)\n",
    "print(*subgraphs[:5], '\\n', sep='\\n')\n",
    "\n",
    "# Isolate the largest subgraph\n",
    "largest_subg = subgraphs[0][0]\n",
    "largest_subg.graph['name'] = 'Main bipartite subgraph'\n",
    "print(nx.info(largest_subg), \"\\n\")\n",
    "\n",
    "# Verify largest subgraph is bipartite\n",
    "G = largest_subg\n",
    "print('Graph is bipartite: {} \\nGraph is connected: {} \\n'.format(nx.is_bipartite(G), nx.is_connected(G)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source node labels\n",
    "graph = G\n",
    "articles, topics = nx.bipartite.sets(graph)\n",
    "\n",
    "# Plot graph by node type\n",
    "# Apply plot settings\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "plt.rcParams['figure.figsize'] = (24,12)\n",
    "plt.axis('off')\n",
    "pos = nx.spring_layout(graph)\n",
    "nx.draw_networkx_nodes(graph, pos, nodelist=articles, node_color='red', alpha = 0.4)\n",
    "nx.draw_networkx_nodes(graph, pos, nodelist=topics, node_color='blue', alpha = 0.4, node_size = 1000)\n",
    "nx.draw_networkx_edges(graph, pos, alpha = 0.4)\n",
    "nx.draw_networkx_labels(graph, pos);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "In this project we combined techniques from topic modeling identify the topics of nearly 11,000 articles in the Reuters news corpus, and then employed network analysis to see how they are thematically related to one another.\n",
    "\n",
    "We used NLTK, Spacy, Gensim, and MALLET to generate and tune two unsupervised models.  We optimized the number of topics (a key hyperparameter) in our LDA model based on topic coherence, and chose the MALLET model over Gensim model given its tigher, more interpretable topics.\n",
    "\n",
    "(VT: to add in network analysis findings)\n",
    "We used network analysis to visualize how ...\n",
    "Generate a bipartite, weighted (on likelyhood of belonging to the most domiant topic) graph of articles and topics, and analyze its topology to identify relationships between topics\n",
    "\n",
    "### Findings\n",
    "\n",
    "(MI: Add mallet and topic distribution conclusions)\n",
    "\n",
    "Evaluating a model based on hold-out likelihood, or it's ability to predict words in a given unseen text based on topics.  \n",
    "Predictive power as revealed by a metric like perplexity has been found to lead model complexity rather than interpretability. (['Applications of Topic Models'](https://mimno.infosci.cornell.edu/papers/2017_fntir_tm_applications.pdf)), which is antithetical to Topic Models use case. \n",
    "\n",
    "Coherence is premised on the idea that word co-occurence statistics demonstrate relationships between words, and that this is a signal of the thematic coherence of a topic (['Interpretable Machine Learning: Lessons from Topic Modeling'](https://cmci.colorado.edu/~mpaul/files/chi16hcml_interpretable.pdf). When compared with the optimized Gensim LDA model., the greater coherence of our Mallet LDA model is apparent in a qualitative assessment of topic keywords.  That is, the model that yielded a stronger coherence metrics had topics that felt more thematically unified.\n",
    "\n",
    "In addition to coherence, the literature suggests that human evaluation and feedback can be important to tuning topic models.  For example, 'consensus measures how well the results of a crowdsourcing approach or generated by a group of human subjects match those given categories of topics' (['In Search of Coherence and Consensus: Measuring the Interpretability of Staistical Topics'](http://www.jmlr.org/papers/volume18/17-069/17-069.pdf)).\n",
    "\n",
    "### Potential Future Avenues\n",
    "\n",
    "- For faster performance and better topic segregation, implement an improved LDA topic model using [MALLET](http://mallet.cs.umass.edu/topics.php) with a Gensim wrapper\n",
    "- Improve the performance of topic modeling using provided labeling article topic labels using an supervised implementation supporting multiple labels ([LLDA](http://www.mimno.org/articles/labelsandpatterns/))\n",
    "- Consider implementing an HDP model to use posterior inference to guide the number of topics. ([Hierarchical Dirichlect Process (HDP)](https://medium.com/square-corner-blog/topic-modeling-optimizing-for-human-interpretability-48a81f6ce0ed))\n",
    "- Alternatively, to perform network analysis of the relationships between authors and topics, consider replacing the Reuters corpus with another source of news articles with authorship labels\n",
    "- Consider implementing a community detection approach to topic modeling like Hierarchical Stochastic Block Modeling ([hSBM](https://advances.sciencemag.org/content/4/7/eaaq1360))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YouTube"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(JO video on setup, data prep, and Gensim training sections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(MI video on MALLET training, topic model conmparison / analysis / viz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(VT video on network analysis and conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pyLDAvis Topic Prevalence and Distribution \n",
    "\n",
    "For commentary: https://towardsdatascience.com/topic-modelling-in-python-with-nltk-and-gensim-4ef03213cd21\n",
    "\n",
    "In this visualization, we can analyze saliency (how much the term tells you about the topic), relevance (a weighted average of the probability of the word given the topic and the word given the topic normalized by the probability of the topic). The size of the bubble indicates the importance of the topics, relative to the data.\n",
    "\n",
    "Customize content to actual vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(gensim_optimal_model, corpus, id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Modeling\n",
    "\n",
    "- https://en.wikipedia.org/wiki/Topic_model\n",
    "- https://medium.com/@soorajsubrahmannian/extracting-hidden-topics-in-a-corpus-55b2214fc17d\n",
    "- http://dirichlet.net/pdf/wallach06topic.pdf\n",
    "- Applied Topic Modeling: https://cfss.uchicago.edu/notes/topic-modeling/\n",
    "- https://springerplus.springeropen.com/articles/10.1186/s40064-016-3252-8\n",
    "- https://mimno.infosci.cornell.edu/papers/2017_fntir_tm_applications.pdf\n",
    "- https://people.cs.umass.edu/~mccallum/papers/tng-icdm07.pdf\n",
    "- https://hookedondata.org/topic-modeling-the-new-york-times-and-trump/\n",
    "\n",
    "### LDA (Latent Dirichlet Allocation)\n",
    "\n",
    "- https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation\n",
    "- https://en.wikipedia.org/wiki/Dirichlet_distribution\n",
    "- http://dirichlet.net/pdf/wallach09rethinking.pdf\n",
    "- https://medium.com/@lettier/how-does-lda-work-ill-explain-using-emoji-108abf40fa7d\n",
    "- https://towardsdatascience.com/light-on-math-machine-learning-intuitive-guide-to-latent-dirichlet-allocation-437c81220158\n",
    "- LDA training: https://markroxor.github.io/gensim/static/notebooks/lda_training_tips.html\n",
    "- LDA model tuning: https://www.thoughtvector.io/blog/lda-alpha-and-beta-parameters-the-intuition/\n",
    "- https://www.machinelearningplus.com/nlp/topic-modeling-visualization-how-to-present-results-lda-models/#6.-What-is-the-Dominant-topic-and-its-percentage-contribution-in-each-document\n",
    "\n",
    "### Perplexity, Coherence, Interpretability\n",
    "\n",
    "- https://en.wikipedia.org/wiki/Perplexity \n",
    "- Perplexity math: http://qpleple.com/perplexity-to-evaluate-topic-models/\n",
    "- Optimizing perplexity: https://cfss.uchicago.edu/notes/topic-modeling/ \n",
    "- https://towardsdatascience.com/evaluate-topic-model-in-python-latent-dirichlet-allocation-lda-7d57484bb5d0\n",
    "- Coherentce, intrinsic / extrinsic measures and math: http://qpleple.com/topic-coherence-to-evaluate-topic-models/ \n",
    "- https://medium.com/@soorajsubrahmannian/extracting-hidden-topics-in-a-corpus-55b2214fc17d\n",
    "- https://mimno.infosci.cornell.edu/info6150/readings/N10-1012.pdf (automatic topic coherence evaluation)\n",
    "- https://medium.com/square-corner-blog/topic-modeling-optimizing-for-human-interpretability-48a81f6ce0ed\n",
    "- https://cmci.colorado.edu/~mpaul/files/chi16hcml_interpretable.pdf (interpretability)\n",
    "- https://www.researchgate.net/publication/327888131_Four_Keys_to_Topic_Interpretability_in_Topic_Modeling_7th_International_Conference_AINL_2018_St_Petersburg_Russia_October_17-19_2018_Proceedings\n",
    "- https://papers.nips.cc/paper/3700-reading-tea-leaves-how-humans-interpret-topic-models.pdf\n",
    "- http://www.jmlr.org/papers/volume18/17-069/17-069.pdf\n",
    "- https://radimrehurek.com/gensim/models/coherencemodel.html\n",
    "\n",
    "### Gensim (Generate Similar)\n",
    "\n",
    "- https://radimrehurek.com/gensim/about.html\n",
    "https://radimrehurek.com/gensim/models/ldamodel.html#gensim.models.ldamodel.LdaModel.show_topic \n",
    "https://stackabuse.com/python-for-nlp-working-with-the-gensim-library-part-2/\n",
    "- https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/\n",
    "- https://www.machinelearningplus.com/nlp/topic-modeling-visualization-how-to-present-results-lda-models/\n",
    "https://www.thinkinfi.com/2019/08/LDA-Gensim-Python.html\n",
    "- https://towardsdatascience.com/topic-modelling-in-python-with-nltk-and-gensim-4ef03213cd21\n",
    "- https://towardsdatascience.com/building-a-topic-modeling-pipeline-with-spacy-and-gensim-c5dc03ffc619\n",
    "\n",
    "### Spacy\n",
    "\n",
    "- https://spacy.io/\n",
    "- https://github.com/explosion/spacy-models\n",
    "- https://stackabuse.com/python-for-nlp-tokenization-stemming-and-lemmatization-with-spacy-library/\n",
    "- https://medium.com/@AravindR07/nlp-using-spacy-and-topic-modeling-using-gensim-python-42c4574830d\n",
    "\n",
    "### MALLET (MAchine Learning for LanguagE Toolkit\n",
    "\n",
    "- http://mallet.cs.umass.edu/topics.php\n",
    "- https://radimrehurek.com/gensim/models/wrappers/ldamallet.html\n",
    "- https://www.thinkinfi.com/2019/08/LDA-Gensim-Python.html\n",
    "- https://github.com/ANRChapitres/topic_modelling_mallet\n",
    "\n",
    "### Text Network Analysis\n",
    "\n",
    "- https://advances.sciencemag.org/content/4/7/eaaq1360\n",
    "- https://noduslabs.com/wp-content/uploads/2019/06/InfraNodus-Paranyushkin-WWW19-Conference.pdf\n",
    "- https://noduslabs.com/cases/tutorial-lda-text-mining-network-analysis/\n",
    "- https://github.com/michal-pikusa/text-network-analysis\n",
    "- https://github.com/martingerlach/hSBM_Topicmodel/blob/master/TopSBM-tutorial.ipynb\n",
    "\n",
    "### Other Methods\n",
    "\n",
    "- Labelled LDA: http://www.mimno.org/articles/labelsandpatterns/\n",
    "- Hierarchical Dirichlet Process: http://mlg.eng.cam.ac.uk/tutorials/07/ywt.pdf\n",
    "- Hierarchical Stochastic Block Models: https://github.com/martingerlach/hSBM_Topicmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
