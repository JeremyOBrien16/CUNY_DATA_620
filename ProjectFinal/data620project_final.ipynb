{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA 620 - Final Project\n",
    "\n",
    "Jeremy OBrien, Mael Illien, Vanita Thompson\n",
    "\n",
    "## Topic Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "A powerful analytical application of NLP is topic modeling, which identifies the themes present in a corpus comprised of multiple documents based on the words in those documents. Because it can be used to uncover the thematic structure in documents, topic modeling has an array of applications in information retrieval and document mining.\n",
    "\n",
    "Topics are 'probability distributions over a fixed vocabulary'. An overview of topic modeling and its current applications in bioinformatics, and it's common to use probabilistic generative models derived from LDA (Latent Dirichlet Allocation) to model in an unsupervised fashion the latent semantic structure of documents. Topic models can be tuned and optimized in a variety of ways, including improving how topics are segregated from each other and calibrating for a useful number of topics.\n",
    "\n",
    "### Research Question\n",
    "We will combine techniques from topic modeling and network analysis to address this question.\n",
    "\n",
    "Given a text corpus comprised of multiple documents, what are the topics of those documents and how are the documents thematically related to one another?\n",
    "\n",
    "### Approach\n",
    "- Leverage the Reuters news corpus of nearly 11,000 articles (labeled with at least one category each; unfortunately, authorship is not labeled)\n",
    "- Using the NLTK, Spacy, and Gensim packages, implement and tune an unsupervised LDA-based topic model (i.e. without reference to the provided article topic labels)\n",
    "- Analyze model perplexity and coherence, overall topic prevalence, and topic distribution across articles\n",
    "- Generate a bipartite, weighted (likely on coherence) graph of articles and topics, and analyze its topology to identify relationships between topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import reuters\n",
    "\n",
    "import spacy  # need to install\n",
    "\n",
    "import gensim  # need to install\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "# warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import & Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data import and preliminary EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'shipment', 'was', 'for', 'April', '8', 'to', '20', 'delivery', '.']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NLTK Reuters corpus test\n",
    "from nltk.corpus import reuters\n",
    "reuters.fileids()\n",
    "reuters.words('test/14841')[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are 25 sampled categoies from the Reuters corpus. These correspond to themes/topics assigned to documents in the corpus and are essentially labels for the articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['earn',\n",
       " 'sun-meal',\n",
       " 'silver',\n",
       " 'carcass',\n",
       " 'wheat',\n",
       " 'groundnut',\n",
       " 'l-cattle',\n",
       " 'rapeseed',\n",
       " 'sunseed',\n",
       " 'sorghum',\n",
       " 'cotton-oil',\n",
       " 'jet',\n",
       " 'iron-steel',\n",
       " 'livestock',\n",
       " 'copper',\n",
       " 'potato',\n",
       " 'wpi',\n",
       " 'cotton-oil',\n",
       " 'oilseed',\n",
       " 'housing',\n",
       " 'rice',\n",
       " 'sun-oil',\n",
       " 'cpu',\n",
       " 'gnp',\n",
       " 'dmk']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choices(reuters.categories(),k=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust to generate dataframe directly from nltk corpus\n",
    "# https://stackoverflow.com/questions/46109166/converting-categorizedplaintextcorpusreader-into-dataframe\n",
    "news = []\n",
    "for fileid in reuters.fileids():\n",
    "    tag, filename = fileid.split('/')\n",
    "    news.append((filename, tag, reuters.categories(fileid), reuters.raw(fileid)))\n",
    "\n",
    "df = pd.DataFrame(news, columns=['filename', 'tag', 'categories','text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>tag</th>\n",
       "      <th>categories</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14826</td>\n",
       "      <td>test</td>\n",
       "      <td>[trade]</td>\n",
       "      <td>ASIAN EXPORTERS FEAR DAMAGE FROM U.S.-JAPAN RI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14828</td>\n",
       "      <td>test</td>\n",
       "      <td>[grain]</td>\n",
       "      <td>CHINA DAILY SAYS VERMIN EAT 7-12 PCT GRAIN STO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14829</td>\n",
       "      <td>test</td>\n",
       "      <td>[crude, nat-gas]</td>\n",
       "      <td>JAPAN TO REVISE LONG-TERM ENERGY DEMAND DOWNWA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14832</td>\n",
       "      <td>test</td>\n",
       "      <td>[corn, grain, rice, rubber, sugar, tin, trade]</td>\n",
       "      <td>THAI TRADE DEFICIT WIDENS IN FIRST QUARTER\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14833</td>\n",
       "      <td>test</td>\n",
       "      <td>[palm-oil, veg-oil]</td>\n",
       "      <td>INDONESIA SEES CPO PRICE RISING SHARPLY\\n  Ind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10783</th>\n",
       "      <td>999</td>\n",
       "      <td>training</td>\n",
       "      <td>[interest, money-fx]</td>\n",
       "      <td>U.K. MONEY MARKET SHORTAGE FORECAST REVISED DO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10784</th>\n",
       "      <td>9992</td>\n",
       "      <td>training</td>\n",
       "      <td>[earn]</td>\n",
       "      <td>KNIGHT-RIDDER INC &amp;lt;KRN&gt; SETS QUARTERLY\\n  Q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10785</th>\n",
       "      <td>9993</td>\n",
       "      <td>training</td>\n",
       "      <td>[earn]</td>\n",
       "      <td>TECHNITROL INC &amp;lt;TNL&gt; SETS QUARTERLY\\n  Qtly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10786</th>\n",
       "      <td>9994</td>\n",
       "      <td>training</td>\n",
       "      <td>[earn]</td>\n",
       "      <td>NATIONWIDE CELLULAR SERVICE INC &amp;lt;NCEL&gt; 4TH ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10787</th>\n",
       "      <td>9995</td>\n",
       "      <td>training</td>\n",
       "      <td>[earn]</td>\n",
       "      <td>&amp;lt;A.H.A. AUTOMOTIVE TECHNOLOGIES CORP&gt; YEAR ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10788 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      filename       tag                                      categories  \\\n",
       "0        14826      test                                         [trade]   \n",
       "1        14828      test                                         [grain]   \n",
       "2        14829      test                                [crude, nat-gas]   \n",
       "3        14832      test  [corn, grain, rice, rubber, sugar, tin, trade]   \n",
       "4        14833      test                             [palm-oil, veg-oil]   \n",
       "...        ...       ...                                             ...   \n",
       "10783      999  training                            [interest, money-fx]   \n",
       "10784     9992  training                                          [earn]   \n",
       "10785     9993  training                                          [earn]   \n",
       "10786     9994  training                                          [earn]   \n",
       "10787     9995  training                                          [earn]   \n",
       "\n",
       "                                                    text  \n",
       "0      ASIAN EXPORTERS FEAR DAMAGE FROM U.S.-JAPAN RI...  \n",
       "1      CHINA DAILY SAYS VERMIN EAT 7-12 PCT GRAIN STO...  \n",
       "2      JAPAN TO REVISE LONG-TERM ENERGY DEMAND DOWNWA...  \n",
       "3      THAI TRADE DEFICIT WIDENS IN FIRST QUARTER\\n  ...  \n",
       "4      INDONESIA SEES CPO PRICE RISING SHARPLY\\n  Ind...  \n",
       "...                                                  ...  \n",
       "10783  U.K. MONEY MARKET SHORTAGE FORECAST REVISED DO...  \n",
       "10784  KNIGHT-RIDDER INC &lt;KRN> SETS QUARTERLY\\n  Q...  \n",
       "10785  TECHNITROL INC &lt;TNL> SETS QUARTERLY\\n  Qtly...  \n",
       "10786  NATIONWIDE CELLULAR SERVICE INC &lt;NCEL> 4TH ...  \n",
       "10787  &lt;A.H.A. AUTOMOTIVE TECHNOLOGIES CORP> YEAR ...  \n",
       "\n",
       "[10788 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output with print\n",
    "\n",
    "# 10,788 separate cases (news articles)\n",
    "# df.shape\n",
    "# len(df.filename.unique())\n",
    "\n",
    "# Each case is tagged as either train or test\n",
    "# df.tag.unique()\n",
    "\n",
    "# There are 10,657 articles with distinct text body - so 131 duplicates\n",
    "# len(df.text.unique())\n",
    "\n",
    "# Check the text body of duplicates (except for first instance)\n",
    "# print(df[df.text.duplicated('first')])\n",
    "\n",
    "# JO: Evaluate cause and consider case for removal\n",
    "# MI: I checked with some of the indexes and found no overlap. See below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df[df.text.duplicated('first')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning and deduplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('G-7 ISSUES STATEMENT AFTER MEETING Following is the text of a statement by '\n",
      " 'the Group of Seven -- the U.S., Japan, West Germany, France, Britain, Italy '\n",
      " 'and Canada -- issued after a Washington meeting yesterday. 1. The finance '\n",
      " 'ministers and central bank governors of seven major industrial countries met '\n",
      " 'today. They continued the process of multilateral surveillance of their '\n",
      " 'economies pursuant to the arrangements for strengthened economic policy '\n",
      " 'coordination agreed at the 1986 Tokyo summit of their heads of state or '\n",
      " 'government. The managing director of the International Monetary Fund also '\n",
      " 'participated in the meeting. 2. The ministers and governors reaffirmed the '\n",
      " 'commitment to the cooperative approach agreed at the recent Paris meeting, '\n",
      " 'and noted the progress achieved in implementing the undertakings embodied in '\n",
      " 'the Louvre Agreement. They agreed, however, that further actions will be '\n",
      " 'essential to resist rising protectionist pressures, sustain global economic '\n",
      " 'expansion, and reduce trade imba')\n"
     ]
    }
   ],
   "source": [
    "# Convert to list\n",
    "data = df['text'].values.tolist()\n",
    "\n",
    "# Remove new line characters\n",
    "data = [re.sub(r'\\s+', ' ', sent) for sent in data]\n",
    "\n",
    "# Remove distracting single quotes\n",
    "data = [re.sub(r\"\\'\", \"\", sent) for sent in data]\n",
    "\n",
    "pprint(data[330][:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('JAPAN BUSINESS LEADERS SAY G-7 ACCORD IS WORRYING The leaders of two of '\n",
      " 'Japans top business groups said in separate statements the Group of Seven '\n",
      " '(G-7) accord reached in Washington yesterday is of deep concern to Japan '\n",
      " 'because it shows the major industrial nations regard the yens current level '\n",
      " 'as appropriate. Eishiro Saito, chairman of the Federation of Economic '\n",
      " 'Organizations (Keidanren), said the yens present rate is well above adequate '\n",
      " 'levels. He did not elaborate. Takashi Ishihara, chairman of the Japan '\n",
      " 'Committee for Economic Development, said the accord will not prevent the yen '\n",
      " 'from rising further. \"We do not understand why the G-7 approved present '\n",
      " 'rates as the yen has risen excessively since the Paris accord,\" Ishihara '\n",
      " 'said. G-7 members Britain, Canada, France, Italy, Japan, the U.S. And West '\n",
      " 'Germany said in a statement they consider their currencies are now within '\n",
      " 'ranges broadly consistent with economic fundamentals. Saito called on each '\n",
      " 'G-7 member nation to prepare to intervene ')\n"
     ]
    }
   ],
   "source": [
    "pprint(data[333][:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text preparation and feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize words and clean up text\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "data_words = list(sent_to_words(data))\n",
    "\n",
    "print(data_words[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "# See trigram example\n",
    "print(trigram_mod[bigram_mod[data_words[0]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "# JO: Confirm if these / other stopwords should be added\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stop words\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "\n",
    "# Form bigrams\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "# python3 -m spacy download en\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n",
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_lemmatized[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary and corpus for topic modeling\n",
    "\n",
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "# Create Corpus\n",
    "texts = data_lemmatized\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "# View\n",
    "print(corpus[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling & Distribution using Gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary Topic Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JO: May eliminate in favor of iterative approach to select optimal number of topics below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build topic model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,  # TDF corpus\n",
    "                                           id2word=id2word,  # dictionary\n",
    "                                           num_topics=20,  # provisionally set to 20, to be optimized\n",
    "                                           random_state=100,  # [CONFIRM]\n",
    "                                           update_every=1,  # how often paramater should be updated\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,  # total number of training passes\n",
    "                                           alpha='auto',  # learn assymetric alpha from training data\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View topics in LDA model\n",
    "pprint(lda_model.print_topics())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing Perplexity and Coherence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perplexity is measure of how well probability distribution / model predicts score\n",
    "https://en.wikipedia.org/wiki/Perplexity\n",
    "\n",
    "https://cfss.uchicago.edu/notes/topic-modeling/, provides examples on optimizing perplexity\n",
    "\n",
    "Coherence is the degree of semantic similarity bnetween high scoring keywords in the topic\n",
    "https://towardsdatascience.com/evaluate-topic-model-in-python-latent-dirichlet-allocation-lda-7d57484bb5d0\n",
    "\n",
    "http://qpleple.com/topic-coherence-to-evaluate-topic-models/, provide intrinsic and extrinsic measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute model perplexity and coherence score\n",
    "\n",
    "# Compute perplexity\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))\n",
    "\n",
    "# Compute coherence score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, \n",
    "                                     texts=data_lemmatized, \n",
    "                                     dictionary=id2word, \n",
    "                                     coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "\n",
    "print('\\nCoherence Score', coherence_lda )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing Number of Topics Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider splitting the model function and the optimization\n",
    "\n",
    "# Find optimal number of topics\n",
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        # model = gensim.models.wrappers.LdaMallet(mallet_path, \n",
    "                                                 # corpus=corpus, \n",
    "                                                 # num_topics=num_topics, \n",
    "                                                 # id2word=id2word)\n",
    "        \n",
    "        model = gensim.models.ldamodel.LdaModel(corpus=corpus,  # TDF corpus\n",
    "                                           id2word=id2word,  # dictionary\n",
    "                                           num_topics=num_topics,  # to be optimized\n",
    "                                           random_state=100,  # [CONFIRM]\n",
    "                                           # update_every=1,  # how often paramater should be updated\n",
    "                                           # chunksize=100,\n",
    "                                           # passes=10,  # total number of training passes\n",
    "                                           # alpha='auto',  # learn assymetric alpha from training data\n",
    "                                           per_word_topics=True)\n",
    "        \n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values\n",
    "\n",
    "# Iterate to find optimal model\n",
    "model_list, coherence_values = compute_coherence_values(dictionary=id2word, \n",
    "                                                        corpus=corpus, \n",
    "                                                        texts=data_lemmatized, \n",
    "                                                        start=2, \n",
    "                                                        limit=40, \n",
    "                                                        step=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph iterations\n",
    "limit=40; start=2; step=6\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel('Num Topics')\n",
    "plt.ylabel('Coherence score')\n",
    "plt.legend(('coherence_values'), loc='best')\n",
    "plt.show()\n",
    "\n",
    "for m, cv in zip(x, coherence_values):\n",
    "    print('Num topics=', m, ' has coherence value of', round(cv, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set n to optimal model\n",
    "n = 4\n",
    "optimal_model= model_list[n]\n",
    "model_topics = optimal_model.show_topics(formatted=False)\n",
    "pprint(optimal_model.print_topics(num_words=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Prevalence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JO: troubleshoot TypeError:  https://cs50.stackexchange.com/questions/30671/typeerror-not-supported-between-instances-of-int-and-tuple\n",
    "\n",
    "# Find dominant topic by sentence\n",
    "def format_topics_sentences(ldamodel=lda_model, corpus=corpus, texts=data):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)\n",
    "\n",
    "\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=optimal_model, corpus=corpus, texts=data)\n",
    "\n",
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "\n",
    "# Show\n",
    "df_dominant_topic.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depends on preceding code which needs troubleshooting\n",
    "# Will need to be adjusted for Gensim rather than MALLET\n",
    "\n",
    "# Find most representative document by topic\n",
    "# Group top 5 sentences under each topic\n",
    "sent_topics_sorteddf_mallet = pd.DataFrame()\n",
    "\n",
    "sent_topics_outdf_grpd = df_topic_sents_keywords.groupby('Dominant_Topic')\n",
    "\n",
    "for i, grp in sent_topics_outdf_grpd:\n",
    "    sent_topics_sorteddf_mallet = pd.concat([sent_topics_sorteddf_mallet, \n",
    "                                             grp.sort_values(['Perc_Contribution'], ascending=[0]).head(1)], \n",
    "                                            axis=0)\n",
    "\n",
    "# Reset Index    \n",
    "sent_topics_sorteddf_mallet.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Format\n",
    "sent_topics_sorteddf_mallet.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Text\"]\n",
    "\n",
    "# Show\n",
    "sent_topics_sorteddf_mallet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depends on preceding code which needs troubleshooting\n",
    "# Will need to be adjusted for Gensim rather than MALLET\n",
    "\n",
    "# Evaluate topic distribution across documents\n",
    "\n",
    "# Number of documents by topic\n",
    "topic_counts = df_topic_sents_keywords['Dominant_Topic'].value_counts()\n",
    "\n",
    "# Percentage of documents by topic\n",
    "topic_contribution = round(topic_counts/topic_counts.sum(), 4)\n",
    "\n",
    "# Topic number and keywords\n",
    "topic_num_keywords = df_topic_sents_keywords[['Dominant_Topic', 'Topic_Keywords']]\n",
    "\n",
    "# Concatenate columns\n",
    "df_dominant_topics = pd.concat([topic_num_keywords, topic_counts, topic_contribution], axis=1)\n",
    "\n",
    "# Set column names\n",
    "df_dominant_topics.columns = ['Dominant_Topic', 'Topic_Keywords', 'Num_Documents', 'Perc_Documents']\n",
    "\n",
    "df_dominant_topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic modeling using MALLET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perplexity is measure of how well probability distribution / model predicts score\n",
    "https://en.wikipedia.org/wiki/Perplexity\n",
    "\n",
    "https://cfss.uchicago.edu/notes/topic-modeling/, provides examples on optimizing perplexity\n",
    "\n",
    "Coherence is the degree of semantic similarity bnetween high scoring keywords in the topic\n",
    "https://towardsdatascience.com/evaluate-topic-model-in-python-latent-dirichlet-allocation-lda-7d57484bb5d0\n",
    "\n",
    "http://qpleple.com/topic-coherence-to-evaluate-topic-models/, provide intrinsic and extrinsic measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LDA Mallet model\n",
    "# Tutorial on setup: https://www.thinkinfi.com/2019/08/LDA-Gensim-Python.html\n",
    "mallet_path = './mallet-2.0.8/bin/mallet'  # erroring\n",
    "ldamallet = gensim.models.wrappers.LdaMallet(mallet_path,\n",
    "                                            corpus=corpus,\n",
    "                                            num_topics=20,\n",
    "                                            id2word=id2word)\n",
    "\n",
    "# Show topics\n",
    "pprint(ldamallet.show_topics(formatted=False))\n",
    "\n",
    "# Compute coherence score\n",
    "cpoherence_model_ldamallet = CoherenceModel(model=ldamallet, \n",
    "                                            texts=data_lemmatized,\n",
    "                                            dictionary=id2word, \n",
    "                                            coherence='c_v')\n",
    "coherence_ldamallet = coherence_model_ldamallet.get_coherence()\n",
    "print('\\\n",
    "nCoherence score: ', coherence_ldamallet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YouTube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
