{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA 620 - Final Project\n",
    "\n",
    "Jeremy OBrien, Mael Illien, Vanita Thompson\n",
    "\n",
    "## Topic Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "A powerful analytical application of NLP is topic modeling, which identifies the themes present in a corpus comprised of multiple documents based on the words in those documents. Because it can be used to uncover the thematic structure in documents, topic modeling has an array of applications in information retrieval and document mining.\n",
    "\n",
    "Topics are 'probability distributions over a fixed vocabulary'. An overview of topic modeling and its current applications in bioinformatics, and it's common to use probabilistic generative models derived from LDA (Latent Dirichlet Allocation) to model in an unsupervised fashion the latent semantic structure of documents. Topic models can be tuned and optimized in a variety of ways, including improving how topics are segregated from each other and calibrating for a useful number of topics.\n",
    "\n",
    "### Research Question\n",
    "We will combine techniques from topic modeling and network analysis to address this question.\n",
    "\n",
    "*Given a text corpus comprised of multiple documents, what are the topics of those documents and how are the documents thematically related to one another?*\n",
    "\n",
    "### Approach\n",
    "- Leverage the Reuters news corpus of nearly 11,000 articles (labeled with at least one category each; unfortunately, authorship is not labeled)\n",
    "- Using the NLTK, Spacy, and Gensim packages, implement and tune an unsupervised LDA-based topic model (i.e. without reference to the provided article topic labels)\n",
    "- Analyze model perplexity and coherence, overall topic prevalence, and topic distribution across articles\n",
    "- Generate a bipartite, weighted (on likelyhood of belonging to the most domiant topic) graph of articles and topics, and analyze its topology to identify relationships between topics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "np.random.seed(12321)\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import reuters\n",
    "\n",
    "import spacy  # need to install\n",
    "\n",
    "import gensim  # need to install\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "# warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# NLTK Reuters corpus\n",
    "from nltk.corpus import reuters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import & Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data import and preliminary EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per the NLTK Reuters README (accessible via `reuters.readme()`), this corpus include 10,788 article from the Reuters financial newswire service.  While it is partitioned into training and test sets, we will not be making use of these splits for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_9178897e_ca05_11ea_8c38_784f434fb9dc\" ><thead>    <tr>        <th class=\"col_heading level0 col0\" >Article</th>        <th class=\"col_heading level0 col2\" >Category</th>        <th class=\"col_heading level0 col3\" >Text</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_9178897e_ca05_11ea_8c38_784f434fb9dcrow0_col0\" class=\"data row0 col0\" >14826</td>\n",
       "                                <td id=\"T_9178897e_ca05_11ea_8c38_784f434fb9dcrow0_col2\" class=\"data row0 col2\" >['trade']</td>\n",
       "                        <td id=\"T_9178897e_ca05_11ea_8c38_784f434fb9dcrow0_col3\" class=\"data row0 col3\" >ASIAN EXPORTERS FEAR DAMAGE FROM U.S.-JAPAN RIFT\n",
       "  Mounting trade friction between the\n",
       "  U.S. And Japan has raised fears among many of Asia's exporting\n",
       "  nations that the row could inflict far-reaching economic\n",
       "  damage, businessmen and officials said.\n",
       "      They told Reuter correspondents in Asian capitals a U.S.\n",
       "  Move against Japan might boost protectionist sentiment in the\n",
       "  U.S. And lead to curbs on American imports of their products.\n",
       "      But some exporters said that while the conflict would hurt\n",
       "  them in the long-run, in the short-term Tokyo's loss might be\n",
       "  their gain.\n",
       "      The U.S. Has said it will impose 300 mln dlrs of tariffs on\n",
       "  imports of Japanese electronics goods on April 17, in\n",
       "  retaliation for Japan's alleged failure to stick to a pact not\n",
       "  to sell semiconductors on world markets at below cost.\n",
       "      Unofficial Japanese estimates put the impact of the tariffs\n",
       "  at 10 billion dlrs and spokesmen for major electronics firms\n",
       "  said they would virtually halt exports of products hit by the\n",
       "  new taxes.\n",
       "      \"We wouldn't be able to do business,\" said a spokesman for\n",
       "  leading Japanese electronics firm Matsushita Electric\n",
       "  Industrial Co Ltd &lt;MC.T>.\n",
       "      \"If the tariffs remain in place for any length of time\n",
       "  beyond a few months it will mean the complete erosion of\n",
       "  exports (of goods subject to tariffs) to the U.S.,\" said Tom\n",
       "  Murtha, a stock analyst at the Tokyo office of broker &lt;James\n",
       "  Capel and Co>.\n",
       "      In Taiwan, businessmen and officials are also worried.\n",
       "      \"We are aware of the seriousness of the U.S. Threat against\n",
       "  Japan because it serves as a warning to us,\" said a senior\n",
       "  Taiwanese trade official who asked not to be named.\n",
       "      Taiwan had a trade trade surplus of 15.6 billion dlrs last\n",
       "  year, 95 pct of it with the U.S.\n",
       "      The surplus helped swell Taiwan's foreign exchange reserves\n",
       "  to 53 billion dlrs, among the world's largest.\n",
       "      \"We must quickly open our markets, remove trade barriers and\n",
       "  cut import tariffs to allow imports of U.S. Products, if we\n",
       "  want to defuse problems from possible U.S. Retaliation,\" said\n",
       "  Paul Sheen, chairman of textile exporters &lt;Taiwan Safe Group>.\n",
       "      A senior official of South Korea's trade promotion\n",
       "  association said the trade dispute between the U.S. And Japan\n",
       "  might also lead to pressure on South Korea, whose chief exports\n",
       "  are similar to those of Japan.\n",
       "      Last year South Korea had a trade surplus of 7.1 billion\n",
       "  dlrs with the U.S., Up from 4.9 billion dlrs in 1985.\n",
       "      In Malaysia, trade officers and businessmen said tough\n",
       "  curbs against Japan might allow hard-hit producers of\n",
       "  semiconductors in third countries to expand their sales to the\n",
       "  U.S.\n",
       "      In Hong Kong, where newspapers have alleged Japan has been\n",
       "  selling below-cost semiconductors, some electronics\n",
       "  manufacturers share that view. But other businessmen said such\n",
       "  a short-term commercial advantage would be outweighed by\n",
       "  further U.S. Pressure to block imports.\n",
       "      \"That is a very short-term view,\" said Lawrence Mills,\n",
       "  director-general of the Federation of Hong Kong Industry.\n",
       "      \"If the whole purpose is to prevent imports, one day it will\n",
       "  be extended to other sources. Much more serious for Hong Kong\n",
       "  is the disadvantage of action restraining trade,\" he said.\n",
       "      The U.S. Last year was Hong Kong's biggest export market,\n",
       "  accounting for over 30 pct of domestically produced exports.\n",
       "      The Australian government is awaiting the outcome of trade\n",
       "  talks between the U.S. And Japan with interest and concern,\n",
       "  Industry Minister John Button said in Canberra last Friday.\n",
       "      \"This kind of deterioration in trade relations between two\n",
       "  countries which are major trading partners of ours is a very\n",
       "  serious matter,\" Button said.\n",
       "      He said Australia's concerns centred on coal and beef,\n",
       "  Australia's two largest exports to Japan and also significant\n",
       "  U.S. Exports to that country.\n",
       "      Meanwhile U.S.-Japanese diplomatic manoeuvres to solve the\n",
       "  trade stand-off continue.\n",
       "      Japan's ruling Liberal Democratic Party yesterday outlined\n",
       "  a package of economic measures to boost the Japanese economy.\n",
       "      The measures proposed include a large supplementary budget\n",
       "  and record public works spending in the first half of the\n",
       "  financial year.\n",
       "      They also call for stepped-up spending as an emergency\n",
       "  measure to stimulate the economy despite Prime Minister\n",
       "  Yasuhiro Nakasone's avowed fiscal reform program.\n",
       "      Deputy U.S. Trade Representative Michael Smith and Makoto\n",
       "  Kuroda, Japan's deputy minister of International Trade and\n",
       "  Industry (MITI), are due to meet in Washington this week in an\n",
       "  effort to end the dispute.\n",
       "  \n",
       "\n",
       "</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_9178897e_ca05_11ea_8c38_784f434fb9dcrow1_col0\" class=\"data row1 col0\" >14828</td>\n",
       "                                <td id=\"T_9178897e_ca05_11ea_8c38_784f434fb9dcrow1_col2\" class=\"data row1 col2\" >['grain']</td>\n",
       "                        <td id=\"T_9178897e_ca05_11ea_8c38_784f434fb9dcrow1_col3\" class=\"data row1 col3\" >CHINA DAILY SAYS VERMIN EAT 7-12 PCT GRAIN STOCKS\n",
       "  A survey of 19 provinces and seven cities\n",
       "  showed vermin consume between seven and 12 pct of China's grain\n",
       "  stocks, the China Daily said.\n",
       "      It also said that each year 1.575 mln tonnes, or 25 pct, of\n",
       "  China's fruit output are left to rot, and 2.1 mln tonnes, or up\n",
       "  to 30 pct, of its vegetables. The paper blamed the waste on\n",
       "  inadequate storage and bad preservation methods.\n",
       "      It said the government had launched a national programme to\n",
       "  reduce waste, calling for improved technology in storage and\n",
       "  preservation, and greater production of additives. The paper\n",
       "  gave no further details.\n",
       "  \n",
       "\n",
       "</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_9178897e_ca05_11ea_8c38_784f434fb9dcrow2_col0\" class=\"data row2 col0\" >14829</td>\n",
       "                                <td id=\"T_9178897e_ca05_11ea_8c38_784f434fb9dcrow2_col2\" class=\"data row2 col2\" >['crude', 'nat-gas']</td>\n",
       "                        <td id=\"T_9178897e_ca05_11ea_8c38_784f434fb9dcrow2_col3\" class=\"data row2 col3\" >JAPAN TO REVISE LONG-TERM ENERGY DEMAND DOWNWARDS\n",
       "  The Ministry of International Trade and\n",
       "  Industry (MITI) will revise its long-term energy supply/demand\n",
       "  outlook by August to meet a forecast downtrend in Japanese\n",
       "  energy demand, ministry officials said.\n",
       "      MITI is expected to lower the projection for primary energy\n",
       "  supplies in the year 2000 to 550 mln kilolitres (kl) from 600\n",
       "  mln, they said.\n",
       "      The decision follows the emergence of structural changes in\n",
       "  Japanese industry following the rise in the value of the yen\n",
       "  and a decline in domestic electric power demand.\n",
       "      MITI is planning to work out a revised energy supply/demand\n",
       "  outlook through deliberations of committee meetings of the\n",
       "  Agency of Natural Resources and Energy, the officials said.\n",
       "      They said MITI will also review the breakdown of energy\n",
       "  supply sources, including oil, nuclear, coal and natural gas.\n",
       "      Nuclear energy provided the bulk of Japan's electric power\n",
       "  in the fiscal year ended March 31, supplying an estimated 27\n",
       "  pct on a kilowatt/hour basis, followed by oil (23 pct) and\n",
       "  liquefied natural gas (21 pct), they noted.\n",
       "  \n",
       "\n",
       "</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_9178897e_ca05_11ea_8c38_784f434fb9dcrow3_col0\" class=\"data row3 col0\" >14832</td>\n",
       "                                <td id=\"T_9178897e_ca05_11ea_8c38_784f434fb9dcrow3_col2\" class=\"data row3 col2\" >['corn', 'grain', 'rice', 'rubber', 'sugar', 'tin', 'trade']</td>\n",
       "                        <td id=\"T_9178897e_ca05_11ea_8c38_784f434fb9dcrow3_col3\" class=\"data row3 col3\" >THAI TRADE DEFICIT WIDENS IN FIRST QUARTER\n",
       "  Thailand's trade deficit widened to 4.5\n",
       "  billion baht in the first quarter of 1987 from 2.1 billion a\n",
       "  year ago, the Business Economics Department said.\n",
       "      It said Janunary/March imports rose to 65.1 billion baht\n",
       "  from 58.7 billion. Thailand's improved business climate this\n",
       "  year resulted in a 27 pct increase in imports of raw materials\n",
       "  and semi-finished products.\n",
       "      The country's oil import bill, however, fell 23 pct in the\n",
       "  first quarter due to lower oil prices.\n",
       "      The department said first quarter exports expanded to 60.6\n",
       "  billion baht from 56.6 billion.\n",
       "      Export growth was smaller than expected due to lower\n",
       "  earnings from many key commodities including rice whose\n",
       "  earnings declined 18 pct, maize 66 pct, sugar 45 pct, tin 26\n",
       "  pct and canned pineapples seven pct.\n",
       "      Products registering high export growth were jewellery up\n",
       "  64 pct, clothing 57 pct and rubber 35 pct.\n",
       "  \n",
       "\n",
       "</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_9178897e_ca05_11ea_8c38_784f434fb9dcrow4_col0\" class=\"data row4 col0\" >14833</td>\n",
       "                                <td id=\"T_9178897e_ca05_11ea_8c38_784f434fb9dcrow4_col2\" class=\"data row4 col2\" >['palm-oil', 'veg-oil']</td>\n",
       "                        <td id=\"T_9178897e_ca05_11ea_8c38_784f434fb9dcrow4_col3\" class=\"data row4 col3\" >INDONESIA SEES CPO PRICE RISING SHARPLY\n",
       "  Indonesia expects crude palm oil (CPO)\n",
       "  prices to rise sharply to between 450 and 550 dlrs a tonne FOB\n",
       "  sometime this year because of better European demand and a fall\n",
       "  in Malaysian output, Hasrul Harahap, junior minister for tree\n",
       "  crops, told Indonesian reporters.\n",
       "      Prices of Malaysian and Sumatran CPO are now around 332\n",
       "  dlrs a tonne CIF for delivery in Rotterdam, traders said.\n",
       "      Harahap said Indonesia would maintain its exports, despite\n",
       "  making recent palm oil purchases from Malaysia, so that it\n",
       "  could possibly increase its international market share.\n",
       "      Indonesia, the world's second largest producer of palm oil\n",
       "  after Malaysia, has been forced to import palm oil to ensure\n",
       "  supplies during the Moslem fasting month of Ramadan.\n",
       "      Harahap said it was better to import to cover a temporary\n",
       "  shortage than to lose export markets.\n",
       "      Indonesian exports of CPO in calendar 1986 were 530,500\n",
       "  tonnes, against 468,500 in 1985, according to central bank\n",
       "  figures.\n",
       "  \n",
       "\n",
       "</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x11a293710>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate dataframe of Reuters\n",
    "news = []\n",
    "for fileid in reuters.fileids():\n",
    "    tag, filename = fileid.split('/')\n",
    "    news.append((filename, tag, reuters.categories(fileid), reuters.raw(fileid)))\n",
    "df = pd.DataFrame(news, columns=['Article', 'Tag', 'Category', 'Text'])\n",
    "\n",
    "# Optional view, otherwise just use df\n",
    "df.head(5).style.hide_index().hide_columns(['Tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Article Count</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>earn</td>\n",
       "      <td>3964</td>\n",
       "      <td>0.297419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>acq</td>\n",
       "      <td>2369</td>\n",
       "      <td>0.177746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>money-fx</td>\n",
       "      <td>717</td>\n",
       "      <td>0.053797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>grain</td>\n",
       "      <td>582</td>\n",
       "      <td>0.043667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>crude</td>\n",
       "      <td>578</td>\n",
       "      <td>0.043367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>trade</td>\n",
       "      <td>485</td>\n",
       "      <td>0.036390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>interest</td>\n",
       "      <td>478</td>\n",
       "      <td>0.035864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ship</td>\n",
       "      <td>286</td>\n",
       "      <td>0.021459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>wheat</td>\n",
       "      <td>283</td>\n",
       "      <td>0.021233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>corn</td>\n",
       "      <td>237</td>\n",
       "      <td>0.017782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Category  Article Count  Percentage\n",
       "0      earn           3964    0.297419\n",
       "1       acq           2369    0.177746\n",
       "2  money-fx            717    0.053797\n",
       "3     grain            582    0.043667\n",
       "4     crude            578    0.043367\n",
       "5     trade            485    0.036390\n",
       "6  interest            478    0.035864\n",
       "7      ship            286    0.021459\n",
       "8     wheat            283    0.021233\n",
       "9      corn            237    0.017782"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Article Count</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>palladium</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>palmkernel</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>copra-cake</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>dfl</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>cotton-oil</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>sun-meal</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>groundnut-oil</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>rye</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>lin-oil</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>castor-oil</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Category  Article Count  Percentage\n",
       "80      palladium              3    0.000225\n",
       "81     palmkernel              3    0.000225\n",
       "82     copra-cake              3    0.000225\n",
       "83            dfl              3    0.000225\n",
       "84     cotton-oil              3    0.000225\n",
       "85       sun-meal              2    0.000150\n",
       "86  groundnut-oil              2    0.000150\n",
       "87            rye              2    0.000150\n",
       "88        lin-oil              2    0.000150\n",
       "89     castor-oil              2    0.000150"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories with less than 1% of all articles:  74\n",
      "Categories with less than .1% of all articles:  28\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate category makeup of corpus\n",
    "def category_count(df):\n",
    "    \n",
    "    cats = list(reuters.categories())\n",
    "    cat_count = []\n",
    "    \n",
    "    # Count an article with multiple categories in tuple\n",
    "    for cat in cats:\n",
    "        cat_count.append(len(df[[cat in x for x in df['Category']]]))\n",
    "    \n",
    "    count_df = pd.DataFrame(cat_count, cats).reset_index()\n",
    "    count_df.set_axis(['Category', 'Article Count'], axis=1, inplace=True)\n",
    "    count_df.sort_values(by=['Article Count'], ascending=False, inplace=True)\n",
    "    count_df.reset_index(drop=True, inplace=True)\n",
    "    count_df['Percentage'] = count_df['Article Count'] / count_df['Article Count'].sum()\n",
    "    \n",
    "    return count_df\n",
    "\n",
    "article_props = category_count(df)\n",
    "display(article_props.head(n=10))\n",
    "display(article_props.tail(n=10))\n",
    "print('Categories with less than 1% of all articles: ', len(article_props[article_props['Percentage'] < .01]))\n",
    "print('Categories with less than .1% of all articles: ', len(article_props[article_props['Percentage'] < .001]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The corpus is labeled with 90 different categories. Each article can be labelled with multiple categories (e.g. 'trade' and 'ship').\n",
    "\n",
    "There is considerable category skew and a pronounced long tail: 'earn' (29.7%) and 'acq' (17.7%) represent nearly half the articles in the corpus, while 74 categories have less than 1% of all articles, and 28 have less than .1%. \n",
    "\n",
    "However, given LDA is unsupervised and these labels aren't used, category skew does not impact the performance of topic modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text preparation and tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA aims to describe document collections by assigning topics based on the those documents' word frequency.  To do this the words must be demarcated and standardized for lexical analysis.\n",
    "\n",
    "We remove characters, diacritics, and punctuation, and convert all text to lower case tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original text: \n",
      " G-7 ISSUES STATEMENT AFTER MEETING\n",
      "  Following is the text of a statement\n",
      "  by the Group of Seven -- the U.S., Japan, West Germany, France,\n",
      "  Britain, Italy and Canada -- issued after a Washington meeting\n",
      "  yesterday.\n",
      "      1. The finance ministers and central bank governors of\n",
      "  seven major industr\n",
      "\n",
      "After cleaning: \n",
      " G-7 ISSUES STATEMENT AFTER MEETING Following is the text of a statement by the Group of Seven -- the U.S., Japan, West Germany, France, Britain, Italy and Canada -- issued after a Washington meeting yesterday. 1. The finance ministers and central bank governors of seven major industrial countries me\n",
      "\n",
      "After tokenization: \n",
      " ['issues', 'statement', 'after', 'meeting', 'following', 'is', 'the', 'text', 'of', 'statement', 'by', 'the', 'group', 'of', 'seven', 'the', 'japan', 'west', 'germany', 'france', 'britain', 'italy', 'and', 'canada', 'issued', 'after', 'washington', 'meeting', 'yesterday', 'the']\n"
     ]
    }
   ],
   "source": [
    "# Convert text to list\n",
    "data = df['Text'].values.tolist()\n",
    "\n",
    "# Remove new line characters and single quotes\n",
    "data = [re.sub(r'\\s+', ' ', sent) for sent in data]\n",
    "data = [re.sub(r\"\\'\", \"\", sent) for sent in data]\n",
    "\n",
    "# Function to tokenize words and remove punctuation\n",
    "def sentence_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuation\n",
    "\n",
    "data_words = list(sentence_to_words(data))\n",
    "\n",
    "# Impact of text preparation\n",
    "print('\\nOriginal text: \\n', (df.iloc[330,3][:300]))\n",
    "print('\\nAfter cleaning: \\n', data[330][:300])\n",
    "print('\\nAfter tokenization: \\n', data_words[330][:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing and feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stopwords are abundant in English. Their high frequency provides very little information to inform topic modeling, so we remove them from the tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove stopwords\n",
    "def remove_stopwords(texts):\n",
    "    \n",
    "    # Identify stopwords using NLTK and amend\n",
    "    stop_words = stopwords.words('english')\n",
    "    stop_words.extend(['from', 'subject', 're', 'edu', 'use'])\n",
    "    \n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "# Remove stop words\n",
    "data_words_nostops = remove_stopwords(data_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some adjacenet words are known to convey different meaning.  We associate  these words in pairs called bigrams, and add them to the tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to make bigrams\n",
    "def make_bigrams(texts):\n",
    "    \n",
    "    # Generate bigram model\n",
    "    bigram = gensim.models.Phrases(data_words, \n",
    "                                   min_count=5, # must occur at least five times in corpus to be counted\n",
    "                                   threshold=100)  # higher threshold fewer phrases\n",
    "    bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "    \n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "# Form bigrams\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Words are inflected when their use in speech changes due to 'tense, case, voice, aspect, person, number, gender, and mood' [Wikipedia](https://en.wikipedia.org/wiki/Inflection).  These inflections in nouns (declension) and verbs (conjugation) can take the form of prefixes, suffixes, or infixes.  **Stemming** uses an algorithmic approach that is more approximate than **lemmatization**, which uses dictionaries to identify root forms.\n",
    "\n",
    "We lemmatize the tokens to normalize them for topic modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['asian', 'exporter', 'fear', 'damage', 'mount', 'trade', 'friction', 'raise', 'fear', 'many', 'asia', 'export', 'nation', 'row', 'could', 'inflict', 'far', 'reach', 'economic', 'damage', 'businessman', 'official', 'say', 'tell', 'asian', 'capital', 'move', 'may', 'boost', 'protectionist_sentiment']\n"
     ]
    }
   ],
   "source": [
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \n",
    "    # https://spacy.io/api/annotation\n",
    "    \n",
    "    texts_out = []\n",
    "    \n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    \n",
    "    return texts_out\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "# python3 -m spacy download en\n",
    "\n",
    "# MI: do we use the nlp variable below anywhere?\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n",
    "# Perform lemmatization keeping only noun, adj, vb, adv\n",
    "data_lemmatized = lemmatization(data_words_bigrams)\n",
    "\n",
    "print(data_lemmatized[0][:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a dictionary representation of the tokens in the corpus, calculating the term document frequency for each token.  With this, we can proceed with topic modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary representation of corpus\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "# Create corpus with term document frequency\n",
    "texts = data_lemmatized\n",
    "corpus = [id2word.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary Topic Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generate a topic model for the article.  We employ two approaches:\n",
    "\n",
    "1. Gensim's built-in LDA topic modeling function, `ldamodel`.  Gensim implementations of LDA employ Variational Inference, which introduces bias and can provide less coherence in topics.\n",
    "2. MALLET (MAchine Learning for LanguagE Toolkit)'s LDA topic model with a Gensim wrapper, `ldamallet`.  This model employs Gibbs sampling (an MCMC method), which is unbiased at the cost of heavy computation (performed in Java).\n",
    "\n",
    "LDA models can be evaluated based on several different metrics:\n",
    "\n",
    "- **Perplexity** is a [measure](https://en.wikipedia.org/wiki/Perplexity) of 'surprise', or how well the model predicts.  The lower the score, the better the prediction.\n",
    "- **Coherence** is the degree of 'semantic similarity between high scoring keywords in the topic' [Learn to Find Topics in a Text Corpus](https://towardsdatascience.com/evaluate-topic-model-in-python-latent-dirichlet-allocation-lda-7d57484bb5d0).  It is computed as a the sum of pairwise scores of the top n words by frequency.  The higher the coherence, the more coherent and interpretable the topic. \n",
    "\n",
    "Selecting the number of topics in an LDA model can be an arbitrary decision. We inform this decision through hyperparameter tuning based on an evaluation of the topic coherence yielded by different numbers of topics.  \n",
    "\n",
    "We optimize the Gensim model accordingly (JO: MALLET too?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate Gensim LDA model\n",
    "def gensim_ldamodel(corpus, num_topics):\n",
    "    \n",
    "    model = gensim.models.ldamodel.LdaModel(corpus=corpus,  # TDF corpus\n",
    "                                               id2word=id2word,  # dictionary\n",
    "                                               num_topics=num_topics,  # to be optimized\n",
    "                                               random_state=100,  # [JO: CONFIRM]\n",
    "                                               # update_every=1,  # how often paramater should be updated\n",
    "                                               # chunksize=100,\n",
    "                                               # passes=10,  # total number of training passes\n",
    "                                               # alpha='auto',  # learn assymetric alpha from training data (JO: consider whether to evaluate symmetric approach for alpha with asymmetric for beta)\n",
    "                                               per_word_topics=True)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Function to generate MALLET LDA model\n",
    "def mallet_ldamodel(corpus, num_topics):\n",
    "    \n",
    "    mallet_path = './mallet-2.0.8/bin/mallet' \n",
    "    \n",
    "    model = gensim.models.wrappers.LdaMallet(mallet_path, \n",
    "                                        corpus=corpus, \n",
    "                                        num_topics=num_topics, \n",
    "                                        id2word=id2word)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Function to iterate over numbers of topics and calculates LDA model coherence\n",
    "def compute_coherence_values(model_type, dictionary, corpus, texts, limit, start=2, step=3):\n",
    "   \n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    coherence='c_v'\n",
    "    \n",
    "    for num_topics in range(start, limit, step):\n",
    "        \n",
    "        if model_type == 'LdaModel':\n",
    "            model = gensim_ldamodel(corpus=corpus,\n",
    "                           num_topics=num_topics)\n",
    "            \n",
    "        elif model_type == 'LdaMallet':\n",
    "            model = mallet_ldamodel(corpus=corpus,\n",
    "                                    num_topics=num_topics)\n",
    "            \n",
    "        else:\n",
    "            print('model_type not supported')\n",
    "            break\n",
    "        \n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, \n",
    "                                        texts=texts,\n",
    "                                        dictionary=id2word, \n",
    "                                        coherence=coherence)\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "        \n",
    "    return model_list, coherence_values  # List of LDA topic models and coherence values for respective number of topics\n",
    "\n",
    "# Function to support decision on optimal number of topics\n",
    "def chart_model_coherence(coherence_values, limit, start=2, step=3):\n",
    "    \n",
    "    x = range(start, limit, step)\n",
    "    \n",
    "    coherence_table = pd.DataFrame(list(zip(x,coherence_values)), columns=['Num Topics','Coherence Score'])\n",
    "    \n",
    "    plt.plot(x, coherence_values)\n",
    "    plt.xlabel('Num Topics')\n",
    "    plt.ylabel('Coherence Score')\n",
    "    plt.legend(('coherence_values'), loc='best')\n",
    "    plt.show()\n",
    "    \n",
    "    return coherence_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gensim LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Num Topics</th>\n",
       "      <th>Coherence Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.315559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>0.396004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>0.424539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>0.396019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>0.407569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>22</td>\n",
       "      <td>0.425183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>26</td>\n",
       "      <td>0.420701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>30</td>\n",
       "      <td>0.410306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>34</td>\n",
       "      <td>0.403574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>38</td>\n",
       "      <td>0.396488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Num Topics  Coherence Score\n",
       "0           2         0.315559\n",
       "1           6         0.396004\n",
       "2          10         0.424539\n",
       "3          14         0.396019\n",
       "4          18         0.407569\n",
       "5          22         0.425183\n",
       "6          26         0.420701\n",
       "7          30         0.410306\n",
       "8          34         0.403574\n",
       "9          38         0.396488"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cast broad net to find neighborhood of optimal number of topics in range of 2 to 40 in steps of 4\n",
    "gs_broad_model_list, gs_broad_coherence_values = compute_coherence_values(model_type='LdaModel',\n",
    "                                                                          dictionary=id2word, \n",
    "                                                                          corpus=corpus, \n",
    "                                                                          texts=data_lemmatized, \n",
    "                                                                          start=2, \n",
    "                                                                          limit=40, \n",
    "                                                                          step=4)\n",
    "\n",
    "# Chart broad net of optimal number of topics\n",
    "chart_model_coherence(gs_broad_coherence_values, \n",
    "                      start=2, \n",
    "                      limit=40, \n",
    "                      step=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When analyzed at 4 topic steps, Gensim LDA model coherence peaks between 6 and 25 topics.  It's not very smooth, so given that the spikes could be obscuring the optimum we narrow our search in that range with 1 topic steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/gensim/topic_coherence/text_analysis.py:449: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  logger.warn(\"stats accumulation interrupted; <= %d documents processed\", self._num_docs)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-a3a15aa8534f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                                                             \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                                                                             \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                                                                             step=1)\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Chart narrower net of optimal number of topics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-3b8e555e283b>\u001b[0m in \u001b[0;36mcompute_coherence_values\u001b[0;34m(model_type, dictionary, corpus, texts, limit, start, step)\u001b[0m\n\u001b[1;32m     52\u001b[0m                                         \u001b[0mdictionary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mid2word\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                                         coherence=coherence)\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mcoherence_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoherencemodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_coherence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoherence_values\u001b[0m  \u001b[0;31m# List of LDA topic models and coherence values for respective number of topics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/gensim/models/coherencemodel.py\u001b[0m in \u001b[0;36mget_coherence\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m         \"\"\"\n\u001b[0;32m--> 609\u001b[0;31m         \u001b[0mconfirmed_measures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_coherence_per_topic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    610\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maggregate_measures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfirmed_measures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/gensim/models/coherencemodel.py\u001b[0m in \u001b[0;36mget_coherence_per_topic\u001b[0;34m(self, segmented_topics, with_std, with_support)\u001b[0m\n\u001b[1;32m    567\u001b[0m             \u001b[0msegmented_topics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeasure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accumulator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimate_probabilities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegmented_topics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_std\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwith_std\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_support\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwith_support\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/gensim/models/coherencemodel.py\u001b[0m in \u001b[0;36mestimate_probabilities\u001b[0;34m(self, segmented_topics)\u001b[0m\n\u001b[1;32m    539\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeyed_vectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accumulator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeasure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accumulator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/gensim/topic_coherence/probability_estimation.py\u001b[0m in \u001b[0;36mp_boolean_sliding_window\u001b[0;34m(texts, segmented_topics, dictionary, window_size, processes)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0maccumulator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallelWordOccurrenceAccumulator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocesses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"using %s to estimate probabilities from sliding windows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccumulator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0maccumulator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccumulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/gensim/topic_coherence/text_analysis.py\u001b[0m in \u001b[0;36maccumulate\u001b[0;34m(self, texts, window_size)\u001b[0m\n\u001b[1;32m    450\u001b[0m             \u001b[0minterrupted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m         \u001b[0maccumulators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminate_workers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_q\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_q\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterrupted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_accumulators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccumulators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/gensim/topic_coherence/text_analysis.py\u001b[0m in \u001b[0;36mterminate_workers\u001b[0;34m(self, input_q, output_q, workers, interrupted)\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0maccumulators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccumulators\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m             \u001b[0maccumulators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_q\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%d accumulators retrieved from output queue\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccumulators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.7/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.7/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"negative maxlength\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bad_message_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.7/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxsize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.7/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Cast narrower net in range of 6 to 25 in single steps to smooth and find optimum in number of topics\n",
    "gs_narrow_model_list, gs_narrow_coherence_values = compute_coherence_values(model_type='LdaModel',\n",
    "                                                                            dictionary=id2word, \n",
    "                                                                            corpus=corpus, \n",
    "                                                                            texts=data_lemmatized, \n",
    "                                                                            start=6, \n",
    "                                                                            limit=25, \n",
    "                                                                            step=1)\n",
    "\n",
    "# Chart narrower net of optimal number of topics\n",
    "gs_narrow_coherence = chart_model_coherence(gs_narrow_coherence_values, \n",
    "                      start=6, \n",
    "                      limit=25, \n",
    "                      step=1)     \n",
    "gs_narrow_coherence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimized Gensim Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9 topics yield the highest coherence score so we select the model with a k of 9. Here is a snapshot of top words for each of the 9 topics in this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gensim LDA model perplexity:  -7.095693898256886\n",
      "\n",
      "Gensim LDA model coherence score:  0.43975307826479676 \n",
      "\n",
      "0: say year rate rise quarter expect growth first earning increase\n",
      "1: price say oil raise crude trader barrel today dlrs rate\n",
      "2: say crop year deficit soybean estimate last trade surplus program\n",
      "3: say company share offer would buy stock group also sell\n",
      "4: say bank market rise dollar rate dealer money yen currency\n",
      "5: loss net ct profit dlrs sale year say include note\n",
      "6: say trade would export official government import country year japanese\n",
      "7: share ct say dividend stock record split dlrs may pay\n",
      "8: say year oil price production last would rise market export\n"
     ]
    }
   ],
   "source": [
    "# Optimal Gensim model\n",
    "# gs_optimal_model = gs_narrow_model_list[int(gs_narrow_coherence.loc[gs_narrow_coherence['Coherence Score'].idxmax()]['Num Topics'])]\n",
    "gs_optimal_model = gensim_ldamodel(corpus=corpus, num_topics=9)\n",
    "\n",
    "# Compute model perplexity and coherence score\n",
    "print('\\nGensim LDA model perplexity: ', gs_optimal_model.log_perplexity(corpus))\n",
    "\n",
    "# print('\\nGensim LDA model coherence score: ', gs_narrow_coherence.loc[gs_narrow_coherence['Coherence Score'].idxmax()]['Coherence Score'])\n",
    "print('\\nGensim LDA model coherence score: ', CoherenceModel(model=gs_optimal_model, texts=texts).get_coherence(), '\\n')\n",
    "\n",
    "# Here is a quick look at the the top words by topic for the optimal Gensim model\n",
    "for topic_id in range(gs_optimal_model.num_topics):\n",
    "    top_k = gs_optimal_model.show_topic(topic_id, 10)\n",
    "    top_k_words = [w for w, _ in top_k]\n",
    "    \n",
    "    print('{}: {}'.format(topic_id, ' '.join(top_k_words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MALLET LDA model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JO: Mael, what if we trained both models first in this section, and then compared their relative performance before selecting MALLET and analyzing its output?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-6ba780c4354d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                                                           \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                                                                           \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                                                                           step=4)\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Chart broad net of optimal number of topics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-3b8e555e283b>\u001b[0m in \u001b[0;36mcompute_coherence_values\u001b[0;34m(model_type, dictionary, corpus, texts, limit, start, step)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmodel_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'LdaMallet'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             model = mallet_ldamodel(corpus=corpus,\n\u001b[0;32m---> 43\u001b[0;31m                                     num_topics=num_topics)\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-3b8e555e283b>\u001b[0m in \u001b[0;36mmallet_ldamodel\u001b[0;34m(corpus, num_topics)\u001b[0m\n\u001b[1;32m     22\u001b[0m                                         \u001b[0mcorpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                                         \u001b[0mnum_topics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_topics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                                         id2word=id2word)\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/gensim/models/wrappers/ldamallet.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, mallet_path, corpus, num_topics, alpha, id2word, workers, prefix, optimize_interval, iterations, topic_threshold, random_seed)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_seed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfinferencer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/gensim/models/wrappers/ldamallet.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, corpus)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \"\"\"\n\u001b[0;32m--> 272\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m         \u001b[0mcmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmallet_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' train-topics --input %s --num-topics %s  --alpha %s --optimize-interval %s '\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0;34m'--num-threads %s --output-state %s --output-doc-topics %s --output-topic-keys %s '\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/gensim/models/wrappers/ldamallet.py\u001b[0m in \u001b[0;36mconvert_input\u001b[0;34m(self, corpus, infer, serialize_corpus)\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0mcmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcmd\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfcorpustxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfcorpusmallet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"converting temporary corpus to MALLET format with %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m         \u001b[0mcheck_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36mcheck_output\u001b[0;34m(stdout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m   1922\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"COMMAND: %s %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m         \u001b[0mprocess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1924\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munused_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1925\u001b[0m         \u001b[0mretcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1926\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.7/Frameworks/Python.framework/Versions/3.7/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36mcommunicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m    949\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stdin_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m                 \u001b[0mstdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    952\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Cast broad net to find neighborhood of optimal number of topics in range of 2 to 40 in steps of 4\n",
    "mlt_broad_model_list, mlt_broad_coherence_values = compute_coherence_values(model_type='LdaMallet',\n",
    "                                                                          dictionary=id2word, \n",
    "                                                                          corpus=corpus, \n",
    "                                                                          texts=data_lemmatized, \n",
    "                                                                          start=2, \n",
    "                                                                          limit=40, \n",
    "                                                                          step=4)\n",
    "\n",
    "# Chart broad net of optimal number of topics\n",
    "chart_model_coherence(mlt_broad_coherence_values, \n",
    "                      start=2, \n",
    "                      limit=40, \n",
    "                      step=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast narrower net in range of 6 to 25 in single steps to smooth and find optimum in number of topics\n",
    "mlt_narrow_model_list, mlt_narrow_coherence_values = compute_coherence_values(model_type='LdaMallet',\n",
    "                                                                            dictionary=id2word, \n",
    "                                                                            corpus=corpus, \n",
    "                                                                            texts=data_lemmatized, \n",
    "                                                                            start=6, \n",
    "                                                                            limit=25, \n",
    "                                                                            step=1)\n",
    "\n",
    "# Chart narrower net of optimal number of topics\n",
    "mlt_narrow_coherence = chart_model_coherence(mlt_narrow_coherence_values, \n",
    "                      start=8, \n",
    "                      limit=25, \n",
    "                      step=1)     \n",
    "mlt_narrow_coherence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimized MALLET model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimal Mallet model\n",
    "#mlt_optimal_model = mlt_narrow_model_list[int(mlt_narrow_coherence.loc[mlt_narrow_coherence['Coherence Score'].idxmax()]['Num Topics'])]\n",
    "#mlt_optimal_model = mallet_ldamodel(corpus=corpus, num_topics=9)\n",
    "mlt_optimal_model = mallet_ldamodel(corpus=corpus, num_topics=20)\n",
    "\n",
    "# Compute model perplexity and coherence score\n",
    "print('\\nMallet LDA model perplexity: ', lda_model.log_perplexity(corpus))\n",
    "#print('\\nMallet LDA model coherence score: ', mlt_narrow_coherence.loc[mlt_narrow_coherence['Coherence Score'].idxmax()]['Coherence Score'])\n",
    "\n",
    "print('\\nMallet LDA model coherence score: ', CoherenceModel(model=mlt_optimal_model, texts=texts).get_coherence(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is a quick look at the the top words by topic for the optimal Mallet model\n",
    "for topic_id in range(mlt_optimal_model.num_topics):\n",
    "    top_k = optimal_model.show_topic(topic_id, 10)\n",
    "    top_k_words = [w for w, _ in top_k]\n",
    "    \n",
    "    print('{}: {}'.format(topic_id, ' '.join(top_k_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(7,\n",
      "  [('company', 0.13172891254179814),\n",
      "   ('group', 0.04874487825554561),\n",
      "   ('firm', 0.042481043658456175),\n",
      "   ('investment', 0.033391419017566995),\n",
      "   ('hold', 0.027410163424857532),\n",
      "   ('business', 0.02491404888616776),\n",
      "   ('analyst', 0.020534074318278153),\n",
      "   ('buy', 0.019074082795648283),\n",
      "   ('investor', 0.018226345782508358),\n",
      "   ('management', 0.018179249281778363)]),\n",
      " (1,\n",
      "  [('loan', 0.040666937779585195),\n",
      "   ('future', 0.03227938186254575),\n",
      "   ('change', 0.03126270841805612),\n",
      "   ('interest', 0.028721024806832047),\n",
      "   ('add', 0.02745018300122001),\n",
      "   ('contract', 0.024552663684424565),\n",
      "   ('cent', 0.0217059780398536),\n",
      "   ('canadian', 0.01967263115087434),\n",
      "   ('make', 0.01936762911752745),\n",
      "   ('increase', 0.018452623017486784)]),\n",
      " (2,\n",
      "  [('year', 0.13836858006042296),\n",
      "   ('expect', 0.07967198964177816),\n",
      "   ('quarter', 0.0671126456624946),\n",
      "   ('report', 0.06012084592145015),\n",
      "   ('earning', 0.04626672421234355),\n",
      "   ('result', 0.042900302114803626),\n",
      "   ('end', 0.039922313336210616),\n",
      "   ('revenue', 0.021881743634009496),\n",
      "   ('fiscal', 0.02006905481225723),\n",
      "   ('high', 0.01760897712559344)]),\n",
      " (8,\n",
      "  [('tonne', 0.06830265848670757),\n",
      "   ('wheat', 0.029161554192229037),\n",
      "   ('grain', 0.025153374233128835),\n",
      "   ('crop', 0.023885480572597137),\n",
      "   ('corn', 0.022413087934560327),\n",
      "   ('estimate', 0.02192229038854806),\n",
      "   ('week', 0.019263803680981594),\n",
      "   ('total', 0.018077709611451942),\n",
      "   ('production', 0.01717791411042945),\n",
      "   ('soybean', 0.01652351738241309)]),\n",
      " (4,\n",
      "  [('oil', 0.12957686583032108),\n",
      "   ('price', 0.11239634275994047),\n",
      "   ('production', 0.04363172443121412),\n",
      "   ('crude', 0.028790133957048693),\n",
      "   ('barrel', 0.025005315755900488),\n",
      "   ('gold', 0.02253880501807357),\n",
      "   ('output', 0.020029768233042738),\n",
      "   ('gas', 0.019774611949819266),\n",
      "   ('raise', 0.016202423984690625),\n",
      "   ('supply', 0.015649585371039762)]),\n",
      " (17,\n",
      "  [('spokesman', 0.032871033019100736),\n",
      "   ('today', 0.018113617294309263),\n",
      "   ('official', 0.017718770050836583),\n",
      "   ('ship', 0.01762005823996841),\n",
      "   ('strike', 0.015300330684566408),\n",
      "   ('begin', 0.012635111791125808),\n",
      "   ('work', 0.012338976358521297),\n",
      "   ('attack', 0.010957011006366911),\n",
      "   ('port', 0.010957011006366911),\n",
      "   ('close', 0.010512807857460145)]),\n",
      " (3,\n",
      "  [('dlrs', 0.26725762901828926),\n",
      "   ('sale', 0.10509959753426053),\n",
      "   ('include', 0.09969942432115747),\n",
      "   ('mln', 0.0453920220082531),\n",
      "   ('note', 0.0453410769779408),\n",
      "   ('tax', 0.044475011462631824),\n",
      "   ('gain', 0.0431504406745122),\n",
      "   ('year', 0.030465128126751236),\n",
      "   ('charge', 0.024402669519588364),\n",
      "   ('income', 0.018900606245860718)]),\n",
      " (12,\n",
      "  [('rate', 0.08984171806494762),\n",
      "   ('growth', 0.042765846771197144),\n",
      "   ('cut', 0.0393847068440217),\n",
      "   ('interest', 0.02355651333878279),\n",
      "   ('economic', 0.021290034926060786),\n",
      "   ('policy', 0.020026751876346883),\n",
      "   ('economy', 0.019060711897153897),\n",
      "   ('inflation', 0.017388719625473732),\n",
      "   ('low', 0.017091476554952814),\n",
      "   ('point', 0.01675707810061678)]),\n",
      " (19,\n",
      "  [('market', 0.0728350779591538),\n",
      "   ('dollar', 0.06273332845326111),\n",
      "   ('exchange', 0.04022399531513066),\n",
      "   ('currency', 0.03473391406192811),\n",
      "   ('yen', 0.025766781348363955),\n",
      "   ('analyst', 0.02573018080667594),\n",
      "   ('dealer', 0.017568260010248152),\n",
      "   ('level', 0.015445428592343166),\n",
      "   ('intervention', 0.013249396091062147),\n",
      "   ('major', 0.01262718688236586)]),\n",
      " (0,\n",
      "  [('bank', 0.09320946693209467),\n",
      "   ('market', 0.040875912408759124),\n",
      "   ('week', 0.038000442380004426),\n",
      "   ('money', 0.033797832337978326),\n",
      "   ('rate', 0.03304578633045786),\n",
      "   ('fund', 0.02380004423800044),\n",
      "   ('reserve', 0.023092236230922363),\n",
      "   ('day', 0.022074762220747623),\n",
      "   ('today', 0.021499668214996683),\n",
      "   ('mark', 0.0205706702057067)])]\n"
     ]
    }
   ],
   "source": [
    "#Build LDA Mallet model\n",
    "#mallet_path = './mallet-2.0.8/bin/mallet' \n",
    "#ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=20, id2word=id2word)\n",
    "\n",
    "# Show topics\n",
    "#pprint(mlt_optimal_model.show_topics(formatted=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute coherence score\n",
    "# coherence_model_ldamallet = CoherenceModel(model=ldamallet, \n",
    "#                                             texts=data_lemmatized,\n",
    "#                                             dictionary=id2word, \n",
    "#                                             coherence='c_v')\n",
    "\n",
    "# coherence_ldamallet = coherence_model_ldamallet.get_coherence()\n",
    "# print('\\nCoherence score: ', coherence_ldamallet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Model Analysis & Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### {Best model} Topic Prevalence and Distribution \n",
    "\n",
    "For commentary: https://towardsdatascience.com/topic-modelling-in-python-with-nltk-and-gensim-4ef03213cd21\n",
    "\n",
    "In this visualization, we can analyze saliency (how much the term tells you about the topic), relevance (a weighted average of the probability of the word given the topic and the word given the topic normalized by the probability of the topic). The size of the bubble indicates the importance of the topics, relative to the data.\n",
    "\n",
    "Customize to actual vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JO: assuming MALLET is the top performer, do this for MALLET only?\n",
    "\n",
    "# MI: I think yes. Less to talk about. Avoid some repetition.\n",
    "\n",
    "# Visualize the topics\n",
    "# pyLDAvis.enable_notebook()\n",
    "# vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
    "# vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most Dominant Topics\n",
    "\n",
    "The most dominant topics in each article are extracted using both optimal models. These will be used in a comparison against the known labels of the reuters corpus. Along with the dominant topics, we also extract the keywords associated with the topics and the measure of how likely the dominant topic was.\n",
    "\n",
    "The function below is used to obtain the proportion of articles that have been assigned a particular topic by the model. This can also be used in comparisons. MI: (Verify or complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a dataframe of the proportion of articles having a particular topic\n",
    "def get_topic_distribution(best_topics_df):\n",
    "    topic_count = best_topics_df.groupby(['best_topic','keywords'])['article'].count()\n",
    "    topic_prop = pd.DataFrame(topic_count/len(best_topics_df)*100)\n",
    "    topic_prop = topic_prop.reset_index()\n",
    "    topic_prop.columns = ['best_topic', 'keywords', 'proportion']\n",
    "    topic_prop['proportion'] = topic_prop['proportion'].apply(lambda x: round(x,2))\n",
    "    return topic_prop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best Gensim Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract best topic for each article along with associate keywords and likelyhood\n",
    "def get_best_gensim_topics(lda_model, corpus):\n",
    "    \n",
    "    lda_model_corpus = lda_model[corpus]\n",
    "    art_topic_keywords = pd.DataFrame(columns = ['article','best_topic','likelyhood','keywords'])\n",
    "    \n",
    "    # Loop through articles to get each article's main topic\n",
    "    for i, article in enumerate(lda_model[corpus]):\n",
    "        for article in enumerate(article): \n",
    "            if article[0] == 0:\n",
    "                #print(article)\n",
    "                wp = lda_model.show_topic(article[1][0][0])\n",
    "                topic_keywords = ', '.join([word for word, prop in wp])\n",
    "                \n",
    "                best_topic = int(article[1][0][0])\n",
    "                max_likelyhood = round(article[1][0][1],4)\n",
    "                \n",
    "                d = {'article': i, 'best_topic': best_topic,'likelyhood': max_likelyhood,'keywords': topic_keywords}\n",
    "                art_topic_keywords = art_topic_keywords.append(d, ignore_index=True)\n",
    "\n",
    "    return art_topic_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "gensim_topic_df = get_best_gensim_topics(gs_optimal_model, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_3f696af2_c9ee_11ea_b9f6_784f434fb9dc\" ><thead>    <tr>        <th class=\"col_heading level0 col0\" >article</th>        <th class=\"col_heading level0 col1\" >best_topic</th>        <th class=\"col_heading level0 col2\" >likelyhood</th>        <th class=\"col_heading level0 col3\" >keywords</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_3f696af2_c9ee_11ea_b9f6_784f434fb9dcrow0_col0\" class=\"data row0 col0\" >0</td>\n",
       "                        <td id=\"T_3f696af2_c9ee_11ea_b9f6_784f434fb9dcrow0_col1\" class=\"data row0 col1\" >0</td>\n",
       "                        <td id=\"T_3f696af2_c9ee_11ea_b9f6_784f434fb9dcrow0_col2\" class=\"data row0 col2\" >0.077400</td>\n",
       "                        <td id=\"T_3f696af2_c9ee_11ea_b9f6_784f434fb9dcrow0_col3\" class=\"data row0 col3\" >say, year, rate, rise, quarter, expect, growth, first, earning, increase</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_3f696af2_c9ee_11ea_b9f6_784f434fb9dcrow1_col0\" class=\"data row1 col0\" >1</td>\n",
       "                        <td id=\"T_3f696af2_c9ee_11ea_b9f6_784f434fb9dcrow1_col1\" class=\"data row1 col1\" >2</td>\n",
       "                        <td id=\"T_3f696af2_c9ee_11ea_b9f6_784f434fb9dcrow1_col2\" class=\"data row1 col2\" >0.073000</td>\n",
       "                        <td id=\"T_3f696af2_c9ee_11ea_b9f6_784f434fb9dcrow1_col3\" class=\"data row1 col3\" >say, crop, year, deficit, soybean, estimate, last, trade, surplus, program</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_3f696af2_c9ee_11ea_b9f6_784f434fb9dcrow2_col0\" class=\"data row2 col0\" >2</td>\n",
       "                        <td id=\"T_3f696af2_c9ee_11ea_b9f6_784f434fb9dcrow2_col1\" class=\"data row2 col1\" >8</td>\n",
       "                        <td id=\"T_3f696af2_c9ee_11ea_b9f6_784f434fb9dcrow2_col2\" class=\"data row2 col2\" >0.988400</td>\n",
       "                        <td id=\"T_3f696af2_c9ee_11ea_b9f6_784f434fb9dcrow2_col3\" class=\"data row2 col3\" >say, year, oil, price, production, last, would, rise, market, export</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_3f696af2_c9ee_11ea_b9f6_784f434fb9dcrow3_col0\" class=\"data row3 col0\" >3</td>\n",
       "                        <td id=\"T_3f696af2_c9ee_11ea_b9f6_784f434fb9dcrow3_col1\" class=\"data row3 col1\" >0</td>\n",
       "                        <td id=\"T_3f696af2_c9ee_11ea_b9f6_784f434fb9dcrow3_col2\" class=\"data row3 col2\" >0.634600</td>\n",
       "                        <td id=\"T_3f696af2_c9ee_11ea_b9f6_784f434fb9dcrow3_col3\" class=\"data row3 col3\" >say, year, rate, rise, quarter, expect, growth, first, earning, increase</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_3f696af2_c9ee_11ea_b9f6_784f434fb9dcrow4_col0\" class=\"data row4 col0\" >4</td>\n",
       "                        <td id=\"T_3f696af2_c9ee_11ea_b9f6_784f434fb9dcrow4_col1\" class=\"data row4 col1\" >6</td>\n",
       "                        <td id=\"T_3f696af2_c9ee_11ea_b9f6_784f434fb9dcrow4_col2\" class=\"data row4 col2\" >0.048400</td>\n",
       "                        <td id=\"T_3f696af2_c9ee_11ea_b9f6_784f434fb9dcrow4_col3\" class=\"data row4 col3\" >say, trade, would, export, official, government, import, country, year, japanese</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_3f696af2_c9ee_11ea_b9f6_784f434fb9dcrow5_col0\" class=\"data row5 col0\" >5</td>\n",
       "                        <td id=\"T_3f696af2_c9ee_11ea_b9f6_784f434fb9dcrow5_col1\" class=\"data row5 col1\" >6</td>\n",
       "                        <td id=\"T_3f696af2_c9ee_11ea_b9f6_784f434fb9dcrow5_col2\" class=\"data row5 col2\" >0.990400</td>\n",
       "                        <td id=\"T_3f696af2_c9ee_11ea_b9f6_784f434fb9dcrow5_col3\" class=\"data row5 col3\" >say, trade, would, export, official, government, import, country, year, japanese</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_3f696af2_c9ee_11ea_b9f6_784f434fb9dcrow6_col0\" class=\"data row6 col0\" >6</td>\n",
       "                        <td id=\"T_3f696af2_c9ee_11ea_b9f6_784f434fb9dcrow6_col1\" class=\"data row6 col1\" >2</td>\n",
       "                        <td id=\"T_3f696af2_c9ee_11ea_b9f6_784f434fb9dcrow6_col2\" class=\"data row6 col2\" >0.074800</td>\n",
       "                        <td id=\"T_3f696af2_c9ee_11ea_b9f6_784f434fb9dcrow6_col3\" class=\"data row6 col3\" >say, crop, year, deficit, soybean, estimate, last, trade, surplus, program</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_3f696af2_c9ee_11ea_b9f6_784f434fb9dcrow7_col0\" class=\"data row7 col0\" >7</td>\n",
       "                        <td id=\"T_3f696af2_c9ee_11ea_b9f6_784f434fb9dcrow7_col1\" class=\"data row7 col1\" >2</td>\n",
       "                        <td id=\"T_3f696af2_c9ee_11ea_b9f6_784f434fb9dcrow7_col2\" class=\"data row7 col2\" >0.618400</td>\n",
       "                        <td id=\"T_3f696af2_c9ee_11ea_b9f6_784f434fb9dcrow7_col3\" class=\"data row7 col3\" >say, crop, year, deficit, soybean, estimate, last, trade, surplus, program</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_3f696af2_c9ee_11ea_b9f6_784f434fb9dcrow8_col0\" class=\"data row8 col0\" >8</td>\n",
       "                        <td id=\"T_3f696af2_c9ee_11ea_b9f6_784f434fb9dcrow8_col1\" class=\"data row8 col1\" >8</td>\n",
       "                        <td id=\"T_3f696af2_c9ee_11ea_b9f6_784f434fb9dcrow8_col2\" class=\"data row8 col2\" >0.977200</td>\n",
       "                        <td id=\"T_3f696af2_c9ee_11ea_b9f6_784f434fb9dcrow8_col3\" class=\"data row8 col3\" >say, year, oil, price, production, last, would, rise, market, export</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_3f696af2_c9ee_11ea_b9f6_784f434fb9dcrow9_col0\" class=\"data row9 col0\" >9</td>\n",
       "                        <td id=\"T_3f696af2_c9ee_11ea_b9f6_784f434fb9dcrow9_col1\" class=\"data row9 col1\" >0</td>\n",
       "                        <td id=\"T_3f696af2_c9ee_11ea_b9f6_784f434fb9dcrow9_col2\" class=\"data row9 col2\" >0.172700</td>\n",
       "                        <td id=\"T_3f696af2_c9ee_11ea_b9f6_784f434fb9dcrow9_col3\" class=\"data row9 col3\" >say, year, rate, rise, quarter, expect, growth, first, earning, increase</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x12888ad10>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gensim_topic_df.head(10).style.hide_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe above displays the most likely topic along with the likelyhood of that topic. The keywords that describe the topics are also shown. When aggregated in the data frame below, topic 0 emerges as the most common topic with 45% of the articles classified as such. Topics 3 and 5 round out the top 3 of topics represent in more than 10% of the articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_91aea3de_c9f0_11ea_b9f6_784f434fb9dcrow0_col2 {\n",
       "            background-color:  #08306b;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_91aea3de_c9f0_11ea_b9f6_784f434fb9dcrow1_col2 {\n",
       "            background-color:  #dbe9f6;\n",
       "            color:  #000000;\n",
       "        }    #T_91aea3de_c9f0_11ea_b9f6_784f434fb9dcrow2_col2 {\n",
       "            background-color:  #dce9f6;\n",
       "            color:  #000000;\n",
       "        }    #T_91aea3de_c9f0_11ea_b9f6_784f434fb9dcrow3_col2 {\n",
       "            background-color:  #94c4df;\n",
       "            color:  #000000;\n",
       "        }    #T_91aea3de_c9f0_11ea_b9f6_784f434fb9dcrow4_col2 {\n",
       "            background-color:  #eaf2fb;\n",
       "            color:  #000000;\n",
       "        }    #T_91aea3de_c9f0_11ea_b9f6_784f434fb9dcrow5_col2 {\n",
       "            background-color:  #ccdff1;\n",
       "            color:  #000000;\n",
       "        }    #T_91aea3de_c9f0_11ea_b9f6_784f434fb9dcrow6_col2 {\n",
       "            background-color:  #f2f8fd;\n",
       "            color:  #000000;\n",
       "        }    #T_91aea3de_c9f0_11ea_b9f6_784f434fb9dcrow7_col2 {\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }    #T_91aea3de_c9f0_11ea_b9f6_784f434fb9dcrow8_col2 {\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }</style><table id=\"T_91aea3de_c9f0_11ea_b9f6_784f434fb9dc\" ><thead>    <tr>        <th class=\"col_heading level0 col0\" >best_topic</th>        <th class=\"col_heading level0 col1\" >keywords</th>        <th class=\"col_heading level0 col2\" >proportion</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_91aea3de_c9f0_11ea_b9f6_784f434fb9dcrow0_col0\" class=\"data row0 col0\" >0</td>\n",
       "                        <td id=\"T_91aea3de_c9f0_11ea_b9f6_784f434fb9dcrow0_col1\" class=\"data row0 col1\" >say, year, rate, rise, quarter, expect, growth, first, earning, increase</td>\n",
       "                        <td id=\"T_91aea3de_c9f0_11ea_b9f6_784f434fb9dcrow0_col2\" class=\"data row0 col2\" >45.600000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_91aea3de_c9f0_11ea_b9f6_784f434fb9dcrow1_col0\" class=\"data row1 col0\" >1</td>\n",
       "                        <td id=\"T_91aea3de_c9f0_11ea_b9f6_784f434fb9dcrow1_col1\" class=\"data row1 col1\" >price, say, oil, raise, crude, trader, barrel, today, dlrs, rate</td>\n",
       "                        <td id=\"T_91aea3de_c9f0_11ea_b9f6_784f434fb9dcrow1_col2\" class=\"data row1 col2\" >7.610000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_91aea3de_c9f0_11ea_b9f6_784f434fb9dcrow2_col0\" class=\"data row2 col0\" >2</td>\n",
       "                        <td id=\"T_91aea3de_c9f0_11ea_b9f6_784f434fb9dcrow2_col1\" class=\"data row2 col1\" >say, crop, year, deficit, soybean, estimate, last, trade, surplus, program</td>\n",
       "                        <td id=\"T_91aea3de_c9f0_11ea_b9f6_784f434fb9dcrow2_col2\" class=\"data row2 col2\" >7.420000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_91aea3de_c9f0_11ea_b9f6_784f434fb9dcrow3_col0\" class=\"data row3 col0\" >3</td>\n",
       "                        <td id=\"T_91aea3de_c9f0_11ea_b9f6_784f434fb9dcrow3_col1\" class=\"data row3 col1\" >say, company, share, offer, would, buy, stock, group, also, sell</td>\n",
       "                        <td id=\"T_91aea3de_c9f0_11ea_b9f6_784f434fb9dcrow3_col2\" class=\"data row3 col2\" >19.080000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_91aea3de_c9f0_11ea_b9f6_784f434fb9dcrow4_col0\" class=\"data row4 col0\" >4</td>\n",
       "                        <td id=\"T_91aea3de_c9f0_11ea_b9f6_784f434fb9dcrow4_col1\" class=\"data row4 col1\" >say, bank, market, rise, dollar, rate, dealer, money, yen, currency</td>\n",
       "                        <td id=\"T_91aea3de_c9f0_11ea_b9f6_784f434fb9dcrow4_col2\" class=\"data row4 col2\" >4.230000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_91aea3de_c9f0_11ea_b9f6_784f434fb9dcrow5_col0\" class=\"data row5 col0\" >5</td>\n",
       "                        <td id=\"T_91aea3de_c9f0_11ea_b9f6_784f434fb9dcrow5_col1\" class=\"data row5 col1\" >loss, net, ct, profit, dlrs, sale, year, say, include, note</td>\n",
       "                        <td id=\"T_91aea3de_c9f0_11ea_b9f6_784f434fb9dcrow5_col2\" class=\"data row5 col2\" >11.100000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_91aea3de_c9f0_11ea_b9f6_784f434fb9dcrow6_col0\" class=\"data row6 col0\" >6</td>\n",
       "                        <td id=\"T_91aea3de_c9f0_11ea_b9f6_784f434fb9dcrow6_col1\" class=\"data row6 col1\" >say, trade, would, export, official, government, import, country, year, japanese</td>\n",
       "                        <td id=\"T_91aea3de_c9f0_11ea_b9f6_784f434fb9dcrow6_col2\" class=\"data row6 col2\" >2.420000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_91aea3de_c9f0_11ea_b9f6_784f434fb9dcrow7_col0\" class=\"data row7 col0\" >7</td>\n",
       "                        <td id=\"T_91aea3de_c9f0_11ea_b9f6_784f434fb9dcrow7_col1\" class=\"data row7 col1\" >share, ct, say, dividend, stock, record, split, dlrs, may, pay</td>\n",
       "                        <td id=\"T_91aea3de_c9f0_11ea_b9f6_784f434fb9dcrow7_col2\" class=\"data row7 col2\" >1.260000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_91aea3de_c9f0_11ea_b9f6_784f434fb9dcrow8_col0\" class=\"data row8 col0\" >8</td>\n",
       "                        <td id=\"T_91aea3de_c9f0_11ea_b9f6_784f434fb9dcrow8_col1\" class=\"data row8 col1\" >say, year, oil, price, production, last, would, rise, market, export</td>\n",
       "                        <td id=\"T_91aea3de_c9f0_11ea_b9f6_784f434fb9dcrow8_col2\" class=\"data row8 col2\" >1.290000</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x128b13490>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_topic_prop = get_topic_distribution(gensim_topic_df)\n",
    "gs_topic_prop.style.hide_index().background_gradient(subset='proportion',cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best Mallet Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract best topic for each article along with associate keywords and likelyhood\n",
    "def get_best_mallet_topics(lda_model, corpus):\n",
    "    lda_model_corpus = lda_model[corpus]\n",
    "    art_topic_keywords = pd.DataFrame(columns = ['article','best_topic','likelyhood','keywords'])\n",
    "    \n",
    "    for i in range(len(lda_model_corpus)):\n",
    "        # Get article topic model distribution\n",
    "        article = lda_model_corpus[i]\n",
    "\n",
    "        # Find the max likelyhood index and select the corresponding topic\n",
    "        likelyhood = [likelyhood for topic,likelyhood in article]\n",
    "        max_likelyhood = max(likelyhood)\n",
    "        best_topic = likelyhood.index(max_likelyhood)\n",
    "        \n",
    "        # Get keywords for best topcis\n",
    "        wp = lda_model.show_topic(best_topic)\n",
    "        topic_keywords = ', '.join([word for word, prop in wp])\n",
    "        \n",
    "        # Assemble and append information to dataframe\n",
    "        d = {'article': i, 'best_topic': best_topic,'likelyhood': max_likelyhood,'keywords': topic_keywords}\n",
    "        art_topic_keywords = art_topic_keywords.append(d, ignore_index=True)\n",
    "        \n",
    "    return art_topic_keywords\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "mallet_topic_df = get_best_mallet_topics(ldamallet, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>best_topic</th>\n",
       "      <th>likelyhood</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.298117</td>\n",
       "      <td>official, trade, japanese, industry, make, cal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.156450</td>\n",
       "      <td>government, debt, year, problem, state, add, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.206019</td>\n",
       "      <td>oil, price, production, crude, barrel, gold, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0.199495</td>\n",
       "      <td>trade, export, import, year, deficit, surplus,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.140772</td>\n",
       "      <td>oil, price, production, crude, barrel, gold, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10783</th>\n",
       "      <td>10783</td>\n",
       "      <td>0</td>\n",
       "      <td>0.115741</td>\n",
       "      <td>bank, market, week, money, rate, fund, reserve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10784</th>\n",
       "      <td>10784</td>\n",
       "      <td>11</td>\n",
       "      <td>0.084906</td>\n",
       "      <td>ct, loss, net, profit, note, exclude, shr, ope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10785</th>\n",
       "      <td>10785</td>\n",
       "      <td>11</td>\n",
       "      <td>0.084906</td>\n",
       "      <td>ct, loss, net, profit, note, exclude, shr, ope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10786</th>\n",
       "      <td>10786</td>\n",
       "      <td>11</td>\n",
       "      <td>0.252451</td>\n",
       "      <td>ct, loss, net, profit, note, exclude, shr, ope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10787</th>\n",
       "      <td>10787</td>\n",
       "      <td>0</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>bank, market, week, money, rate, fund, reserve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10788 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      article best_topic  likelyhood  \\\n",
       "0           0          9    0.298117   \n",
       "1           1         15    0.156450   \n",
       "2           2          4    0.206019   \n",
       "3           3          6    0.199495   \n",
       "4           4          4    0.140772   \n",
       "...       ...        ...         ...   \n",
       "10783   10783          0    0.115741   \n",
       "10784   10784         11    0.084906   \n",
       "10785   10785         11    0.084906   \n",
       "10786   10786         11    0.252451   \n",
       "10787   10787          0    0.050000   \n",
       "\n",
       "                                                keywords  \n",
       "0      official, trade, japanese, industry, make, cal...  \n",
       "1      government, debt, year, problem, state, add, g...  \n",
       "2      oil, price, production, crude, barrel, gold, o...  \n",
       "3      trade, export, import, year, deficit, surplus,...  \n",
       "4      oil, price, production, crude, barrel, gold, o...  \n",
       "...                                                  ...  \n",
       "10783  bank, market, week, money, rate, fund, reserve...  \n",
       "10784  ct, loss, net, profit, note, exclude, shr, ope...  \n",
       "10785  ct, loss, net, profit, note, exclude, shr, ope...  \n",
       "10786  ct, loss, net, profit, note, exclude, shr, ope...  \n",
       "10787  bank, market, week, money, rate, fund, reserve...  \n",
       "\n",
       "[10788 rows x 4 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mallet_topic_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using the mallet model, the porportion are a lot more diversified which makes sense given the increased number of topics. Update this if number of topics end up changing.\n",
    "\n",
    "Topic 11 makes up for 17% of the articles with keywords like: ct, loss, net, profit, note, exclude, shr, oper, mth, rev. We can recognize these as words from earnings reports. \n",
    "\n",
    "Topic 14 with nearly 10% is the second most represented with keywords: share, stock, common, dividend, record, shareholder, outstanding, split, pay, company. Interestingly, while there is no overlap in the words, the theme of company and financial information is very similar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow0_col2 {\n",
       "            background-color:  #bfd8ed;\n",
       "            color:  #000000;\n",
       "        }    #T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow1_col2 {\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }    #T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow2_col2 {\n",
       "            background-color:  #d6e6f4;\n",
       "            color:  #000000;\n",
       "        }    #T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow3_col2 {\n",
       "            background-color:  #cadef0;\n",
       "            color:  #000000;\n",
       "        }    #T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow4_col2 {\n",
       "            background-color:  #c4daee;\n",
       "            color:  #000000;\n",
       "        }    #T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow5_col2 {\n",
       "            background-color:  #c7dcef;\n",
       "            color:  #000000;\n",
       "        }    #T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow6_col2 {\n",
       "            background-color:  #e8f1fa;\n",
       "            color:  #000000;\n",
       "        }    #T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow7_col2 {\n",
       "            background-color:  #d9e8f5;\n",
       "            color:  #000000;\n",
       "        }    #T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow8_col2 {\n",
       "            background-color:  #b4d3e9;\n",
       "            color:  #000000;\n",
       "        }    #T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow9_col2 {\n",
       "            background-color:  #e3eef9;\n",
       "            color:  #000000;\n",
       "        }    #T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow10_col2 {\n",
       "            background-color:  #d4e4f4;\n",
       "            color:  #000000;\n",
       "        }    #T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow11_col2 {\n",
       "            background-color:  #08306b;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow12_col2 {\n",
       "            background-color:  #e2edf8;\n",
       "            color:  #000000;\n",
       "        }    #T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow13_col2 {\n",
       "            background-color:  #eaf2fb;\n",
       "            color:  #000000;\n",
       "        }    #T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow14_col2 {\n",
       "            background-color:  #64a9d3;\n",
       "            color:  #000000;\n",
       "        }    #T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow15_col2 {\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }    #T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow16_col2 {\n",
       "            background-color:  #ebf3fb;\n",
       "            color:  #000000;\n",
       "        }    #T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow17_col2 {\n",
       "            background-color:  #e0ecf8;\n",
       "            color:  #000000;\n",
       "        }    #T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow18_col2 {\n",
       "            background-color:  #95c5df;\n",
       "            color:  #000000;\n",
       "        }    #T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow19_col2 {\n",
       "            background-color:  #e1edf8;\n",
       "            color:  #000000;\n",
       "        }</style><table id=\"T_578cf01a_c9f1_11ea_b9f6_784f434fb9dc\" ><thead>    <tr>        <th class=\"col_heading level0 col0\" >best_topic</th>        <th class=\"col_heading level0 col1\" >keywords</th>        <th class=\"col_heading level0 col2\" >proportion</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow0_col0\" class=\"data row0 col0\" >0</td>\n",
       "                        <td id=\"T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow0_col1\" class=\"data row0 col1\" >bank, market, week, money, rate, fund, reserve, day, today, mark</td>\n",
       "                        <td id=\"T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow0_col2\" class=\"data row0 col2\" >5.870000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow1_col0\" class=\"data row1 col0\" >1</td>\n",
       "                        <td id=\"T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow1_col1\" class=\"data row1 col1\" >loan, future, change, interest, add, contract, cent, canadian, make, increase</td>\n",
       "                        <td id=\"T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow1_col2\" class=\"data row1 col2\" >1.470000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow2_col0\" class=\"data row2 col0\" >2</td>\n",
       "                        <td id=\"T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow2_col1\" class=\"data row2 col1\" >year, expect, quarter, report, earning, result, end, revenue, fiscal, high</td>\n",
       "                        <td id=\"T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow2_col2\" class=\"data row2 col2\" >4.160000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow3_col0\" class=\"data row3 col0\" >3</td>\n",
       "                        <td id=\"T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow3_col1\" class=\"data row3 col1\" >dlrs, sale, include, mln, note, tax, gain, year, charge, income</td>\n",
       "                        <td id=\"T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow3_col2\" class=\"data row3 col2\" >5.160000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow4_col0\" class=\"data row4 col0\" >4</td>\n",
       "                        <td id=\"T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow4_col1\" class=\"data row4 col1\" >oil, price, production, crude, barrel, gold, output, gas, raise, supply</td>\n",
       "                        <td id=\"T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow4_col2\" class=\"data row4 col2\" >5.630000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow5_col0\" class=\"data row5 col0\" >5</td>\n",
       "                        <td id=\"T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow5_col1\" class=\"data row5 col1\" >offer, merger, bid, make, tender, proposal, takeover, propose, board, seek</td>\n",
       "                        <td id=\"T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow5_col2\" class=\"data row5 col2\" >5.440000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow6_col0\" class=\"data row6 col0\" >6</td>\n",
       "                        <td id=\"T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow6_col1\" class=\"data row6 col1\" >trade, export, import, year, deficit, surplus, country, foreign, product, official</td>\n",
       "                        <td id=\"T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow6_col2\" class=\"data row6 col2\" >2.730000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow7_col0\" class=\"data row7 col0\" >7</td>\n",
       "                        <td id=\"T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow7_col1\" class=\"data row7 col1\" >company, group, firm, investment, hold, business, analyst, buy, investor, management</td>\n",
       "                        <td id=\"T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow7_col2\" class=\"data row7 col2\" >3.880000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow8_col0\" class=\"data row8 col0\" >8</td>\n",
       "                        <td id=\"T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow8_col1\" class=\"data row8 col1\" >tonne, wheat, grain, crop, corn, estimate, week, total, production, soybean</td>\n",
       "                        <td id=\"T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow8_col2\" class=\"data row8 col2\" >6.410000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow9_col0\" class=\"data row9 col0\" >9</td>\n",
       "                        <td id=\"T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow9_col1\" class=\"data row9 col1\" >official, trade, japanese, industry, make, call, open, issue, farm, bill</td>\n",
       "                        <td id=\"T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow9_col2\" class=\"data row9 col2\" >3.060000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow10_col0\" class=\"data row10 col0\" >10</td>\n",
       "                        <td id=\"T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow10_col1\" class=\"data row10 col1\" >rise, year, fall, month, compare, figure, increase, early, total, previous</td>\n",
       "                        <td id=\"T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow10_col2\" class=\"data row10 col2\" >4.360000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow11_col0\" class=\"data row11 col0\" >11</td>\n",
       "                        <td id=\"T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow11_col1\" class=\"data row11 col1\" >ct, loss, net, profit, note, exclude, shr, oper, mth, rev</td>\n",
       "                        <td id=\"T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow11_col2\" class=\"data row11 col2\" >17.660000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow12_col0\" class=\"data row12 col0\" >12</td>\n",
       "                        <td id=\"T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow12_col1\" class=\"data row12 col1\" >rate, growth, cut, interest, economic, policy, economy, inflation, low, point</td>\n",
       "                        <td id=\"T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow12_col2\" class=\"data row12 col2\" >3.210000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow13_col0\" class=\"data row13 col0\" >13</td>\n",
       "                        <td id=\"T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow13_col1\" class=\"data row13 col1\" >price, agreement, producer, meeting, talk, member, coffee, quota, consumer, agree</td>\n",
       "                        <td id=\"T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow13_col2\" class=\"data row13 col2\" >2.560000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow14_col0\" class=\"data row14 col0\" >14</td>\n",
       "                        <td id=\"T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow14_col1\" class=\"data row14 col1\" >share, stock, common, dividend, record, shareholder, outstanding, split, pay, company</td>\n",
       "                        <td id=\"T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow14_col2\" class=\"data row14 col2\" >9.930000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow15_col0\" class=\"data row15 col0\" >15</td>\n",
       "                        <td id=\"T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow15_col1\" class=\"data row15 col1\" >government, debt, year, problem, state, add, grow, major, foreign, time</td>\n",
       "                        <td id=\"T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow15_col2\" class=\"data row15 col2\" >1.530000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow16_col0\" class=\"data row16 col0\" >16</td>\n",
       "                        <td id=\"T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow16_col1\" class=\"data row16 col1\" >plan, cost, company, pay, make, plant, statement, operation, announce, program</td>\n",
       "                        <td id=\"T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow16_col2\" class=\"data row16 col2\" >2.420000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow17_col0\" class=\"data row17 col0\" >17</td>\n",
       "                        <td id=\"T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow17_col1\" class=\"data row17 col1\" >spokesman, today, official, ship, strike, begin, work, attack, port, close</td>\n",
       "                        <td id=\"T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow17_col2\" class=\"data row17 col2\" >3.360000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow18_col0\" class=\"data row18 col0\" >18</td>\n",
       "                        <td id=\"T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow18_col1\" class=\"data row18 col1\" >unit, buy, sell, sale, acquire, purchase, acquisition, company, complete, agree</td>\n",
       "                        <td id=\"T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow18_col2\" class=\"data row18 col2\" >7.920000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow19_col0\" class=\"data row19 col0\" >19</td>\n",
       "                        <td id=\"T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow19_col1\" class=\"data row19 col1\" >market, dollar, exchange, currency, yen, analyst, dealer, level, intervention, major</td>\n",
       "                        <td id=\"T_578cf01a_c9f1_11ea_b9f6_784f434fb9dcrow19_col2\" class=\"data row19 col2\" >3.260000</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x128b136d0>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mallet_topic_prop = get_topic_distribution(mallet_topic_df)\n",
    "mallet_topic_prop.style.hide_index().background_gradient(subset='proportion',cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discuss overlap between columns. Maybe read an example article to validate. Talk about verification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary dataframe with keywords from each model vs known categories\n",
    "summary_df = pd.concat([df['Category'], gensim_topic_df['keywords'], mallet_topic_df['keywords']], axis=1, sort=False)\n",
    "summary_df.columns = ['reuters_categories','gensim_keywords','mallet_keywords']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reuters_categories</th>\n",
       "      <th>gensim_keywords</th>\n",
       "      <th>mallet_keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[trade]</td>\n",
       "      <td>say, year, rate, rise, quarter, expect, growth...</td>\n",
       "      <td>official, trade, japanese, industry, make, cal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[grain]</td>\n",
       "      <td>say, crop, year, deficit, soybean, estimate, l...</td>\n",
       "      <td>government, debt, year, problem, state, add, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[crude, nat-gas]</td>\n",
       "      <td>say, year, oil, price, production, last, would...</td>\n",
       "      <td>oil, price, production, crude, barrel, gold, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[corn, grain, rice, rubber, sugar, tin, trade]</td>\n",
       "      <td>say, year, rate, rise, quarter, expect, growth...</td>\n",
       "      <td>trade, export, import, year, deficit, surplus,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[palm-oil, veg-oil]</td>\n",
       "      <td>say, trade, would, export, official, governmen...</td>\n",
       "      <td>oil, price, production, crude, barrel, gold, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10783</th>\n",
       "      <td>[interest, money-fx]</td>\n",
       "      <td>say, bank, market, rise, dollar, rate, dealer,...</td>\n",
       "      <td>bank, market, week, money, rate, fund, reserve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10784</th>\n",
       "      <td>[earn]</td>\n",
       "      <td>say, year, rate, rise, quarter, expect, growth...</td>\n",
       "      <td>ct, loss, net, profit, note, exclude, shr, ope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10785</th>\n",
       "      <td>[earn]</td>\n",
       "      <td>say, year, rate, rise, quarter, expect, growth...</td>\n",
       "      <td>ct, loss, net, profit, note, exclude, shr, ope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10786</th>\n",
       "      <td>[earn]</td>\n",
       "      <td>say, company, share, offer, would, buy, stock,...</td>\n",
       "      <td>ct, loss, net, profit, note, exclude, shr, ope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10787</th>\n",
       "      <td>[earn]</td>\n",
       "      <td>say, year, rate, rise, quarter, expect, growth...</td>\n",
       "      <td>bank, market, week, money, rate, fund, reserve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10788 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   reuters_categories  \\\n",
       "0                                             [trade]   \n",
       "1                                             [grain]   \n",
       "2                                    [crude, nat-gas]   \n",
       "3      [corn, grain, rice, rubber, sugar, tin, trade]   \n",
       "4                                 [palm-oil, veg-oil]   \n",
       "...                                               ...   \n",
       "10783                            [interest, money-fx]   \n",
       "10784                                          [earn]   \n",
       "10785                                          [earn]   \n",
       "10786                                          [earn]   \n",
       "10787                                          [earn]   \n",
       "\n",
       "                                         gensim_keywords  \\\n",
       "0      say, year, rate, rise, quarter, expect, growth...   \n",
       "1      say, crop, year, deficit, soybean, estimate, l...   \n",
       "2      say, year, oil, price, production, last, would...   \n",
       "3      say, year, rate, rise, quarter, expect, growth...   \n",
       "4      say, trade, would, export, official, governmen...   \n",
       "...                                                  ...   \n",
       "10783  say, bank, market, rise, dollar, rate, dealer,...   \n",
       "10784  say, year, rate, rise, quarter, expect, growth...   \n",
       "10785  say, year, rate, rise, quarter, expect, growth...   \n",
       "10786  say, company, share, offer, would, buy, stock,...   \n",
       "10787  say, year, rate, rise, quarter, expect, growth...   \n",
       "\n",
       "                                         mallet_keywords  \n",
       "0      official, trade, japanese, industry, make, cal...  \n",
       "1      government, debt, year, problem, state, add, g...  \n",
       "2      oil, price, production, crude, barrel, gold, o...  \n",
       "3      trade, export, import, year, deficit, surplus,...  \n",
       "4      oil, price, production, crude, barrel, gold, o...  \n",
       "...                                                  ...  \n",
       "10783  bank, market, week, money, rate, fund, reserve...  \n",
       "10784  ct, loss, net, profit, note, exclude, shr, ope...  \n",
       "10785  ct, loss, net, profit, note, exclude, shr, ope...  \n",
       "10786  ct, loss, net, profit, note, exclude, shr, ope...  \n",
       "10787  bank, market, week, money, rate, fund, reserve...  \n",
       "\n",
       "[10788 rows x 3 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can verify the relevance of the keywords generated from our topic models and the known labels against the actual text. For example, with the first text which is labeled as `trade` the related topic keywords for the topic models are:\n",
    "\n",
    "- Gensim: say, year, rate, rise, quarter, expect, growth, first, earning, increase (45% of articles are related)\n",
    "- MALLET: official, trade, japanese, industry, make, call, open, issue, farm, bill (3% of articles are related)\n",
    "\n",
    "This tells us that the MALLET model is able to discern topics are that particularly related to japanese trade. In the case of the article below, this is spot on as is evident from the first couple of sentences. Meanwhile, the Gensim model is classifying this article in a larger mass of articles not limited to Japan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASIAN EXPORTERS FEAR DAMAGE FROM U.S.-JAPAN RIFT\n",
      "  Mounting trade friction between the\n",
      "  U.S. And Japan has raised fears among many of Asia's exporting\n",
      "  nations that the row could inflict far-reaching economic\n",
      "  damage, businessmen and officials said.\n",
      "      They told Reuter correspondents in Asian capitals a U.S.\n",
      "  Move against Japan might boost protectionist sentiment in the\n",
      "  U.S. And lead to curbs on American imports of their products.\n",
      "      But some exporters said that while the conflict would hurt\n",
      "  them in the long-run, in the short-term Tokyo's loss might be\n",
      "  their gain.\n",
      "      The U.S. Has said it will impose 300 mln dlrs of tariffs on\n",
      "  imports of Japanese electronics goods on April 17, in\n",
      "  retaliation for Japan's alleged failure to stick to a pact not\n",
      "  to sell semiconductors on world markets at below cost.\n",
      "      Unofficial Japanese estimates put the impact of the tariffs\n",
      "  at 10 billion dlrs and spokesmen for major electronics firms\n",
      "  said they would virtually halt exports\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[0,3][:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print chosen dataframe to csv file\n",
    "mallet_topic_df.to_csv('mallet_df.csv', index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Analysis\n",
    "\n",
    "- Expecting a disconnected graph with num_topics central nodes with edges to articles. \n",
    "- Get the top 5 largest subgraphs which represent the most common topics (degree centrality)\n",
    "- From the most popular topics, suggest next 5 articles to read by looking at edge weight (likelyhood)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dataframe from csv file and build a graph from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import networkx.algorithms.bipartite as bipartite\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_full = nx.from_pandas_edgelist(art_topic_keywords,'article','best_topic')\n",
    "G_full.graph['name'] = 'Full bipartite graph'\n",
    "print(nx.info(G_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'Graph is bipartite: {} \\nGraph is connected: {} \\nNumber of connected components {}'\n",
    "print(s.format(nx.is_bipartite(G_full), nx.is_connected(G_full), nx.number_connected_components(G_full)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify connected components with greater than five nodes\n",
    "sorted([len(c) for c in nx.connected_components(G_full) if len(c) > 5], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract subgraphs\n",
    "def get_subgraphs(graph):\n",
    "    \n",
    "    subgraphs = [(graph.subgraph(c),len(c)) for c in nx.connected_components(graph) if len(c) > 5] # networkx 2.4\n",
    "    return sorted(subgraphs, key = lambda x: x[1], reverse=True)\n",
    "\n",
    "# Create connected subgraphs and confirm\n",
    "subgraphs = get_subgraphs(G_full)\n",
    "print(*subgraphs[:5], '\\n', sep='\\n')\n",
    "\n",
    "# Isolate the largest subgraph\n",
    "largest_subg = subgraphs[0][0]\n",
    "largest_subg.graph['name'] = 'Main bipartite subgraph'\n",
    "print(nx.info(largest_subg), \"\\n\")\n",
    "\n",
    "# Verify largest subgraph is bipartite\n",
    "G = largest_subg\n",
    "print('Graph is bipartite: {} \\nGraph is connected: {} \\n'.format(nx.is_bipartite(G), nx.is_connected(G)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source node labels\n",
    "graph = G\n",
    "articles, topics = nx.bipartite.sets(graph)\n",
    "\n",
    "# Plot graph by node type\n",
    "# Apply plot settings\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "plt.rcParams['figure.figsize'] = (24,12)\n",
    "plt.axis('off')\n",
    "pos = nx.spring_layout(graph)\n",
    "nx.draw_networkx_nodes(graph, pos, nodelist=articles, node_color='red', alpha = 0.4)\n",
    "nx.draw_networkx_nodes(graph, pos, nodelist=topics, node_color='blue', alpha = 0.4, node_size = 1000)\n",
    "nx.draw_networkx_edges(graph, pos, alpha = 0.4)\n",
    "nx.draw_networkx_labels(graph, pos);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YouTube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(JO: add remaining references)\n",
    "\n",
    "**Topic Modeling**\n",
    "\n",
    "https://en.wikipedia.org/wiki/Topic_model\n",
    "https://springerplus.springeropen.com/articles/10.1186/s40064-016-3252-8\n",
    "https://mimno.infosci.cornell.edu/papers/2017_fntir_tm_applications.pdf\n",
    "https://cfss.uchicago.edu/notes/topic-modeling/\n",
    "\n",
    "**LDA**\n",
    "https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation\n",
    "https://en.wikipedia.org/wiki/Dirichlet_distribution https://towardsdatascience.com/light-on-math-machine-learning-intuitive-guide-to-latent-dirichlet-allocation-437c81220158\n",
    "\n",
    "**Perplexity and Coherence**\n",
    "https://en.wikipedia.org/wiki/Perplexity\n",
    "https://cfss.uchicago.edu/notes/topic-modeling/ (provides examples on optimizing perplexity\n",
    "https://mimno.infosci.cornell.edu/info6150/readings/N10-1012.pdf (automatic topic coherence evaluation)\n",
    "https://towardsdatascience.com/evaluate-topic-model-in-python-latent-dirichlet-allocation-lda-7d57484bb5d0\n",
    "http://qpleple.com/topic-coherence-to-evaluate-topic-models/ (intrinsic / extrinsic measures and associated math)\n",
    "\n",
    "**Gensim**\n",
    "https://radimrehurek.com/gensim/auto_examples/index.html\n",
    "https://www.thinkinfi.com/2019/08/LDA-Gensim-Python.html\n",
    "https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/\n",
    "https://www.machinelearningplus.com/nlp/topic-modeling-visualization-how-to-present-results-lda-models/\n",
    "https://towardsdatascience.com/building-a-topic-modeling-pipeline-with-spacy-and-gensim-c5dc03ffc619\n",
    "\n",
    "**Spacy**\n",
    "https://spacy.io/\n",
    "\n",
    "**MALLET**\n",
    "http://mallet.cs.umass.edu/topics.php\n",
    "https://www.thinkinfi.com/2019/08/LDA-Gensim-Python.html\n",
    "\n",
    "**Text Network Analysis**\n",
    "https://advances.sciencemag.org/content/4/7/eaaq1360\n",
    "https://noduslabs.com/wp-content/uploads/2019/06/InfraNodus-Paranyushkin-WWW19-Conference.pdf\n",
    "https://noduslabs.com/cases/tutorial-lda-text-mining-network-analysis/\n",
    "https://github.com/michal-pikusa/text-network-analysis\n",
    "https://github.com/martingerlach/hSBM_Topicmodel/blob/master/TopSBM-tutorial.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
