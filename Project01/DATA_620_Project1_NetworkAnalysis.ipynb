{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA 620\n",
    "\n",
    "---\n",
    "### Project 1\n",
    "### Mael Illien and Jeremy OBrien"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference materials:\n",
    "- [Foursquare Endpoints Overview](https://developer.foursquare.com/docs/places-api/endpoints/)\n",
    "- [Foursquare Places API Next Venues](https://developer.foursquare.com/docs/api-reference/venues/nextvenues/)\n",
    "- [Foursquare Places API Venue Categories](https://developer.foursquare.com/docs/api-reference/venues/categories/)\n",
    "- [Foursquare Places API Authentication](https://developer.foursquare.com/docs/places-api/authentication/)\n",
    "- [Building a Foursquare Location Graph](https://nbviewer.jupyter.org/github/furukama/IPythonNotebooks/blob/master/Building%20a%20Foursquare%20Location%20Graph.ipynb)\n",
    "- [How to create a location graph from the Foursquare API](http://beautifuldata.net/2014/05/how-to-create-a-location-graph-from-the-foursquare-api/)\n",
    "- [Classification of Moscow Metro stations using Foursquare data](https://towardsdatascience.com/classification-of-moscow-metro-stations-using-foursquare-data-fb8aad3e0e4)\n",
    "- [A brief guide to using Foursquare API with a hands-on example in Python](https://medium.com/@aboutiana/a-brief-guide-to-using-foursquare-api-with-a-hands-on-example-on-python-6fc4d5451203)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bounding box for NYC based on [geographic extent](https://www1.nyc.gov/assets/planning/download/pdf/data-maps/open-data/nybb_metadata.pdf?ver=18c)\n",
    "- North 40.915568 \n",
    "- South 40.495992\n",
    "- East -73.699215\n",
    "- West -74.257159 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox = [40.4959929,-74.257159,40.915568,-73.699215]  # bounding box for New York City"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_crawl = []  # list of locations to be crawled\n",
    "done_crawl = []  # list of crawled locations \n",
    "links = []  # list of tuples that represent links between locations\n",
    "venues = pd.DataFrame()  # dataframe (not dict?) of location id => meta-data on location "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import foursquare\n",
    "import pandas as pd\n",
    "\n",
    "# Fill these out to run but don't save to Github\n",
    "CLIENT_ID = ''\n",
    "CLIENT_SECRET = ''\n",
    "\n",
    "client = foursquare.Foursquare(client_id=CLIENT_ID, client_secret=CLIENT_SECRET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: 1 locations and 0 links.1 venues to go.\n",
      "Step 1: 2 locations and 0 links.0 venues to go.\n",
      "Step 2: 2 locations and 0 links.0 venues to go.\n",
      "Step 3: 2 locations and 0 links.0 venues to go.\n",
      "Step 4: 2 locations and 0 links.0 venues to go.\n",
      "Step 5: 2 locations and 0 links.0 venues to go.\n",
      "Step 6: 2 locations and 0 links.0 venues to go.\n",
      "Step 7: 2 locations and 0 links.0 venues to go.\n"
     ]
    }
   ],
   "source": [
    "to_crawl = ['43695300f964a5208c291fe3']  # Example of the Empire State Building\n",
    "depth = 8\n",
    "\n",
    "for i in range(depth):\n",
    "\n",
    "    new_crawl = []\n",
    "    print('Step ' + str(i) + ': ' + str(len(venues)) + ' locations and ' + str(len(links)) + ' links.' + str(len(to_crawl)) + ' venues to go.')\n",
    "    \n",
    "    for v in to_crawl:\n",
    "        \n",
    "        if v not in venues:\n",
    "            res = client.venues(v)\n",
    "            venues = venues.append(pd.DataFrame(\n",
    "                \n",
    "                # 3rd-level subset (userCount, checkinsCount, lat, lng) throwing errors\n",
    "                {'name':res['venue']['name'],\n",
    "                 'users':res['venue']['stats']['usersCount'],\n",
    "                 'checkins':res['venue']['stats']['checkinsCount'],\n",
    "                 'lat':res['venue']['location']['lat'],\n",
    "                 'lng':res['venue']['location']['lng']},\n",
    "                index = [v]\n",
    "            ))\n",
    "        \n",
    "        next_venues = client.venues.nextvenues(v)\n",
    "        \n",
    "        for nv in next_venues['nextVenues']['items']:\n",
    "            \n",
    "            if ((nv['location']['lat'] > bbox[1]) & \n",
    "                (nv['location']['lat'] < bbox[3]) & \n",
    "                (nv['location']['lng'] > bbox[0]) & \n",
    "                (nv['location']['lng'] < bbox[2])):\n",
    "                \n",
    "                if nv['id'] not in venues:\n",
    "                    venues = venues.append(pd.DataFrame(\n",
    "                        {'name':nv['name'], \n",
    "                         'users':nv['stats']['usersCount'],\n",
    "                         'checkins':nv['stats']['checkinsCount'],\n",
    "                         'lat':nv['location']['lat'],\n",
    "                         'lng':nv['location']['lng']},\n",
    "                        index = [nv['id']]\n",
    "                    ))\n",
    "                \n",
    "                if (nv['id'] not in done_crawl) & (nv['id'] not in to_crawl) & (nv['id'] not in new_crawl):\n",
    "                    new_crawl.append(nv['id'])\n",
    "                \n",
    "                links.append(v, nv['id'])\n",
    "            \n",
    "            done_crawl.append(v)\n",
    "            \n",
    "        to_crawl = new_crawl\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate network\n",
    "venues = venues.reset.index().drop_duplicates(cols='index',take_last=True).set_index('index')\n",
    "labels = venues['name'].to_dict()\n",
    "\n",
    "import network as nx\n",
    "G = nv.DiGraph()\n",
    "G.add_nodes_from(venues.index)\n",
    "for f, t in links:\n",
    "    G.add_edge(f, t)\n",
    "    \n",
    "nx.info(G)\n",
    "\n",
    "pagerank = nx.pagerank(G, alpha=.9)\n",
    "venues['pagerank'] = [pagerank[n] for n in venues.index]\n",
    "\n",
    "betweenness = nx.betweenness_centrality(G)\n",
    "venues['betweenness'] = [betweenness[n] for n in venues.index]\n",
    "\n",
    "# Plot network\n",
    "\n",
    "fig = plt.figure(figsize(16,9), dpi=150))\n",
    "graph_pos = nx.spring_layout(G)\n",
    "nodesize = [10000 * n for n in page.rank.values()]\n",
    "nx.draw_networks_nodes(G, graph_pos, node_size=nodesize, alpha=.5, node_color='blue')\n",
    "nx.draw_networks_edges(G, graph_pos, width=1, alpha=.3, edge_color='blue')\n",
    "nx.draw_networkx_labels(G, graph_pos, labels=labels, font_size=10, font_family='Arial')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_620_base",
   "language": "python",
   "name": "data_620_base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
