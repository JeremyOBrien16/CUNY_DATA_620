{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA 620 - Project 3\n",
    "\n",
    "Jeremy OBrien, Mael Illien, Vanita Thompson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Using any of the three classifiers described in chapter 6 of Natural Language Processing with Python, and any features you can think of, build the best name gender classifier you can. \n",
    "* Begin by splitting the Names Corpus into three subsets: 500 words for the test set, 500 words for the dev-test set, and the remaining 6900 words for the training set. \n",
    "* Then, starting with the example name gender classifier, make incremental improvements. Use the dev-test set to check your progress. \n",
    "* Once you are satisfied with your classifier, check its final performance on the test set. \n",
    "* How does the performance on the test set compare to the performance on the dev-test set? Is this what you'd expect?\n",
    "* Source: Natural Language Processing with Python, exercise 6.10.2.\n",
    "\n",
    "The three classifiers from Chapter 6: NaiveBayes, DecisionTree, MaxEntropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import nltk, re, pprint\n",
    "from nltk.corpus import names\n",
    "from nltk.classify import apply_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Description of approach)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import & Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Sinclair', 'male'),\n",
       " ('Raleigh', 'male'),\n",
       " ('Tarrah', 'female'),\n",
       " ('Jeremiah', 'male'),\n",
       " ('Lesley', 'female'),\n",
       " ('Lanny', 'male'),\n",
       " ('Reynolds', 'male'),\n",
       " ('Selina', 'female'),\n",
       " ('Kaleena', 'female'),\n",
       " ('Luce', 'female')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_names = ([(name, 'male') for name in names.words('male.txt')] + \n",
    "         [(name, 'female') for name in names.words('female.txt')])\n",
    "\n",
    "random.shuffle(labeled_names)\n",
    "labeled_names[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incorporated in function\n",
    "# train_names = labeled_names[:500]\n",
    "# devtest_names = labeled_names[500:1000]\n",
    "# test_names = labeled_names[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incorporated in function\n",
    "# train_set = [(gender_features(n), gender) for (n, gender) in train_names]\n",
    "# devtest_set = [(gender_features(n), gender) for (n, gender) in devtest_names]\n",
    "# test_set = [(gender_features(n), gender) for (n, gender) in test_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_classifier(names_corpus, gender_features_function, classifier_type):\n",
    "#     train_set = apply_features(gender_features, names[:500])\n",
    "#     devtest_set = apply_features(gender_features, names[500:1000])\n",
    "#     test_set = apply_features(gender_features, names[1000:])\n",
    "\n",
    "    # Train test split\n",
    "    train_names = names_corpus[:500]\n",
    "    devtest_names = names_corpus[500:1000]\n",
    "    test_names = names_corpus[1000:]\n",
    "    \n",
    "    # Appy features\n",
    "    train_set = [(gender_features_function(n), gender) for (n, gender) in train_names]\n",
    "    devtest_set = [(gender_features_function(n), gender) for (n, gender) in devtest_names]\n",
    "    test_set = [(gender_features_function(n), gender) for (n, gender) in test_names]\n",
    "    \n",
    "    # Classify and print score\n",
    "    classifier = classifier_type.train(train_set)\n",
    "    print(nltk.classify.accuracy(classifier, devtest_set))\n",
    "    print(nltk.classify.accuracy(classifier, test_set))\n",
    "    \n",
    "    #classifier.show_most_informative_features(5)\n",
    "    \n",
    "    return classifier  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def errors(classifier):\n",
    "    errors = []\n",
    "    for (name, tag) in devtest_names:\n",
    "        guess = classifier.classify(gender_features(name))\n",
    "        if guess != tag:\n",
    "            errors.append( (tag, guess, name) )\n",
    "            \n",
    "    for (tag, guess, name) in sorted(errors): \n",
    "        print('correct=%-8s guess=%-8s name=%-30s'%(tag, guess, name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Explanation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_features(word):\n",
    "    return {'last_letter': word[-1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'last_letter': 'n'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_features('John')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_features2(name):\n",
    "    features = {}\n",
    "    features[\"firstletter\"] = name[0].lower()\n",
    "    features[\"lastletter\"] = name[-1].lower()\n",
    "    for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
    "        features[\"count(%s)\" % letter] = name.lower().count(letter)\n",
    "        features[\"has(%s)\" % letter] = (letter in name.lower())\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gender_features2('John')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_features3(word):\n",
    "    return {'suffix1': word[-1:],'suffix2': word[-2:]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'suffix1': 'a', 'suffix2': 'na'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_features3('Cristina')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_features4(name):\n",
    "    features = {}\n",
    "    features[\"firstletter\"] = name[0].lower()\n",
    "    features[\"lastletter\"] = name[-1].lower()\n",
    "    features['suffix1'] =  name[-1:]\n",
    "    features['suffix2'] = name[-2:]\n",
    "    features['suffix3'] = name[-3:]\n",
    "    # features['length'] = len(name) # doesn't add much\n",
    "    #suf = []\n",
    "    for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
    "        features[\"count(%s)\" % letter] = name.lower().count(letter)\n",
    "        features[\"has(%s)\" % letter] = (letter in name.lower())\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.742\n",
      "0.741647465437788\n"
     ]
    }
   ],
   "source": [
    "mod1 = test_classifier(labeled_names, gender_features, nltk.NaiveBayesClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "             last_letter = 'r'              male : female =     20.0 : 1.0\n",
      "             last_letter = 'd'              male : female =      8.0 : 1.0\n",
      "             last_letter = 't'              male : female =      6.9 : 1.0\n",
      "             last_letter = 'i'            female : male   =      5.3 : 1.0\n",
      "             last_letter = 'o'              male : female =      5.3 : 1.0\n",
      "male\n",
      "female\n"
     ]
    }
   ],
   "source": [
    "mod1.show_most_informative_features(5)\n",
    "print(mod1.classify(gender_features('Neo')))\n",
    "print(mod1.classify(gender_features('Trinity')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.722\n",
      "0.7386232718894009\n",
      "Most Informative Features\n",
      "              lastletter = 'a'            female : male   =     16.4 : 1.0\n",
      "              lastletter = 'o'              male : female =     15.5 : 1.0\n",
      "              lastletter = 's'              male : female =     15.5 : 1.0\n",
      "             firstletter = 'h'              male : female =      6.9 : 1.0\n",
      "              lastletter = 'r'              male : female =      6.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "mod2 = test_classifier(labeled_names, gender_features2, nltk.NaiveBayesClassifier)\n",
    "mod2.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.774\n",
      "0.7564804147465438\n",
      "Most Informative Features\n",
      "                 suffix1 = 'a'            female : male   =     16.4 : 1.0\n",
      "                 suffix1 = 'o'              male : female =     15.5 : 1.0\n",
      "                 suffix1 = 's'              male : female =     15.5 : 1.0\n",
      "                 suffix1 = 'r'              male : female =      6.3 : 1.0\n",
      "                 suffix1 = 'k'              male : female =      5.5 : 1.0\n"
     ]
    }
   ],
   "source": [
    "mod3 = test_classifier(labeled_names, gender_features3, nltk.NaiveBayesClassifier)\n",
    "mod3.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.76\n",
      "0.7785138248847926\n",
      "Most Informative Features\n",
      "              lastletter = 'a'            female : male   =     16.4 : 1.0\n",
      "                 suffix1 = 'a'            female : male   =     16.4 : 1.0\n",
      "                 suffix1 = 'o'              male : female =     15.5 : 1.0\n",
      "              lastletter = 'o'              male : female =     15.5 : 1.0\n",
      "              lastletter = 's'              male : female =     15.5 : 1.0\n",
      "                 suffix1 = 's'              male : female =     15.5 : 1.0\n",
      "             firstletter = 'h'              male : female =      6.9 : 1.0\n",
      "              lastletter = 'r'              male : female =      6.3 : 1.0\n",
      "                 suffix1 = 'r'              male : female =      6.3 : 1.0\n",
      "             firstletter = 'w'              male : female =      6.2 : 1.0\n"
     ]
    }
   ],
   "source": [
    "mod4 = test_classifier(labeled_names, gender_features4, nltk.NaiveBayesClassifier)\n",
    "mod4.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.686\n",
      "0.663594470046083\n"
     ]
    }
   ],
   "source": [
    "dt_mod1 = test_classifier(labeled_names, gender_features4, nltk.DecisionTreeClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def entropy(labels):\n",
    "    freqdist = nltk.FreqDist(labels)\n",
    "    probs = [freqdist.freq(l) for l in freqdist]\n",
    "    return -sum(p * math.log(p,2) for p in probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of using probabilites to set model parameters as the Naive Bayes classifier does, the Maximum Entropy Model (or MaxEnt) searches for the set of parameters that maximize model performance. The property of entropy entails uniformity of the distribution where there isn't empirical evidence that would constrain that uniformity.  \n",
    "\n",
    "Intuition is that classifiers with lower entropy introduce biases that are not justified. \n",
    "\n",
    "Importantly, MaxEnt does not assume independence of features (as Naive Bayes does) and so is not negatively impacted when there is dependence between features (can often be the case). As MaxEnt captures the structure of the training data, the more features it uses the stronger the constraint of empirical consistenycy becomes (reference)[https://lost-contact.mit.edu/afs/cs.pitt.edu/projects/nltk/docs/tutorial/classifying/nochunks.html#maxent].\n",
    "\n",
    "For each joint feature (define!), MaxEnt algorithms calculate the empirical frequency and...(complete!).\n",
    "\n",
    "NLTK offers two algorithms, Generalized Iterative Scaling (GIS) and Improved Iterative Scaling (IIS), which offers faster convergence. Accoring to wikipedia (link!) and the literature ('A comparison of algorithms for maximum entropy parameter estimation')[http://luthuli.cs.uiuc.edu/~daf/courses/Opt-2017/Papers/p18-malouf.pdf], the performance of these algorithms has been substantially improved uppon by gradient-based methods, such as coordinate descent and limited memory L-BFGS and LMBVM. Most notably, iterative optimizations can be time consuming\n",
    "\n",
    "Additionally, MaxEnt is a conditional classifier, meaning it can be used to determine the most likely label for a given input or conversely how likely a label is for that input.  A generative classifier like Naive Bayers can estimate the most likely input value, how likely an input value is, the same given an input label. \n",
    "\n",
    "https://web.stanford.edu/class/cs124/lec/Maximum_Entropy_Classifiers.pdf (cite!) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rapid comuptation, peaks after single iteration\n",
    "\n",
    "(Add chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "me_mod1 = test_classifier(labeled_names, gender_features, nltk.ConditionalExponentialClassifier)  # consider changing max_iter param to 20, how to add kwarg?\n",
    "\n",
    "# https://stackoverflow.com/questions/39391280/how-to-change-number-of-iterations-in-maxent-classifier-for-pos-tagging-in-nltk\n",
    "\n",
    "me_mod1.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   6.644 last_letter=='a' and label is 'female'\n",
      "   6.644 last_letter=='u' and label is 'male'\n",
      "   6.644 last_letter=='c' and label is 'male'\n",
      "   6.644 last_letter=='b' and label is 'male'\n",
      "   6.644 last_letter=='w' and label is 'male'\n",
      "  -3.000 last_letter=='i' and label is 'male'\n",
      "  -3.000 last_letter=='r' and label is 'female'\n",
      "  -1.503 last_letter=='d' and label is 'female'\n",
      "  -1.322 last_letter=='t' and label is 'female'\n",
      "  -1.095 last_letter=='e' and label is 'male'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(me_mod1.show_most_informative_features("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Explanation)\n",
    "\n",
    "(Add chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ==> Training (100 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.334\n",
      "             2          -0.57503        0.666\n",
      "             3          -0.56222        0.666\n",
      "             4          -0.55009        0.666\n",
      "             5          -0.53866        0.672\n",
      "             6          -0.52791        0.678\n",
      "             7          -0.51780        0.692\n",
      "             8          -0.50832        0.702\n",
      "             9          -0.49942        0.722\n",
      "            10          -0.49107        0.732\n",
      "            11          -0.48323        0.748\n",
      "            12          -0.47587        0.758\n",
      "            13          -0.46895        0.760\n",
      "            14          -0.46243        0.756\n",
      "            15          -0.45629        0.762\n",
      "            16          -0.45049        0.766\n",
      "            17          -0.44502        0.772\n",
      "            18          -0.43984        0.780\n",
      "            19          -0.43494        0.780\n",
      "            20          -0.43029        0.786\n",
      "            21          -0.42588        0.788\n",
      "            22          -0.42168        0.790\n",
      "            23          -0.41769        0.794\n",
      "            24          -0.41388        0.798\n",
      "            25          -0.41025        0.808\n",
      "            26          -0.40678        0.808\n",
      "            27          -0.40346        0.810\n",
      "            28          -0.40029        0.808\n",
      "            29          -0.39725        0.812\n",
      "            30          -0.39433        0.816\n",
      "            31          -0.39153        0.822\n",
      "            32          -0.38884        0.820\n",
      "            33          -0.38625        0.818\n",
      "            34          -0.38376        0.818\n",
      "            35          -0.38136        0.818\n",
      "            36          -0.37905        0.820\n",
      "            37          -0.37682        0.820\n",
      "            38          -0.37467        0.820\n",
      "            39          -0.37258        0.820\n",
      "            40          -0.37057        0.826\n",
      "            41          -0.36862        0.826\n",
      "            42          -0.36674        0.826\n",
      "            43          -0.36491        0.826\n",
      "            44          -0.36314        0.826\n",
      "            45          -0.36143        0.826\n",
      "            46          -0.35976        0.826\n",
      "            47          -0.35814        0.824\n",
      "            48          -0.35657        0.824\n",
      "            49          -0.35505        0.826\n",
      "            50          -0.35356        0.828\n",
      "            51          -0.35212        0.830\n",
      "            52          -0.35071        0.832\n",
      "            53          -0.34934        0.830\n",
      "            54          -0.34801        0.830\n",
      "            55          -0.34671        0.834\n",
      "            56          -0.34544        0.836\n",
      "            57          -0.34421        0.836\n",
      "            58          -0.34300        0.838\n",
      "            59          -0.34183        0.842\n",
      "            60          -0.34068        0.842\n",
      "            61          -0.33956        0.842\n",
      "            62          -0.33846        0.842\n",
      "            63          -0.33739        0.842\n",
      "            64          -0.33634        0.842\n",
      "            65          -0.33532        0.842\n",
      "            66          -0.33431        0.842\n",
      "            67          -0.33333        0.838\n",
      "            68          -0.33237        0.838\n",
      "            69          -0.33143        0.838\n",
      "            70          -0.33051        0.838\n",
      "            71          -0.32961        0.838\n",
      "            72          -0.32872        0.840\n",
      "            73          -0.32786        0.838\n",
      "            74          -0.32701        0.838\n",
      "            75          -0.32617        0.838\n",
      "            76          -0.32535        0.838\n",
      "            77          -0.32455        0.838\n",
      "            78          -0.32376        0.838\n",
      "            79          -0.32299        0.838\n",
      "            80          -0.32223        0.838\n",
      "            81          -0.32149        0.838\n",
      "            82          -0.32076        0.838\n",
      "            83          -0.32004        0.838\n",
      "            84          -0.31933        0.838\n",
      "            85          -0.31863        0.840\n",
      "            86          -0.31795        0.840\n",
      "            87          -0.31728        0.840\n",
      "            88          -0.31662        0.840\n",
      "            89          -0.31597        0.840\n",
      "            90          -0.31533        0.840\n",
      "            91          -0.31470        0.842\n",
      "            92          -0.31408        0.842\n",
      "            93          -0.31348        0.842\n",
      "            94          -0.31288        0.842\n",
      "            95          -0.31229        0.844\n",
      "            96          -0.31170        0.846\n",
      "            97          -0.31113        0.846\n",
      "            98          -0.31057        0.846\n",
      "            99          -0.31001        0.846\n",
      "         Final          -0.30947        0.846\n",
      "0.76\n",
      "0.7530241935483871\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'me_mod2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-2e19ae823a5d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mme_mod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabeled_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgender_features2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConditionalExponentialClassifier\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mme_mod2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow_most_informative_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'me_mod2' is not defined"
     ]
    }
   ],
   "source": [
    "me_mod = test_classifier(labeled_names, gender_features2, nltk.ConditionalExponentialClassifier)\n",
    "me_mod2.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slow computation, peaks after six iterations\n",
    "\n",
    "(Add chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "me_mod3 = test_classifier(labeled_names, gender_features3, nltk.ConditionalExponentialClassifier)\n",
    "me_mod3.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rapid computation, unclear if reached optimum as continues to improve\n",
    "\n",
    "(Add chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ==> Training (100 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.396\n",
      "             2          -0.61468        0.604\n",
      "             3          -0.58329        0.622\n",
      "             4          -0.55521        0.700\n",
      "             5          -0.53014        0.752\n",
      "             6          -0.50773        0.780\n",
      "             7          -0.48767        0.800\n",
      "             8          -0.46966        0.818\n",
      "             9          -0.45343        0.834\n",
      "            10          -0.43876        0.850\n",
      "            11          -0.42544        0.858\n",
      "            12          -0.41331        0.866\n",
      "            13          -0.40221        0.866\n",
      "            14          -0.39202        0.870\n",
      "            15          -0.38263        0.870\n",
      "            16          -0.37394        0.874\n",
      "            17          -0.36589        0.878\n",
      "            18          -0.35839        0.878\n",
      "            19          -0.35139        0.878\n",
      "            20          -0.34484        0.880\n",
      "            21          -0.33869        0.884\n",
      "            22          -0.33290        0.890\n",
      "            23          -0.32745        0.896\n",
      "            24          -0.32229        0.900\n",
      "            25          -0.31740        0.900\n",
      "            26          -0.31277        0.900\n",
      "            27          -0.30836        0.900\n",
      "            28          -0.30416        0.902\n",
      "            29          -0.30015        0.904\n",
      "            30          -0.29632        0.904\n",
      "            31          -0.29265        0.904\n",
      "            32          -0.28913        0.906\n",
      "            33          -0.28576        0.908\n",
      "            34          -0.28252        0.908\n",
      "            35          -0.27940        0.912\n",
      "            36          -0.27639        0.912\n",
      "            37          -0.27349        0.912\n",
      "            38          -0.27069        0.912\n",
      "            39          -0.26799        0.914\n",
      "            40          -0.26537        0.916\n",
      "            41          -0.26284        0.916\n",
      "            42          -0.26038        0.916\n",
      "            43          -0.25800        0.914\n",
      "            44          -0.25569        0.918\n",
      "            45          -0.25344        0.918\n",
      "            46          -0.25126        0.918\n",
      "            47          -0.24914        0.918\n",
      "            48          -0.24708        0.920\n",
      "            49          -0.24507        0.920\n",
      "            50          -0.24311        0.920\n",
      "            51          -0.24120        0.920\n",
      "            52          -0.23934        0.920\n",
      "            53          -0.23752        0.920\n",
      "            54          -0.23575        0.920\n",
      "            55          -0.23401        0.926\n",
      "            56          -0.23232        0.928\n",
      "            57          -0.23066        0.928\n",
      "            58          -0.22904        0.928\n",
      "            59          -0.22746        0.930\n",
      "            60          -0.22591        0.932\n",
      "            61          -0.22439        0.932\n",
      "            62          -0.22290        0.932\n",
      "            63          -0.22145        0.932\n",
      "            64          -0.22002        0.932\n",
      "            65          -0.21862        0.932\n",
      "            66          -0.21724        0.932\n",
      "            67          -0.21590        0.932\n",
      "            68          -0.21457        0.932\n",
      "            69          -0.21328        0.932\n",
      "            70          -0.21200        0.934\n",
      "            71          -0.21075        0.934\n",
      "            72          -0.20952        0.934\n",
      "            73          -0.20831        0.934\n",
      "            74          -0.20713        0.934\n",
      "            75          -0.20596        0.934\n",
      "            76          -0.20481        0.938\n",
      "            77          -0.20369        0.938\n",
      "            78          -0.20258        0.938\n",
      "            79          -0.20148        0.938\n",
      "            80          -0.20041        0.940\n",
      "            81          -0.19935        0.942\n",
      "            82          -0.19831        0.942\n",
      "            83          -0.19729        0.942\n",
      "            84          -0.19628        0.944\n",
      "            85          -0.19529        0.944\n",
      "            86          -0.19431        0.944\n",
      "            87          -0.19335        0.944\n",
      "            88          -0.19240        0.944\n",
      "            89          -0.19146        0.944\n",
      "            90          -0.19054        0.946\n",
      "            91          -0.18963        0.948\n",
      "            92          -0.18873        0.950\n",
      "            93          -0.18785        0.950\n",
      "            94          -0.18698        0.950\n",
      "            95          -0.18612        0.950\n",
      "            96          -0.18527        0.950\n",
      "            97          -0.18443        0.950\n",
      "            98          -0.18361        0.950\n",
      "            99          -0.18280        0.950\n",
      "         Final          -0.18199        0.950\n",
      "0.76\n",
      "0.7831221198156681\n",
      "   2.871 suffix3=='zra' and label is 'male'\n",
      "   2.808 suffix3=='wen' and label is 'female'\n",
      "   2.504 suffix2=='Bo' and label is 'female'\n",
      "   2.504 suffix3=='Bo' and label is 'female'\n",
      "   2.332 suffix3=='sha' and label is 'male'\n",
      "   2.052 suffix3=='ird' and label is 'female'\n",
      "   2.030 suffix3=='mey' and label is 'male'\n",
      "   2.007 suffix3=='arl' and label is 'male'\n",
      "  -1.924 lastletter=='a' and label is 'male'\n",
      "  -1.924 suffix1=='a' and label is 'male'\n"
     ]
    }
   ],
   "source": [
    "me_mod4 = test_classifier(labeled_names, gender_features4, nltk.ConditionalExponentialClassifier)\n",
    "me_mod4.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
