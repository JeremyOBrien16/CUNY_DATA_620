{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA 620 - Project 3\n",
    "\n",
    "Jeremy OBrien, Mael Illien, Vanita Thompson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name Gender Classifier\n",
    "\n",
    "* Using any of the three classifiers described in chapter 6 of Natural Language Processing with Python, and any features you can think of, build the best name gender classifier you can. \n",
    "* Begin by splitting the Names Corpus into three subsets: 500 words for the test set, 500 words for the dev-test set, and the remaining 6900 words for the training set. \n",
    "* Then, starting with the example name gender classifier, make incremental improvements. Use the dev-test set to check your progress. \n",
    "* Once you are satisfied with your classifier, check its final performance on the test set. \n",
    "* How does the performance on the test set compare to the performance on the dev-test set? Is this what you'd expect?\n",
    "* Source: Natural Language Processing with Python, exercise 6.10.2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "For this project, we work with the 'names' corpus contained within NLTK.\n",
    "\n",
    "We start our work by restructing some of the guidelines from Chapter 6 of our text. The function 'test_classifier' performs most of the work: splitting the data into train and test sets, extracting features, training the model, and predicting based on the test set. \n",
    "\n",
    "In the feature engineering section, we build on examples from the text and develop new features to evaluate. \n",
    "\n",
    "We study each of the three classifiers described in the text - NaiveBayes, DecisionTree, and MaxEntropy - in their respective sections, and compare results in a summary table in the conclusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import nltk, re, pprint\n",
    "from nltk.corpus import names\n",
    "from nltk.classify import apply_features\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ease of comparison, we compile a list of the models created for this project and their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [] # Will contain tuples (classifier, class_name, gf_name, acc_devtest, acc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import & Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NLTK 'names' corpus contains both male and female names in separate text files. The code below extracts the names from both files, assigns a gender to the name, and stores the information in a list of tuples. The labeled names are shuffled to randomize their distribution over the train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Christie', 'female'),\n",
       " ('Tibold', 'male'),\n",
       " ('Chet', 'male'),\n",
       " ('Alyss', 'female'),\n",
       " ('Eunice', 'female'),\n",
       " ('Mehetabel', 'female'),\n",
       " ('Marj', 'female'),\n",
       " ('Adam', 'male'),\n",
       " ('Natka', 'female'),\n",
       " ('Sarene', 'female')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_names = ([(name, 'male') for name in names.words('male.txt')] + \n",
    "         [(name, 'female') for name in names.words('female.txt')])\n",
    "\n",
    "random.seed(620)\n",
    "random.shuffle(labeled_names)\n",
    "labeled_names[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Classifier\n",
    "\n",
    "The **test_classifier** function takes as arguments a corpus of labeled names, a function to extract features from that corpus, and a classifier type. It splits the datasets into three parts: a training set, a devtest set, and a test set. It trains the classifier and returns the model and its accuracy on both test sets. This information is made available to compare between approaches to feature engineering and model types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_classifier(names_corpus, gender_features_function, classifier_type):\n",
    "\n",
    "    # Train test split\n",
    "    train_names = names_corpus[:500]\n",
    "    devtest_names = names_corpus[500:1000]\n",
    "    test_names = names_corpus[1000:]\n",
    "    \n",
    "    # Appy features\n",
    "    train_set = [(gender_features_function(n), gender) for (n, gender) in train_names]\n",
    "    devtest_set = [(gender_features_function(n), gender) for (n, gender) in devtest_names]\n",
    "    test_set = [(gender_features_function(n), gender) for (n, gender) in test_names]\n",
    "    \n",
    "    # Classify and print score; if Maximum Entropy, use trace to limit diagnostic output on screen\n",
    "    if classifier_type == nltk.ConditionalExponentialClassifier:\n",
    "        classifier = classifier_type.train(train_set, trace=0)\n",
    "    else:\n",
    "        classifier = classifier_type.train(train_set)\n",
    "    acc_devtest = round(nltk.classify.accuracy(classifier, devtest_set), 3)\n",
    "    acc_test = round(nltk.classify.accuracy(classifier, test_set), 3)\n",
    "    print('Dev test set accuracy: ' + str(acc_devtest))\n",
    "    print('Test set accuracy: ' + str(acc_test))\n",
    "    \n",
    "    #classifier.show_most_informative_features(5)\n",
    "    \n",
    "    class_name = classifier_type.__name__\n",
    "    gf_name = gender_features_function.__name__\n",
    "    models.append((classifier, class_name, gf_name, acc_devtest, acc_test))\n",
    "    \n",
    "    return classifier  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We explore a number of approaches to breaking down first names and extracting features to train the classifier model. These different approaches may lend the classifiers more or less power to efficiently discriminate between female and male names.\n",
    "\n",
    "We include features defined in the text and augment them with additional appraoches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Approach \\#1**:  The last letter of the name. While a simple approach, the particular letter at the end of a name can be powerful predictor of gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_features1(name):\n",
    "    return {'last_letter': name[-1]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Approach \\#2**:  The first letter, last letter, and presence and counts of all letters in the name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_features2(name):\n",
    "    features = {}\n",
    "    features[\"firstletter\"] = name[0].lower()\n",
    "    features[\"lastletter\"] = name[-1].lower()\n",
    "    for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
    "        features[\"count(%s)\" % letter] = name.lower().count(letter)\n",
    "        features[\"has(%s)\" % letter] = (letter in name.lower())\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Approach \\#3**:  The last and penultimate letters in the name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_features3(word):\n",
    "    return {'suffix1': word[-1:], 'suffix2': word[-2:]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Approach \\#4**:  The first letter, last letter, presence and counts of all letters, and suffixes (final sequence of one, two, or three letters) of the name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_features4(name):\n",
    "    features = {}\n",
    "    features[\"firstletter\"] = name[0].lower()\n",
    "    features[\"lastletter\"] = name[-1].lower()\n",
    "    features['suffix1'] =  name[-1:]\n",
    "    features['suffix2'] = name[-2:]\n",
    "    features['suffix3'] = name[-3:]\n",
    "    for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
    "        features[\"count(%s)\" % letter] = name.lower().count(letter)\n",
    "        features[\"has(%s)\" % letter] = (letter in name.lower())\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Approach \\#5**:  Whether the first letter or last letter of the name are vowels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_features5(name):\n",
    "    features = {}\n",
    "    features[\"vowel_start\"] = int(name[0].lower() in 'aeiuo')\n",
    "    features[\"vowel_end\"] = int(name[-1].lower() in 'aeiuo')\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Approach \\#6**:  The length of the name, with an arbitrary cutoff of five letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_features6(name):\n",
    "    features = {}\n",
    "    features[\"short_name\"] = int(len(name) < 4)\n",
    "    features['length'] = len(name)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifiers\n",
    "\n",
    "In this section, we define the model parameters and call the **test_classifier** function. Accuracy scores on both test sets are outputted for each model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes\n",
    "\n",
    "With a Naive Bayes classifier, every feature is used to determine which label (male or female) should be assigned to a given input name. The prior probability (the proportion of male and females names in the training data) is modulated by the contribution from each feature to arrive at a likelihood estimate for each label. The label with the highest probability is then assigned. Note that this classifier works under the assumption that each feature is independent of every other features which can be unrealistic, hence the qualifier 'naive'. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test our first feature (last letter only) and by displaying the most informative features, we discover the important classifying power of the last letter 'a' which is nearly 46 times more likely to be a female name. The accuracy score is solid for a single feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev test set accuracy: 0.758\n",
      "Test set accuracy: 0.756\n",
      "Most Informative Features\n",
      "             last_letter = 'a'            female : male   =     45.9 : 1.0\n",
      "             last_letter = 'd'              male : female =      9.7 : 1.0\n",
      "             last_letter = 'o'              male : female =      8.9 : 1.0\n",
      "             last_letter = 'r'              male : female =      6.5 : 1.0\n",
      "             last_letter = 'i'            female : male   =      4.7 : 1.0\n"
     ]
    }
   ],
   "source": [
    "nb_mod1 = test_classifier(labeled_names, gender_features1, nltk.NaiveBayesClassifier)\n",
    "nb_mod1.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When including the first letter, last letter, and the presence and count of all alphabet letters, we see that the first five most informative features are identical to the first approach. We print the next five features to see the contribution of the added features. While their contribution is not as significant as the first five, we can see below the impact of two 'd's in a name, the first letter 'z', and the presence of 'w'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev test set accuracy: 0.738\n",
      "Test set accuracy: 0.753\n",
      "Most Informative Features\n",
      "              lastletter = 'a'            female : male   =     45.9 : 1.0\n",
      "              lastletter = 'd'              male : female =      9.7 : 1.0\n",
      "              lastletter = 'o'              male : female =      8.9 : 1.0\n",
      "              lastletter = 'r'              male : female =      6.5 : 1.0\n",
      "              lastletter = 'i'            female : male   =      4.7 : 1.0\n",
      "                count(d) = 2                male : female =      4.5 : 1.0\n",
      "              lastletter = 'm'              male : female =      3.9 : 1.0\n",
      "             firstletter = 'z'              male : female =      3.9 : 1.0\n",
      "                count(w) = 1                male : female =      3.9 : 1.0\n",
      "                  has(w) = True             male : female =      3.9 : 1.0\n"
     ]
    }
   ],
   "source": [
    "nb_mod2 = test_classifier(labeled_names, gender_features2, nltk.NaiveBayesClassifier)\n",
    "nb_mod2.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A suffix a size one is equivalent to the last letter of a name so it is no surprise to see suffix1 = 'a' appearing at the top. Suffixes of size two have a strong contribution. The suffix 'ne' (as in 'Anne') is more likely to be female while the suffix 'er' (as in Peter) is more likely to be male."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev test set accuracy: 0.762\n",
      "Test set accuracy: 0.766\n",
      "Most Informative Features\n",
      "                 suffix1 = 'a'            female : male   =     45.9 : 1.0\n",
      "                 suffix2 = 'ne'           female : male   =     10.2 : 1.0\n",
      "                 suffix1 = 'd'              male : female =      9.7 : 1.0\n",
      "                 suffix1 = 'o'              male : female =      8.9 : 1.0\n",
      "                 suffix1 = 'r'              male : female =      6.5 : 1.0\n",
      "                 suffix2 = 'er'             male : female =      5.2 : 1.0\n",
      "                 suffix1 = 'i'            female : male   =      4.7 : 1.0\n",
      "                 suffix2 = 'on'             male : female =      4.6 : 1.0\n",
      "                 suffix1 = 'm'              male : female =      3.9 : 1.0\n",
      "                 suffix2 = 'ed'             male : female =      3.6 : 1.0\n"
     ]
    }
   ],
   "source": [
    "nb_mod3 = test_classifier(labeled_names, gender_features3, nltk.NaiveBayesClassifier)\n",
    "nb_mod3.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When three-letter suffixes are included we encounter the highest accuracy on the test set for a Naive Bayers model so far: .779. We encounter duplication between lastletter and suffix1. A suffix of size three 'ine' shows up in the top ten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev test set accuracy: 0.78\n",
      "Test set accuracy: 0.779\n",
      "Most Informative Features\n",
      "              lastletter = 'a'            female : male   =     45.9 : 1.0\n",
      "                 suffix1 = 'a'            female : male   =     45.9 : 1.0\n",
      "                 suffix2 = 'ne'           female : male   =     10.2 : 1.0\n",
      "              lastletter = 'd'              male : female =      9.7 : 1.0\n",
      "                 suffix1 = 'd'              male : female =      9.7 : 1.0\n",
      "              lastletter = 'o'              male : female =      8.9 : 1.0\n",
      "                 suffix1 = 'o'              male : female =      8.9 : 1.0\n",
      "                 suffix3 = 'ine'          female : male   =      6.5 : 1.0\n",
      "              lastletter = 'r'              male : female =      6.5 : 1.0\n",
      "                 suffix1 = 'r'              male : female =      6.5 : 1.0\n"
     ]
    }
   ],
   "source": [
    "nb_mod4 = test_classifier(labeled_names, gender_features4, nltk.NaiveBayesClassifier)\n",
    "nb_mod4.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By evaluating letters on whether they are vowels, we find that names ending in vowels are 2.5 times more likely to be female names. The converse (ending in a consonant), is true for males."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev test set accuracy: 0.728\n",
      "Test set accuracy: 0.729\n",
      "Most Informative Features\n",
      "               vowel_end = 1              female : male   =      2.5 : 1.0\n",
      "               vowel_end = 0                male : female =      2.4 : 1.0\n",
      "             vowel_start = 1              female : male   =      1.1 : 1.0\n",
      "             vowel_start = 0                male : female =      1.0 : 1.0\n"
     ]
    }
   ],
   "source": [
    "nb_mod5 = test_classifier(labeled_names, gender_features5, nltk.NaiveBayesClassifier)\n",
    "nb_mod5.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With an accuracy score of 0.63, the number of letters in a name is the worst feature to classify gender thus far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev test set accuracy: 0.656\n",
      "Test set accuracy: 0.63\n",
      "Most Informative Features\n",
      "                  length = 3                male : female =      3.5 : 1.0\n",
      "                  length = 9              female : male   =      3.5 : 1.0\n",
      "              short_name = 1                male : female =      3.1 : 1.0\n",
      "                  length = 4                male : female =      1.7 : 1.0\n",
      "                  length = 7              female : male   =      1.3 : 1.0\n",
      "                  length = 10               male : female =      1.2 : 1.0\n",
      "                  length = 5              female : male   =      1.1 : 1.0\n",
      "              short_name = 0              female : male   =      1.1 : 1.0\n",
      "                  length = 8              female : male   =      1.0 : 1.0\n",
      "                  length = 6              female : male   =      1.0 : 1.0\n"
     ]
    }
   ],
   "source": [
    "nb_mod6 = test_classifier(labeled_names, gender_features6, nltk.NaiveBayesClassifier)\n",
    "nb_mod6.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision trees are made up of two components: decision nodes, which check feature values, and leaf nodes, which assign labels. The algorithm computes a decision stump for each possible feature, and evaluates which feature achieves the best accuracy on the training data. It then iteratively checks every leaf of the stump and computes a new decision stump based on the feature that maximizes the accuracy as before.\n",
    "\n",
    "We leverage pseudocode and truncated pretty_format output to help understand the structure of each decision tree below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first approach uses only a single feature (the last letter) which doesn't result in much of a tree. However, the accuracy score is quite similar to the Naives Bayes model using the same feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev test set accuracy: 0.756\n",
      "Test set accuracy: 0.762\n"
     ]
    }
   ],
   "source": [
    "dt_mod1 = test_classifier(labeled_names, gender_features1, nltk.DecisionTreeClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When a wider set of features are use a branching structure becomes apparent, with indents representing leaf nodes. Interestingly, the accuracy score has decreased slightly from the last letter feature alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev test set accuracy: 0.768\n",
      "Test set accuracy: 0.723\n",
      "lastletter=a? ..................... female\n",
      "lastletter=b? ..................... male\n",
      "lastletter=c? ..................... male\n",
      "lastletter=d? ..................... male\n",
      "  firstletter=a? .................. male\n",
      "  firstletter=c? .................. female\n",
      "  firstletter=d? .................. male\n",
      "  firstletter=f? .................. female\n",
      "  firstletter=m? .................. male\n",
      "  firstletter=n? .................. male\n",
      "  firstletter=r? .................. male\n",
      "  firstletter=s? .................. male\n",
      "  firstletter=t? .................. male\n",
      "  firstletter=w? .................. male\n",
      "lastletter=e? ..................... female\n",
      "  firstletter=a? .................. female\n",
      "    count(c)=0? ................... female\n",
      "      count(a)=2? ................. male\n",
      "      count(a)=1? ................. female\n",
      "    count(c)=1? ................... male\n",
      "  firstletter=b? .................. female\n",
      "    count(f)=0? ................... female\n",
      "    count(f)=1? ................... male\n",
      "  firstletter=c? .................. female\n"
     ]
    }
   ],
   "source": [
    "dt_mod2 = test_classifier(labeled_names, gender_features2, nltk.DecisionTreeClassifier)\n",
    "print(dt_mod2.pretty_format(width=50, prefix='', depth=4)[:1003]) # alternate to pseudocode function call"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next approach, only suffixes of size 2 form the leaves of the tree. The score is lower than the first two approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev test set accuracy: 0.73\n",
      "Test set accuracy: 0.732\n",
      "suffix2=ad? ....................... male\n",
      "suffix2=ah? ....................... female\n",
      "suffix2=ak? ....................... male\n",
      "suffix2=al? ....................... male\n",
      "suffix2=am? ....................... male\n",
      "suffix2=an? ....................... female\n",
      "suffix2=ar? ....................... male\n",
      "suffix2=as? ....................... male\n",
      "suffix2=at? ....................... male\n",
      "suffix2=ba? ....................... female\n",
      "suffix2=be? ....................... female\n",
      "suffix2=by? ....................... male\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt_mod3 = test_classifier(labeled_names, gender_features3, nltk.DecisionTreeClassifier)\n",
    "print(dt_mod3.pretty_format(width=50, prefix='', depth=4)[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While adding more features increases complexity, it has actually reduced the accuracy compared with the preceding approaches. This is likely due to the fact that as the tree descends down into leaves there is less and less training data available to generalize, leading to overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev test set accuracy: 0.634\n",
      "Test set accuracy: 0.639\n",
      "suffix3=aak? ...................... male\n",
      "suffix3=ace? ...................... male\n",
      "suffix3=Ace? ...................... male\n",
      "suffix3=ada? ...................... female\n",
      "suffix3=add? ...................... male\n",
      "suffix3=ady? ...................... male\n",
      "suffix3=afe? ...................... male\n",
      "suffix3=ain? ...................... female\n",
      "suffix3=air? ...................... male\n",
      "suffix3=ait? ...................... male\n",
      "suffix3=ale? ...................... male\n",
      "suffix3=ami? ...................... female\n",
      "suffix3=ana? ...................... female\n",
      "suffix3=and? ...................... male\n",
      "suffix3=ane? ...................... female\n",
      "suffix3=ang? ...................... male\n",
      "suffix3=ani? ...................... female\n",
      "suffix3=ano? ...................... male\n",
      "suffix3=ara? ...................... female\n",
      "suffix3=ard? ...................... male\n",
      "suffix3=arj? ...................... female\n",
      "suffix3=ark? ...................... male\n",
      "suffix3=arv? ...................... male\n",
      "suffix3=ary? ...................... male\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt_mod4 = test_classifier(labeled_names, gender_features4, nltk.DecisionTreeClassifier)\n",
    "print(dt_mod4.pretty_format(width=50, prefix='', depth=4)[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next two approaches yield single-feature trees without additional branching. Their accuracy scores are similar to the Naive Bayes approaches using the same feature sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev test set accuracy: 0.728\n",
      "Test set accuracy: 0.729\n",
      "if vowel_end == 0: return 'male'\n",
      "if vowel_end == 1: return 'female'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt_mod5 = test_classifier(labeled_names, gender_features5, nltk.DecisionTreeClassifier)\n",
    "print(dt_mod5.pseudocode(depth=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev test set accuracy: 0.626\n",
      "Test set accuracy: 0.61\n",
      "if length == 10: return 'female'\n",
      "if length == 11: return 'female'\n",
      "if length == 12: return 'female'\n",
      "if length == 13: return 'female'\n",
      "if length == 2: return 'female'\n",
      "if length == 3: return 'male'\n",
      "if length == 4: return 'male'\n",
      "if length == 5: return 'female'\n",
      "if length == 6: return 'female'\n",
      "if length == 7: return 'female'\n",
      "if length == 8: return 'female'\n",
      "if length == 9: return 'female'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt_mod6 = test_classifier(labeled_names, gender_features6, nltk.DecisionTreeClassifier)\n",
    "print(dt_mod6.pseudocode(depth=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of using probabilites to set model parameters as the Naive Bayes classifier does, the Maximum Entropy Model (or [MaxEntropy](https://web.stanford.edu/class/cs124/lec/Maximum_Entropy_Classifiers.pdf)) searches for the set of parameters that maximize model performance. The property of [entropy](https://lost-contact.mit.edu/afs/cs.pitt.edu/projects/nltk/docs/tutorial/classifying/nochunks.html#maxent) entails uniformity of the distribution where there isn't empirical evidence that would constrain that uniformity.  \n",
    "\n",
    "Unlike Naive Bayes, MaxEntropy does not assume independence of features, and so is not negatively impacted when there is dependence between features - which can often be the case. As MaxEnt captures the structure of the training data, the more features it uses the stronger the constraint of empirical consistency becomes.\n",
    "\n",
    "MaxEntropy is a conditional classifier, meaning it can be used to determine the most likely label for a given input or conversely how likely a label is for that input.  A generative classifier like Naive Bayers can estimate the most likely input value, how likely an input value is, as well as the same given an input label. \n",
    "\n",
    "NLTK offers two MaxEntropy algorithms out of the box: Generalized Iterative Scaling (GIS) and Improved Iterative Scaling (IIS). Iterative optimization using these algorithms can be time consuming, and the Wikipedia article on [MaxEntropy](https://en.wikipedia.org/wiki/Maximum_entropy_probability_distribution) and the literature ['A comparison of algorithms for maximum entropy parameter estimation'](http://luthuli.cs.uiuc.edu/~daf/courses/Opt-2017/Papers/p18-malouf.pdf) note that gradient-based methods, such as coordinate descent and limited memory L-BFGS and LMBVM are preferable for their improved computational performance. While NLTK offered additional classifier algorithms through SciPy, it seems support has lapsed in the latest SciPy releases.\n",
    "\n",
    "Given the outdated SciPy support and minimal computational duress of this dataset, for this project we implement MaxEntropy using the GIS algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using only the last letter of the name leads to rapid convergence on the second iteration. Interestingly, consonants in the last letter position are the most informative features, in five of six cases classifying male. This contrasts with the Naive Bayes model, which had a mix of vowels / consonants and genders as top features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev test set accuracy: 0.756\n",
      "Test set accuracy: 0.763\n",
      "   6.644 last_letter=='k' and label is 'male'\n",
      "   6.644 last_letter=='x' and label is 'male'\n",
      "   6.644 last_letter=='b' and label is 'male'\n",
      "   6.644 last_letter=='z' and label is 'female'\n",
      "   6.644 last_letter=='p' and label is 'male'\n",
      "   6.644 last_letter=='c' and label is 'male'\n",
      "  -5.858 last_letter=='a' and label is 'male'\n",
      "  -2.392 last_letter=='i' and label is 'male'\n",
      "  -2.000 last_letter=='d' and label is 'female'\n",
      "  -1.807 last_letter=='o' and label is 'female'\n"
     ]
    }
   ],
   "source": [
    "me_mod1 = test_classifier(labeled_names, gender_features1, nltk.ConditionalExponentialClassifier)\n",
    "me_mod1.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Including the first letter and counts of all letters improves accuracy, but with a noticeable impact on computational performance. Some first letters and shorter counts are top ten features, demonstrating the contribution to performance these features have. Even after 90 iterations the model continues to improve incrementally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev test set accuracy: 0.766\n",
      "Test set accuracy: 0.782\n",
      "  -5.130 lastletter=='a' and label is 'male'\n",
      "   3.347 firstletter=='u' and label is 'female'\n",
      "   2.292 firstletter=='y' and label is 'male'\n",
      "  -2.175 lastletter=='i' and label is 'male'\n",
      "  -1.604 lastletter=='o' and label is 'female'\n",
      "  -1.590 lastletter=='d' and label is 'female'\n",
      "   1.563 lastletter=='c' and label is 'male'\n",
      "   1.501 count(e)==4 and label is 'female'\n",
      "   1.449 count(h)==3 and label is 'female'\n",
      "  -1.374 lastletter=='r' and label is 'female'\n"
     ]
    }
   ],
   "source": [
    "me_mod2 = test_classifier(labeled_names, gender_features2, nltk.ConditionalExponentialClassifier)\n",
    "me_mod2.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Including the last two letters of the name does not improve upon the accuracy of just using the final letter.  As it takes noticeably longer to process and seven iterations to reach an optimum, this is not a strong candidate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev test set accuracy: 0.758\n",
      "Test set accuracy: 0.763\n",
      "  15.029 suffix2=='ha' and label is 'male'\n",
      "  11.066 suffix2=='vi' and label is 'male'\n",
      "  10.253 suffix2=='ko' and label is 'female'\n",
      "  -9.849 suffix1=='a' and label is 'male'\n",
      "   8.238 suffix2=='Em' and label is 'female'\n",
      "   7.264 suffix2=='ev' and label is 'female'\n",
      "   6.848 suffix2=='es' and label is 'female'\n",
      "   6.848 suffix2=='ss' and label is 'female'\n",
      "   6.439 suffix2=='me' and label is 'male'\n",
      "   6.439 suffix2=='fe' and label is 'male'\n"
     ]
    }
   ],
   "source": [
    "me_mod3 = test_classifier(labeled_names, gender_features3, nltk.ConditionalExponentialClassifier)\n",
    "me_mod3.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding two and three-letter suffixes to first letter, last letter, and counts delivers the best accuracy of all models (including Naive Bayers and Decision Trees) so far: 0.784. In exchange, the model takes a good amount of time to run, and continues to improve after 90 iterations. With the exception of the final letter 'a' classifying male, two- and three-letter suffixes have the most impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev test set accuracy: 0.772\n",
      "Test set accuracy: 0.784\n",
      "  -3.148 lastletter=='a' and label is 'male'\n",
      "  -3.148 suffix1=='a' and label is 'male'\n",
      "   2.847 suffix2=='ha' and label is 'male'\n",
      "   2.847 suffix3=='cha' and label is 'male'\n",
      "   2.367 suffix3=='nri' and label is 'male'\n",
      "   2.058 suffix3=='eer' and label is 'female'\n",
      "   1.968 suffix3=='lil' and label is 'male'\n",
      "   1.847 suffix3=='ase' and label is 'male'\n",
      "   1.799 suffix3=='vie' and label is 'male'\n",
      "   1.795 suffix2=='vi' and label is 'male'\n"
     ]
    }
   ],
   "source": [
    "me_mod4 = test_classifier(labeled_names, gender_features4, nltk.ConditionalExponentialClassifier)\n",
    "me_mod4.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final two approaches - whether first / last letters are vowels, and the length of names - yield the worst accuracy measures of the MaxEntropy models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev test set accuracy: 0.728\n",
      "Test set accuracy: 0.729\n",
      "  -1.238 vowel_end==1 and label is 'male'\n",
      "   0.495 vowel_end==1 and label is 'female'\n",
      "  -0.477 vowel_end==0 and label is 'female'\n",
      "   0.394 vowel_end==0 and label is 'male'\n",
      "  -0.314 vowel_start==1 and label is 'male'\n",
      "   0.219 vowel_start==1 and label is 'female'\n",
      "  -0.188 vowel_start==0 and label is 'male'\n",
      "   0.149 vowel_start==0 and label is 'female'\n"
     ]
    }
   ],
   "source": [
    "me_mod5 = test_classifier(labeled_names, gender_features5, nltk.ConditionalExponentialClassifier)\n",
    "me_mod5.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev test set accuracy: 0.626\n",
      "Test set accuracy: 0.611\n",
      "   5.721 length==2 and label is 'female'\n",
      "   5.185 length==13 and label is 'female'\n",
      "   5.185 length==11 and label is 'female'\n",
      "   5.185 length==12 and label is 'female'\n",
      "  -1.716 length==9 and label is 'male'\n",
      "  -0.740 length==3 and label is 'female'\n",
      "   0.542 length==9 and label is 'female'\n",
      "   0.417 length==3 and label is 'male'\n",
      "  -0.400 length==7 and label is 'male'\n",
      "  -0.279 short_name==0 and label is 'male'\n"
     ]
    }
   ],
   "source": [
    "me_mod6 = test_classifier(labeled_names, gender_features6, nltk.ConditionalExponentialClassifier)\n",
    "me_mod6.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We conclude by summarizing all the models we have tested. This summary is shown both in the order of testing, and ranked by accuracy on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_models(models):\n",
    "    table = pd.DataFrame(columns = ['class', 'features', 'accuracy_devtest', 'accuracy_test'])\n",
    "    \n",
    "    for m in models:\n",
    "        df = pd.DataFrame({'class': [m[1]], 'features': [m[2]], 'accuracy_devtest': [m[3]], 'accuracy_test': [m[4]]})\n",
    "        table = table.append(df, ignore_index=True)\n",
    "\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>features</th>\n",
       "      <th>accuracy_devtest</th>\n",
       "      <th>accuracy_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>MaxentClassifier</td>\n",
       "      <td>gender_features4</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MaxentClassifier</td>\n",
       "      <td>gender_features2</td>\n",
       "      <td>0.766</td>\n",
       "      <td>0.782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>gender_features4</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>gender_features3</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MaxentClassifier</td>\n",
       "      <td>gender_features3</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MaxentClassifier</td>\n",
       "      <td>gender_features1</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>gender_features1</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>gender_features1</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>gender_features2</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>gender_features3</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>gender_features5</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>MaxentClassifier</td>\n",
       "      <td>gender_features5</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>gender_features5</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>gender_features2</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>gender_features4</td>\n",
       "      <td>0.634</td>\n",
       "      <td>0.639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>gender_features6</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>MaxentClassifier</td>\n",
       "      <td>gender_features6</td>\n",
       "      <td>0.626</td>\n",
       "      <td>0.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>gender_features6</td>\n",
       "      <td>0.626</td>\n",
       "      <td>0.610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     class          features  accuracy_devtest  accuracy_test\n",
       "15        MaxentClassifier  gender_features4             0.772          0.784\n",
       "13        MaxentClassifier  gender_features2             0.766          0.782\n",
       "3     NaiveBayesClassifier  gender_features4             0.780          0.779\n",
       "2     NaiveBayesClassifier  gender_features3             0.762          0.766\n",
       "14        MaxentClassifier  gender_features3             0.758          0.763\n",
       "12        MaxentClassifier  gender_features1             0.756          0.763\n",
       "6   DecisionTreeClassifier  gender_features1             0.756          0.762\n",
       "0     NaiveBayesClassifier  gender_features1             0.758          0.756\n",
       "1     NaiveBayesClassifier  gender_features2             0.738          0.753\n",
       "8   DecisionTreeClassifier  gender_features3             0.730          0.732\n",
       "4     NaiveBayesClassifier  gender_features5             0.728          0.729\n",
       "16        MaxentClassifier  gender_features5             0.728          0.729\n",
       "10  DecisionTreeClassifier  gender_features5             0.728          0.729\n",
       "7   DecisionTreeClassifier  gender_features2             0.768          0.723\n",
       "9   DecisionTreeClassifier  gender_features4             0.634          0.639\n",
       "5     NaiveBayesClassifier  gender_features6             0.656          0.630\n",
       "17        MaxentClassifier  gender_features6             0.626          0.611\n",
       "11  DecisionTreeClassifier  gender_features6             0.626          0.610"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = summarize_models(models)\n",
    "table.sort_values(by='accuracy_test', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ConditionalExponentialClassifier: 2 labels, 892 features>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = models[15][0] # Select the best model by index from the table above\n",
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest accuracy scores overall were attained by MaxEntropy classifiers - one using gender_features4 (combining many different features) to achieve an accuracy of 0.784, and close behind it the other one using gender_features2 for 0.782.\n",
    "\n",
    "The next best performing models are Naive Bayes classifiers using gender_features4 and gender_features3 (first and last letters) with accuracies of 0.779 and 0.766, respectively.\n",
    "\n",
    "The top performing Decision Tree classifier uses gender_features1 (last letters) garners seventh place with an accuracy of 0.762.\n",
    "\n",
    "Overall, assessed on the basis of average accuracy over the different feature sets, MaxEntropy outperforms Naive Bayes, and both outscore Decision Trees. \n",
    "\n",
    "This may have something to do with the MaxEntropy classifier accounting for connections between the features rather than treating them independently in the way that Naive Bayes does. Additionally, given that the training set consists of only 500 names it's possible that the Decision Tree classifier 'memorized' the training data and is unable to generalize on new, unseen data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>accuracy_devtest</th>\n",
       "      <th>accuracy_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MaxentClassifier</td>\n",
       "      <td>0.734333</td>\n",
       "      <td>0.738667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>0.737000</td>\n",
       "      <td>0.735500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.707000</td>\n",
       "      <td>0.699167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    class  accuracy_devtest  accuracy_test\n",
       "1        MaxentClassifier          0.734333       0.738667\n",
       "2    NaiveBayesClassifier          0.737000       0.735500\n",
       "0  DecisionTreeClassifier          0.707000       0.699167"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.groupby('class', as_index=False).mean().sort_values(by='accuracy_test', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MaxEntropy models were relatively more accurate than Naive Bayes and Decision Tree classifiers when using the GIS algorithm, but it's not clear if more efficient algorithms (like coordinate descent) might also deliver improved accuracy. Unfortunately, testing this without an update to the NLTK package that supports current versions of SciPy would entail a non-trivial level of effort, so this remains to be explored.\n",
    "\n",
    "Additionally, while essential for Natural Language Processing, the NLTK module may not contain the most powerful classifiers. Revisiting this project using the sklearn package could allow for more control over the classification process. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "#YouTubeVideo('...')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
